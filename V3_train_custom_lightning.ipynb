{"cells":[{"cell_type":"markdown","metadata":{"id":"xmcyc_tu7_sT"},"source":["### DRIVE CONNECTION"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34216,"status":"ok","timestamp":1675562685860,"user":{"displayName":"Neural Networks","userId":"08057855560763417429"},"user_tz":-60},"id":"6krqangM8D4P","outputId":"e47160ef-5899-4f0b-dc44-0cad246f5aee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/',force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"7N2WmitQqRPx"},"source":["### INSTALL DEPENDECIES"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26843,"status":"ok","timestamp":1675562712699,"user":{"displayName":"Neural Networks","userId":"08057855560763417429"},"user_tz":-60},"id":"9L8ZJF9kUSu6","outputId":"41b8418c-d97f-489b-89fe-6ae8acb9dfef"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 KB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.6/530.6 KB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install pytorch_lightning --quiet\n","!pip install lightly --quiet\n","!pip install wandb --quiet"]},{"cell_type":"markdown","metadata":{"id":"O5-hFUnOyQmO"},"source":["### Requirements per pointbert (forget about this 😞)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12721,"status":"ok","timestamp":1674760418541,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"FzPlKBXBfhnH","outputId":"8165d373-6417-458e-cbc2-e0d225283c8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libpython3.7-minimal libpython3.7-stdlib python3.7-minimal\n","Suggested packages:\n","  python3.7-venv binfmt-support\n","The following NEW packages will be installed:\n","  libpython3.7-minimal libpython3.7-stdlib python3.7 python3.7-minimal\n","0 upgraded, 4 newly installed, 0 to remove and 27 not upgraded.\n","Need to get 4,530 kB of archives.\n","After this operation, 23.3 MB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.7-minimal amd64 3.7.16-1+focal1 [588 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.7-minimal amd64 3.7.16-1+focal1 [1,808 kB]\n","Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.7-stdlib amd64 3.7.16-1+focal1 [1,773 kB]\n","Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.7 amd64 3.7.16-1+focal1 [360 kB]\n","Fetched 4,530 kB in 6s (734 kB/s)\n","Selecting previously unselected package libpython3.7-minimal:amd64.\n","(Reading database ... 129502 files and directories currently installed.)\n","Preparing to unpack .../libpython3.7-minimal_3.7.16-1+focal1_amd64.deb ...\n","Unpacking libpython3.7-minimal:amd64 (3.7.16-1+focal1) ...\n","Selecting previously unselected package python3.7-minimal.\n","Preparing to unpack .../python3.7-minimal_3.7.16-1+focal1_amd64.deb ...\n","Unpacking python3.7-minimal (3.7.16-1+focal1) ...\n","Selecting previously unselected package libpython3.7-stdlib:amd64.\n","Preparing to unpack .../libpython3.7-stdlib_3.7.16-1+focal1_amd64.deb ...\n","Unpacking libpython3.7-stdlib:amd64 (3.7.16-1+focal1) ...\n","Selecting previously unselected package python3.7.\n","Preparing to unpack .../python3.7_3.7.16-1+focal1_amd64.deb ...\n","Unpacking python3.7 (3.7.16-1+focal1) ...\n","Setting up libpython3.7-minimal:amd64 (3.7.16-1+focal1) ...\n","Setting up python3.7-minimal (3.7.16-1+focal1) ...\n","Setting up libpython3.7-stdlib:amd64 (3.7.16-1+focal1) ...\n","Setting up python3.7 (3.7.16-1+focal1) ...\n","Processing triggers for man-db (2.9.1-1) ...\n","Processing triggers for mime-support (3.64ubuntu1) ...\n"]}],"source":["#Installare python 3.7\n","#attivarlo\n","#installare le estensioni compilandole\n","\n","!apt-get install python3.7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6KoG1RhTfB0"},"outputs":[],"source":["!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11285,"status":"ok","timestamp":1674760429824,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"xr24pT1ATlwi","outputId":"a7c5319a-9c1a-44f0-8069-36a0918741af"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n","\n","  Selection    Path                Priority   Status\n","------------------------------------------------------------\n","* 0            /usr/bin/python3.8   1         auto mode\n","  1            /usr/bin/python3.7   1         manual mode\n","  2            /usr/bin/python3.8   1         manual mode\n","\n","Press <enter> to keep the current choice[*], or type selection number: 1\n","update-alternatives: using /usr/bin/python3.7 to provide /usr/bin/python3 (python3) in manual mode\n"]}],"source":["!sudo update-alternatives --config python3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":440,"status":"ok","timestamp":1674760434255,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"uh68qZrgWN2o","outputId":"4fea57c4-d250-4c24-900d-45b6f8745a8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.7.16\n"]}],"source":["!python -V"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8784,"status":"ok","timestamp":1674760445042,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"YkOEjk6GT3JX","outputId":"7f076e22-cc08-4247-9005-283263fea241"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  python-pip-whl python3-setuptools python3-wheel\n","Suggested packages:\n","  python-setuptools-doc\n","The following NEW packages will be installed:\n","  python-pip-whl python3-pip python3-setuptools python3-wheel\n","0 upgraded, 4 newly installed, 0 to remove and 27 not upgraded.\n","Need to get 2,389 kB of archives.\n","After this operation, 4,933 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.7 [1,805 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.7 [230 kB]\n","Fetched 2,389 kB in 2s (956 kB/s)\n","Selecting previously unselected package python-pip-whl.\n","(Reading database ... 130122 files and directories currently installed.)\n","Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.7_all.deb ...\n","Unpacking python-pip-whl (20.0.2-5ubuntu1.7) ...\n","Selecting previously unselected package python3-setuptools.\n","Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n","Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n","Selecting previously unselected package python3-wheel.\n","Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n","Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n","Selecting previously unselected package python3-pip.\n","Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.7_all.deb ...\n","Unpacking python3-pip (20.0.2-5ubuntu1.7) ...\n","Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n","Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n","Setting up python-pip-whl (20.0.2-5ubuntu1.7) ...\n","Setting up python3-pip (20.0.2-5ubuntu1.7) ...\n","Processing triggers for man-db (2.9.1-1) ...\n"]}],"source":["#INSTALL PIPPO\n","!apt-get install python3-pip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":522,"status":"ok","timestamp":1674760457082,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"xN-2ue4kUGso","outputId":"50938f58-e524-4832-f0ac-a318664b6c93"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT\n"]}],"source":["#mi sposto in pointbert folder per installare i req\n","%cd drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3653,"status":"ok","timestamp":1674760576365,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"lCpKWahhgird","outputId":"4e62beda-6ee8-4c74-8d5b-08c19e55382a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/bin/add-apt-repository\", line 12, in <module>\n","    from softwareproperties.SoftwareProperties import SoftwareProperties, shortcut_handler\n","  File \"/usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py\", line 28, in <module>\n","    import apt_pkg\n","ModuleNotFoundError: No module named 'apt_pkg'\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n","Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n","Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n","Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n","Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n","Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n","Get:9 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n","Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n","Get:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,439 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,288 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,916 kB]\n","Get:17 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [986 kB]\n","Fetched 7,969 kB in 3s (2,421 kB/s)\n","Reading package lists... Done\n"]}],"source":["!sudo add-apt-repository ppa:deadsnakes/ppa\n","!sudo apt-get update"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4143,"status":"ok","timestamp":1674760597346,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"S7ofx99ogpCv","outputId":"a459aba7-17c2-4cce-c8f1-cc9a66911e67"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  python3.7-lib2to3\n","The following NEW packages will be installed:\n","  python3.7-distutils python3.7-lib2to3\n","0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n","Need to get 309 kB of archives.\n","After this operation, 1,229 kB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.7-lib2to3 all 3.7.16-1+focal1 [122 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.7-distutils all 3.7.16-1+focal1 [187 kB]\n","Fetched 309 kB in 2s (173 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python3.7-lib2to3.\n","(Reading database ... 130486 files and directories currently installed.)\n","Preparing to unpack .../python3.7-lib2to3_3.7.16-1+focal1_all.deb ...\n","Unpacking python3.7-lib2to3 (3.7.16-1+focal1) ...\n","Selecting previously unselected package python3.7-distutils.\n","Preparing to unpack .../python3.7-distutils_3.7.16-1+focal1_all.deb ...\n","Unpacking python3.7-distutils (3.7.16-1+focal1) ...\n","Setting up python3.7-lib2to3 (3.7.16-1+focal1) ...\n","Setting up python3.7-distutils (3.7.16-1+focal1) ...\n"]}],"source":["!sudo apt install python3.7-distutils"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":353179,"status":"ok","timestamp":1674760955100,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"lH7O18INU4wp","outputId":"1c1b373f-8e35-423e-dc31-ee878a54546b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting argparse\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Collecting easydict\n","  Downloading easydict-1.10.tar.gz (6.4 kB)\n","Collecting h5py\n","  Downloading h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 38.2 MB/s \n","\u001b[?25hCollecting matplotlib\n","  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n","\u001b[K     |████████████████████████████████| 11.2 MB 68.5 MB/s \n","\u001b[?25hCollecting numpy\n","  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 134 kB/s \n","\u001b[?25hCollecting open3d\n","  Downloading open3d-0.13.0-cp37-cp37m-manylinux2014_x86_64.whl (300.6 MB)\n","\u001b[K     |████████████████████████████████| 300.6 MB 18 kB/s \n","\u001b[?25hCollecting opencv-python\n","  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n","\u001b[K     |████████████████████████████████| 61.8 MB 1.2 MB/s \n","\u001b[?25hCollecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 69.0 MB/s \n","\u001b[?25hCollecting scipy\n","  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n","\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 71.3 MB/s \n","\u001b[?25hCollecting timm==0.4.5\n","  Downloading timm-0.4.5-py3-none-any.whl (287 kB)\n","\u001b[K     |████████████████████████████████| 287 kB 45.8 MB/s \n","\u001b[?25hCollecting tqdm\n","  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 8.5 MB/s \n","\u001b[?25hCollecting transforms3d\n","  Downloading transforms3d-0.4.1.tar.gz (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 70.6 MB/s \n","\u001b[?25hCollecting termcolor\n","  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n","Collecting fonttools>=4.22.0\n","  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n","\u001b[K     |████████████████████████████████| 965 kB 66.1 MB/s \n","\u001b[?25hCollecting packaging>=20.0\n","  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.7 MB/s \n","\u001b[?25hCollecting kiwisolver>=1.0.1\n","  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 72.3 MB/s \n","\u001b[?25hCollecting pyparsing>=2.2.1\n","  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n","\u001b[K     |████████████████████████████████| 98 kB 9.6 MB/s \n","\u001b[?25hCollecting python-dateutil>=2.7\n","  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n","\u001b[K     |████████████████████████████████| 247 kB 73.8 MB/s \n","\u001b[?25hCollecting pillow>=6.2.0\n","  Downloading Pillow-9.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 63.6 MB/s \n","\u001b[?25hCollecting cycler>=0.10\n","  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n","Collecting wheel>=0.36.0\n","  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n","Collecting ipywidgets>=7.6.0\n","  Downloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n","\u001b[K     |████████████████████████████████| 137 kB 68.5 MB/s \n","\u001b[?25hCollecting pygments>=2.7.4\n","  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 63.6 MB/s \n","\u001b[?25hCollecting pandas>=1.0\n","  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n","\u001b[K     |████████████████████████████████| 11.3 MB 53.7 MB/s \n","\u001b[?25hCollecting jupyterlab==3.*,>=3.0.0\n","  Downloading jupyterlab-3.5.3-py3-none-any.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 44.5 MB/s \n","\u001b[?25hCollecting jupyter-packaging~=0.10\n","  Downloading jupyter_packaging-0.12.3-py3-none-any.whl (15 kB)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from open3d->-r requirements.txt (line 6)) (45.2.0)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Collecting scikit-learn>=0.21\n","  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","\u001b[K     |████████████████████████████████| 24.8 MB 1.5 MB/s \n","\u001b[?25hCollecting protobuf<=3.20.1,>=3.8.0\n","  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 53.6 MB/s \n","\u001b[?25hCollecting torchvision\n","  Downloading torchvision-0.14.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n","\u001b[K     |████████████████████████████████| 24.2 MB 1.4 MB/s \n","\u001b[?25hCollecting torch>=1.4\n","  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n","\u001b[K     |██████████████████████████████  | 834.1 MB 1.2 MB/s eta 0:00:44tcmalloc: large alloc 1147494400 bytes == 0x47f12000 @  0x7fee92ee3680 0x7fee92f03da2 0x5cc0a7 0x60fadc 0x4fb7c2 0x4df3b4 0x53ed1e 0x54124b 0x53f542 0x5c85f8 0x53ec54 0x5452cf 0x53f542 0x5c85f8 0x53ec54 0x541f6e 0x4dc244 0x541506 0x4dc244 0x541506 0x4dc244 0x541506 0x5c8454 0x53ec54 0x5411b6 0x53f542 0x5c85f8 0x53ec54 0x541f6e 0x53f542 0x5c85f8\n","\u001b[K     |████████████████████████████████| 887.5 MB 9.0 kB/s \n","\u001b[?25hCollecting typing-extensions; python_version < \"3.8\"\n","  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n","Collecting six>=1.5\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting widgetsnbextension~=4.0\n","  Downloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 49.3 MB/s \n","\u001b[?25hCollecting jupyterlab-widgets~=3.0\n","  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n","\u001b[K     |████████████████████████████████| 384 kB 62.2 MB/s \n","\u001b[?25hCollecting ipykernel>=4.5.1\n","  Downloading ipykernel-6.16.2-py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 77.5 MB/s \n","\u001b[?25hCollecting traitlets>=4.3.1\n","  Downloading traitlets-5.8.1-py3-none-any.whl (116 kB)\n","\u001b[K     |████████████████████████████████| 116 kB 67.2 MB/s \n","\u001b[?25hCollecting ipython>=6.1.0\n","  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n","\u001b[K     |████████████████████████████████| 793 kB 69.4 MB/s \n","\u001b[?25hCollecting pytz>=2017.3\n","  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n","\u001b[K     |████████████████████████████████| 499 kB 68.0 MB/s \n","\u001b[?25hCollecting tornado>=6.1.0\n","  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n","\u001b[K     |████████████████████████████████| 423 kB 73.9 MB/s \n","\u001b[?25hCollecting tomli\n","  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n","Collecting jinja2>=2.1\n","  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 73.6 MB/s \n","\u001b[?25hCollecting nbclassic\n","  Downloading nbclassic-0.5.1-py3-none-any.whl (10.0 MB)\n","\u001b[K     |████████████████████████████████| 10.0 MB 56.5 MB/s \n","\u001b[?25hCollecting jupyterlab-server~=2.10\n","  Downloading jupyterlab_server-2.19.0-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 5.5 MB/s \n","\u001b[?25hCollecting jupyter-server<3,>=1.16.0\n","  Downloading jupyter_server-1.23.5-py3-none-any.whl (346 kB)\n","\u001b[K     |████████████████████████████████| 346 kB 72.6 MB/s \n","\u001b[?25hCollecting notebook<7\n","  Downloading notebook-6.5.2-py3-none-any.whl (439 kB)\n","\u001b[K     |████████████████████████████████| 439 kB 68.3 MB/s \n","\u001b[?25hCollecting jupyter-core\n","  Downloading jupyter_core-4.12.0-py3-none-any.whl (89 kB)\n","\u001b[K     |████████████████████████████████| 89 kB 7.0 MB/s \n","\u001b[?25hCollecting tomlkit\n","  Downloading tomlkit-0.11.6-py3-none-any.whl (35 kB)\n","Collecting deprecation\n","  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n","Collecting joblib>=0.11\n","  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n","\u001b[K     |████████████████████████████████| 297 kB 71.7 MB/s \n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","Collecting requests\n","  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[K     |████████████████████████████████| 317.1 MB 35 kB/s \n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\"\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[K     |████████████████████████████████| 557.1 MB 12 kB/s \n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\"\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[K     |████████████████████████████████| 21.0 MB 16.1 MB/s \n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\"\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[K     |████████████████████████████████| 849 kB 54.0 MB/s \n","\u001b[?25hCollecting debugpy>=1.0\n","  Downloading debugpy-1.6.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 55.7 MB/s \n","\u001b[?25hCollecting matplotlib-inline>=0.1\n","  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n","Collecting pyzmq>=17\n","  Downloading pyzmq-25.0.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 60.2 MB/s \n","\u001b[?25hCollecting nest-asyncio\n","  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n","Collecting jupyter-client>=6.1.12\n","  Downloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 75.7 MB/s \n","\u001b[?25hCollecting psutil\n","  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n","\u001b[K     |████████████████████████████████| 280 kB 67.0 MB/s \n","\u001b[?25hCollecting decorator\n","  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n","Collecting pickleshare\n","  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n","Collecting backcall\n","  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n","Collecting pexpect>4.3; sys_platform != \"win32\"\n","  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 9.1 MB/s \n","\u001b[?25hCollecting jedi>=0.16\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 59.1 MB/s \n","\u001b[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n","\u001b[K     |████████████████████████████████| 386 kB 45.0 MB/s \n","\u001b[?25hCollecting MarkupSafe>=2.0\n","  Downloading MarkupSafe-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Collecting nbconvert>=5\n","  Downloading nbconvert-7.2.9-py3-none-any.whl (274 kB)\n","\u001b[K     |████████████████████████████████| 274 kB 68.4 MB/s \n","\u001b[?25hCollecting argon2-cffi\n","  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n","Collecting nbformat\n","  Downloading nbformat-5.7.3-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 8.8 MB/s \n","\u001b[?25hCollecting terminado>=0.8.3\n","  Downloading terminado-0.17.1-py3-none-any.whl (17 kB)\n","Collecting prometheus-client\n","  Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n","\u001b[K     |████████████████████████████████| 122 kB 63.5 MB/s \n","\u001b[?25hCollecting Send2Trash>=1.8.0\n","  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n","Collecting notebook-shim>=0.1.0\n","  Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n","Collecting ipython-genutils\n","  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n","Collecting babel>=2.10\n","  Downloading Babel-2.11.0-py3-none-any.whl (9.5 MB)\n","\u001b[K     |████████████████████████████████| 9.5 MB 58.0 MB/s \n","\u001b[?25hCollecting jsonschema>=4.17.3\n","  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 12.5 MB/s \n","\u001b[?25hCollecting importlib-metadata>=4.8.3; python_version < \"3.10\"\n","  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n","Collecting json5>=0.9.0\n","  Downloading json5-0.9.11-py2.py3-none-any.whl (19 kB)\n","Collecting websocket-client\n","  Downloading websocket_client-1.5.0-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 5.1 MB/s \n","\u001b[?25hCollecting anyio<4,>=3.1.0\n","  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 11.3 MB/s \n","\u001b[?25hCollecting idna<4,>=2.5\n","  Downloading idna-3.4-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 126 kB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 74.0 MB/s \n","\u001b[?25hCollecting charset-normalizer<4,>=2\n","  Downloading charset_normalizer-3.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170 kB)\n","\u001b[K     |████████████████████████████████| 170 kB 73.9 MB/s \n","\u001b[?25hCollecting certifi>=2017.4.17\n","  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n","\u001b[K     |████████████████████████████████| 155 kB 69.8 MB/s \n","\u001b[?25hCollecting entrypoints\n","  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n","Collecting ptyprocess>=0.5\n","  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n","Collecting parso<0.9.0,>=0.8.0\n","  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n","\u001b[K     |████████████████████████████████| 100 kB 12.9 MB/s \n","\u001b[?25hCollecting wcwidth\n","  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n","Collecting beautifulsoup4\n","  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n","\u001b[K     |████████████████████████████████| 128 kB 68.6 MB/s \n","\u001b[?25hCollecting defusedxml\n","  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n","Collecting mistune<3,>=2.0.3\n","  Downloading mistune-2.0.4-py2.py3-none-any.whl (24 kB)\n","Collecting tinycss2\n","  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n","Collecting pandocfilters>=1.4.1\n","  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n","Collecting jupyterlab-pygments\n","  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n","Collecting nbclient>=0.5.0\n","  Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\n","\u001b[K     |████████████████████████████████| 71 kB 413 kB/s \n","\u001b[?25hCollecting bleach\n","  Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 53.7 MB/s \n","\u001b[?25hCollecting argon2-cffi-bindings\n","  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.8 MB/s \n","\u001b[?25hCollecting fastjsonschema\n","  Downloading fastjsonschema-2.16.2-py3-none-any.whl (22 kB)\n","Collecting attrs>=17.4.0\n","  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 9.5 MB/s \n","\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n","  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 6.8 MB/s \n","\u001b[?25hCollecting pkgutil-resolve-name>=1.3.10; python_version < \"3.9\"\n","  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n","Collecting importlib-resources>=1.4.0; python_version < \"3.9\"\n","  Downloading importlib_resources-5.10.2-py3-none-any.whl (34 kB)\n","Collecting zipp>=0.5\n","  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\n","Collecting sniffio>=1.1\n","  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n","Collecting soupsieve>1.2\n","  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n","Collecting webencodings>=0.4\n","  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n","Collecting cffi>=1.0.1\n","  Downloading cffi-1.15.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n","\u001b[K     |████████████████████████████████| 427 kB 70.6 MB/s \n","\u001b[?25hCollecting pycparser\n","  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 67.8 MB/s \n","\u001b[?25hBuilding wheels for collected packages: easydict, transforms3d\n","  Building wheel for easydict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for easydict: filename=easydict-1.10-py3-none-any.whl size=6496 sha256=7a411fa2d588b50f199da85db90fab8d376f5576f7b68b5e50797b073db850e4\n","  Stored in directory: /root/.cache/pip/wheels/8d/d6/16/3fd964549d5c27d89d6c5fdb4306283ca55be1799f3d48a67b\n","  Building wheel for transforms3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transforms3d: filename=transforms3d-0.4.1-py3-none-any.whl size=1376754 sha256=8cf77af2132c01bebcacab13d3efa58bbb6dbdc32638ec9ba15f9817f142fd6b\n","  Stored in directory: /root/.cache/pip/wheels/cc/da/f5/b05c90f16d37764a65c010013110b15eab345f9c310d1bc16f\n","Successfully built easydict transforms3d\n","\u001b[31mERROR: jupyter-packaging 0.12.3 has requirement setuptools>=60.2.0, but you'll have setuptools 45.2.0 which is incompatible.\u001b[0m\n","Installing collected packages: argparse, easydict, numpy, h5py, fonttools, packaging, typing-extensions, kiwisolver, pyparsing, six, python-dateutil, pillow, cycler, matplotlib, wheel, tqdm, widgetsnbextension, jupyterlab-widgets, debugpy, traitlets, matplotlib-inline, decorator, pickleshare, backcall, ptyprocess, pexpect, parso, jedi, wcwidth, prompt-toolkit, pygments, ipython, pyzmq, nest-asyncio, tornado, jupyter-core, entrypoints, jupyter-client, psutil, ipykernel, ipywidgets, pyyaml, pytz, pandas, tomli, MarkupSafe, jinja2, Send2Trash, pycparser, cffi, argon2-cffi-bindings, argon2-cffi, soupsieve, beautifulsoup4, zipp, importlib-metadata, defusedxml, mistune, webencodings, tinycss2, pandocfilters, jupyterlab-pygments, fastjsonschema, attrs, pyrsistent, pkgutil-resolve-name, importlib-resources, jsonschema, nbformat, nbclient, bleach, nbconvert, terminado, websocket-client, idna, sniffio, anyio, prometheus-client, jupyter-server, notebook-shim, ipython-genutils, nbclassic, babel, json5, urllib3, charset-normalizer, certifi, requests, jupyterlab-server, notebook, jupyterlab, tomlkit, deprecation, jupyter-packaging, addict, scipy, joblib, threadpoolctl, scikit-learn, open3d, opencv-python, protobuf, tensorboardX, nvidia-cublas-cu11, nvidia-cudnn-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-runtime-cu11, torch, torchvision, timm, transforms3d, termcolor\n","  Attempting uninstall: wheel\n","    Found existing installation: wheel 0.34.2\n","    Not uninstalling wheel at /usr/lib/python3/dist-packages, outside environment /usr\n","    Can't uninstall 'wheel'. No files were found to uninstall.\n","Successfully installed MarkupSafe-2.1.2 Send2Trash-1.8.0 addict-2.4.0 anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 argparse-1.4.0 attrs-22.2.0 babel-2.11.0 backcall-0.2.0 beautifulsoup4-4.11.1 bleach-6.0.0 certifi-2022.12.7 cffi-1.15.1 charset-normalizer-3.0.1 cycler-0.11.0 debugpy-1.6.6 decorator-5.1.1 defusedxml-0.7.1 deprecation-2.1.0 easydict-1.10 entrypoints-0.4 fastjsonschema-2.16.2 fonttools-4.38.0 h5py-3.8.0 idna-3.4 importlib-metadata-6.0.0 importlib-resources-5.10.2 ipykernel-6.16.2 ipython-7.34.0 ipython-genutils-0.2.0 ipywidgets-8.0.4 jedi-0.18.2 jinja2-3.1.2 joblib-1.2.0 json5-0.9.11 jsonschema-4.17.3 jupyter-client-7.4.9 jupyter-core-4.12.0 jupyter-packaging-0.12.3 jupyter-server-1.23.5 jupyterlab-3.5.3 jupyterlab-pygments-0.2.2 jupyterlab-server-2.19.0 jupyterlab-widgets-3.0.5 kiwisolver-1.4.4 matplotlib-3.5.3 matplotlib-inline-0.1.6 mistune-2.0.4 nbclassic-0.5.1 nbclient-0.7.2 nbconvert-7.2.9 nbformat-5.7.3 nest-asyncio-1.5.6 notebook-6.5.2 notebook-shim-0.2.2 numpy-1.21.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 open3d-0.13.0 opencv-python-4.7.0.68 packaging-23.0 pandas-1.3.5 pandocfilters-1.5.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.4.0 pkgutil-resolve-name-1.3.10 prometheus-client-0.16.0 prompt-toolkit-3.0.36 protobuf-3.20.1 psutil-5.9.4 ptyprocess-0.7.0 pycparser-2.21 pygments-2.14.0 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 pytz-2022.7.1 pyyaml-6.0 pyzmq-25.0.0 requests-2.28.2 scikit-learn-1.0.2 scipy-1.7.3 six-1.16.0 sniffio-1.3.0 soupsieve-2.3.2.post1 tensorboardX-2.5.1 termcolor-2.2.0 terminado-0.17.1 threadpoolctl-3.1.0 timm-0.4.5 tinycss2-1.2.1 tomli-2.0.1 tomlkit-0.11.6 torch-1.13.1 torchvision-0.14.1 tornado-6.2 tqdm-4.64.1 traitlets-5.8.1 transforms3d-0.4.1 typing-extensions-4.4.0 urllib3-1.26.14 wcwidth-0.2.6 webencodings-0.5.1 websocket-client-1.5.0 wheel-0.38.4 widgetsnbextension-4.0.5 zipp-3.11.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","cffi","cycler","dateutil","ipython_genutils","kiwisolver","numpy","pexpect","pickleshare"]}}},"metadata":{},"output_type":"display_data"}],"source":["#installo i req\n","!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6992,"status":"ok","timestamp":1674760962086,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"uKvW9EPKyTDg","outputId":"032f6701-e38b-4972-d22b-255c500a7448"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l\r\u001b[K     |██▎                             | 10 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 20 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 30 kB 38.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 40 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 51 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 61 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 71 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 81 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 92 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 102 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 112 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 122 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 133 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 143 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 145 kB 34.7 MB/s \n","\u001b[?25h"]}],"source":["#POINT BERT REQuirements\n","!pip install Ninja --quiet\n","!pip install https://github.com/unlimblue/KNN_CUDA/releases/download/0.2/KNN_CUDA-0.2-py3-none-any.whl --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9076,"status":"ok","timestamp":1674760971155,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"cUndx3I_4v4a","outputId":"dc7044fe-10fd-491e-ea5b-f2bd45d5ba98"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/chamfer_dist\n","running install\n","running bdist_egg\n","running egg_info\n","writing chamfer.egg-info/PKG-INFO\n","writing dependency_links to chamfer.egg-info/dependency_links.txt\n","writing top-level names to chamfer.egg-info/top_level.txt\n","reading manifest file 'chamfer.egg-info/SOURCES.txt'\n","writing manifest file 'chamfer.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_ext\n","Traceback (most recent call last):\n","  File \"setup.py\", line 19, in <module>\n","    cmdclass={'build_ext': BuildExtension})\n","  File \"/usr/lib/python3/dist-packages/setuptools/__init__.py\", line 144, in setup\n","    return distutils.core.setup(**attrs)\n","  File \"/usr/lib/python3.7/distutils/core.py\", line 148, in setup\n","    dist.run_commands()\n","  File \"/usr/lib/python3.7/distutils/dist.py\", line 966, in run_commands\n","    self.run_command(cmd)\n","  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\n","    cmd_obj.run()\n","  File \"/usr/lib/python3/dist-packages/setuptools/command/install.py\", line 67, in run\n","    self.do_egg_install()\n","  File \"/usr/lib/python3/dist-packages/setuptools/command/install.py\", line 109, in do_egg_install\n","    self.run_command('bdist_egg')\n","  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\n","    self.distribution.run_command(command)\n","  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\n","    cmd_obj.run()\n","  File \"/usr/lib/python3/dist-packages/setuptools/command/bdist_egg.py\", line 172, in run\n","    cmd = self.call_command('install_lib', warn_dir=0)\n","  File \"/usr/lib/python3/dist-packages/setuptools/command/bdist_egg.py\", line 158, in call_command\n","    self.run_command(cmdname)\n","  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\n","    self.distribution.run_command(command)\n","  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\n","    cmd_obj.run()\n","  File \"/usr/lib/python3/dist-packages/setuptools/command/install_lib.py\", line 23, in run\n","    self.build()\n","  File \"/usr/lib/python3.7/distutils/command/install_lib.py\", line 109, in build\n","    self.run_command('build_ext')\n","  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\n","    self.distribution.run_command(command)\n","  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\n","    cmd_obj.run()\n","  File \"/usr/lib/python3/dist-packages/setuptools/command/build_ext.py\", line 87, in run\n","    _build_ext.run(self)\n","  File \"/usr/lib/python3.7/distutils/command/build_ext.py\", line 340, in run\n","    self.build_extensions()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py\", line 499, in build_extensions\n","    _check_cuda_version(compiler_name, compiler_version)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py\", line 386, in _check_cuda_version\n","    raise RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))\n","RuntimeError: \n","The detected CUDA version (11.2) mismatches the version that was used to compile\n","PyTorch (11.7). Please make sure to use the same CUDA versions.\n","\n"]}],"source":["%cd extensions/chamfer_dist/\n","!python setup.py install"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":133},"executionInfo":{"elapsed":11,"status":"error","timestamp":1674760971155,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"aGoVy5UFYcy8","outputId":"1f416897-e79b-4cbf-8835-26e62e3c08cf"},"outputs":[{"ename":"SyntaxError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-155d8d9e973c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    cd Point_BERT\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["#sposarsi nella cartella models\n","cd Point_BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1035,"status":"ok","timestamp":1674760994399,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"TTszofQQ25rf","outputId":"90f43675-eb09-4f27-f1c8-5a161a80a168"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions\n"]}],"source":["%cd /content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1674760995834,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"PgIzYVXKcqdT","outputId":"bc3fed02-b380-4b14-f206-3d9dc7cb30ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.7.16\n"]}],"source":["!python -V"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101272,"status":"ok","timestamp":1674760259803,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"1JyLvZSgbGRV","outputId":"1640aa91-bca8-4bee-c36d-d6b438354bf8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: torchvision 0.8.1\n","Uninstalling torchvision-0.8.1:\n","  Would remove:\n","    /usr/local/lib/python3.8/dist-packages/torchvision-0.8.1.dist-info/*\n","    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libcudart.459720b2.so.10.2\n","    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n","    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n","    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libz.1328edc3.so.1\n","    /usr/local/lib/python3.8/dist-packages/torchvision/*\n","Proceed (Y/n)? y\n","  Successfully uninstalled torchvision-0.8.1\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: torchaudio 0.8.1\n","Uninstalling torchaudio-0.8.1:\n","  Would remove:\n","    /usr/local/lib/python3.8/dist-packages/torchaudio-0.8.1.dist-info/*\n","    /usr/local/lib/python3.8/dist-packages/torchaudio/*\n","Proceed (Y/n)? y\n","  Successfully uninstalled torchaudio-0.8.1\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","timm 0.4.5 requires torchvision, which is not installed.\n","fastai 2.7.10 requires torchvision>=0.8.2, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m1.13.1+cu116\n","\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.8.1 requires torch==1.7.0, but you have torch 1.7.1 which is incompatible.\n","fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["#uninstall current version of packages\n","!pip uninstall torch torchvision torchtext torchaudio\n","\n","!pip install torch==1.7.0 --quiet\n","import torch\n","print(torch.__version__)\n","!pip install torchvision==0.8.1 --quiet\n","!pip install torchtext==0.8.1 --quiet\n","!pip install torchaudio==0.8.1 --quiet\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8622,"status":"ok","timestamp":1674758802683,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"i2jLZ4CG4szT","outputId":"31ef8407-82cf-4895-e81d-47c504fb072e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd\n","running install\n","running bdist_egg\n","running egg_info\n","writing emd_ext.egg-info/PKG-INFO\n","writing dependency_links to emd_ext.egg-info/dependency_links.txt\n","writing top-level names to emd_ext.egg-info/top_level.txt\n","writing manifest file 'emd_ext.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_ext\n","/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n","  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n","building 'emd_cuda' extension\n","Emitting ninja build file /content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/build/temp.linux-x86_64-3.8/build.ninja...\n","Compiling objects...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","[1/1] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/cuda/emd_kernel.cu -o /content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/build/temp.linux-x86_64-3.8/cuda/emd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=emd_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n","\u001b[31mFAILED: \u001b[0m/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/build/temp.linux-x86_64-3.8/cuda/emd_kernel.o \n","/usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c -c /content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/cuda/emd_kernel.cu -o /content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/build/temp.linux-x86_64-3.8/cuda/emd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O2 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=emd_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++14\n","/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/cuda/emd_kernel.cu(179): error: identifier \"CHECK_EQ\" is undefined\n","\n","/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/cuda/emd_kernel.cu(191): error: identifier \"THCudaCheck\" is undefined\n","\n","/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/cuda/emd_kernel.cu(266): error: identifier \"CHECK_EQ\" is undefined\n","\n","/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/cuda/emd_kernel.cu(277): error: identifier \"THCudaCheck\" is undefined\n","\n","/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/cuda/emd_kernel.cu(383): error: identifier \"CHECK_EQ\" is undefined\n","\n","/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/cuda/emd_kernel.cu(396): error: identifier \"THCudaCheck\" is undefined\n","\n","/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/cuda/emd_kernel.cu(401): error: explicit type is missing (\"int\" assumed)\n","\n","7 errors detected in the compilation of \"/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd/cuda/emd_kernel.cu\".\n","ninja: build stopped: subcommand failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 1900, in _run_ninja_build\n","    subprocess.run(\n","  File \"/usr/lib/python3.8/subprocess.py\", line 516, in run\n","    raise CalledProcessError(retcode, process.args,\n","subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"setup.py\", line 13, in <module>\n","    setup(\n","  File \"/usr/local/lib/python3.8/dist-packages/setuptools/__init__.py\", line 153, in setup\n","    return distutils.core.setup(**attrs)\n","  File \"/usr/lib/python3.8/distutils/core.py\", line 148, in setup\n","    dist.run_commands()\n","  File \"/usr/lib/python3.8/distutils/dist.py\", line 966, in run_commands\n","    self.run_command(cmd)\n","  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\n","    cmd_obj.run()\n","  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/install.py\", line 67, in run\n","    self.do_egg_install()\n","  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/install.py\", line 109, in do_egg_install\n","    self.run_command('bdist_egg')\n","  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\n","    self.distribution.run_command(command)\n","  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\n","    cmd_obj.run()\n","  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/bdist_egg.py\", line 164, in run\n","    cmd = self.call_command('install_lib', warn_dir=0)\n","  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/bdist_egg.py\", line 150, in call_command\n","    self.run_command(cmdname)\n","  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\n","    self.distribution.run_command(command)\n","  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\n","    cmd_obj.run()\n","  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/install_lib.py\", line 11, in run\n","    self.build()\n","  File \"/usr/lib/python3.8/distutils/command/install_lib.py\", line 109, in build\n","    self.run_command('build_ext')\n","  File \"/usr/lib/python3.8/distutils/cmd.py\", line 313, in run_command\n","    self.distribution.run_command(command)\n","  File \"/usr/lib/python3.8/distutils/dist.py\", line 985, in run_command\n","    cmd_obj.run()\n","  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/build_ext.py\", line 79, in run\n","    _build_ext.run(self)\n","  File \"/usr/local/lib/python3.8/dist-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n","    _build_ext.build_ext.run(self)\n","  File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 340, in run\n","    self.build_extensions()\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 843, in build_extensions\n","    build_ext.build_extensions(self)\n","  File \"/usr/local/lib/python3.8/dist-packages/Cython/Distutils/old_build_ext.py\", line 195, in build_extensions\n","    _build_ext.build_ext.build_extensions(self)\n","  File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 449, in build_extensions\n","    self._build_extensions_serial()\n","  File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 474, in _build_extensions_serial\n","    self.build_extension(ext)\n","  File \"/usr/local/lib/python3.8/dist-packages/setuptools/command/build_ext.py\", line 202, in build_extension\n","    _build_ext.build_extension(self, ext)\n","  File \"/usr/lib/python3.8/distutils/command/build_ext.py\", line 528, in build_extension\n","    objects = self.compiler.compile(sources,\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 658, in unix_wrap_ninja_compile\n","    _write_ninja_file_and_compile_objects(\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 1573, in _write_ninja_file_and_compile_objects\n","    _run_ninja_build(\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\", line 1916, in _run_ninja_build\n","    raise RuntimeError(message) from e\n","RuntimeError: Error compiling objects for extension\n"]}],"source":["#%cd ..\n","%cd /content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/extensions/emd\n","!python setup.py install"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1674757369541,"user":{"displayName":"Neural Networs","userId":"08057855560763417429"},"user_tz":-60},"id":"C0H0Qt1QUW_U","outputId":"f0c8a4b2-3ce9-4cac-8e6b-7c194c48bfc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 5, in <module>\n","    from pip._internal.cli.main import main\n","ModuleNotFoundError: No module named 'pip'\n"]}],"source":["!pip show torch"]},{"cell_type":"markdown","metadata":{"id":"MswvuXbQqY6C"},"source":["### IMPORT"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6831,"status":"ok","timestamp":1675562721619,"user":{"displayName":"Neural Networks","userId":"08057855560763417429"},"user_tz":-60},"id":"lrEhFdapTFi_"},"outputs":[],"source":["import argparse\n","import pytorch_lightning as pl\n","import torch\n","from torchvision import transforms\n","import numpy as np\n","import wandb\n","from lightly.loss.ntx_ent_loss import NTXentLoss\n","from torch.utils.data import DataLoader\n","#from datasets.data import ShapeNetRender, ModelNet40SVM\n","from drive.MyDrive.CrossPoint_Sapienza_NN_2023.util import IOStream, AverageMeter\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","#from models.dgcnn import DGCNN, ResNet, DGCNN_partseg\n","from torchvision.models import resnet50, resnet18\n","from torchvision.models import vit_l_16\n","#from models/pointbert/Point-BERT/models import Point_Bert\n","\n","#path management\n","import sys\n","\n","#cache pyton management\n","import imp\n","#for _init_() function to save checkpoints\n","import os\n","\n","from sklearn.svm import SVC"]},{"cell_type":"markdown","metadata":{"id":"RdF6O9INqz5B"},"source":["### CONSTANTS\n","❗❗❗❗ Change the name of the experiment when you do a training with different combination of models \n","\n","❗❗❗❗ Change the number of the start epoch\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":469,"status":"ok","timestamp":1675562843234,"user":{"displayName":"Neural Networks","userId":"08057855560763417429"},"user_tz":-60},"id":"h_klQtp2q3j9"},"outputs":[],"source":["#COSTANTI\n","exp_name = 'PCT+VisionTransformer' # Name of the experiment\n","model_point = 'pct' # Model to use, [dgcnn, pct]\n","model_img = 'visiontransformer' # Model to use for images feature extraction, [resnet, visiontrasformer]\n","batch_size = 5 # (Size of training batch)\n","val_batch_size = 2 # (Size of validation batch)\n","test_batch_size = 2 # (Size of testing batch)\n","epochs = 100 # number of episode to train\n","start_epoch = 0  # number of episode to train\n","use_sgd = False # Use SGD\n","lr = 0.001 # learning rate (default: 0.001, 0.1 if using sgd)\n","momentum = 0.9 # SGD momentum (default: 0.9)\n","no_cuda = False # enables CUDA training\n","seed = 1 # random seed (default: 1)'\n","evalu = False # evaluate the model\n","num_points = 2048 # num of points to use\n","dropout = 0.5 # dropout rate\n","emb_dims = 1024 # Dimension of embeddings\n","k = 20 # Num of nearest neighbors to use\n","resume = False  # resume from checkpoint\n","model_path = '' # Pretrained point model path.   #/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints/nomeexp/\n","#model_img_path = '' # Pretrained img model path.   #/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints/nomeexp/\n","save_freq = 2 # save frequency\n","print_freq = 50 # print frequency\n","enable_wandb = True # enables wandb\n","spct_model_path = \"/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/naive_pct.t7\"\n","\n","#use a dictionary\n","args = {\n","    'exp_name': exp_name,\n","    'model_point': model_point,\n","    'model_img': model_img,\n","    'batch_size': batch_size,\n","    'val_batch_size' : val_batch_size,\n","    'test_batch_size': test_batch_size,\n","    'epochs': epochs,\n","    'start_epoch': start_epoch,\n","    'use_sgd': use_sgd,\n","    'lr': lr,\n","    'momentum': momentum,\n","    'no_cuda': no_cuda,\n","    'seed': seed,\n","    'evalu': evalu,\n","    'num_points': num_points,\n","    'dropout': dropout,\n","    'emb_dims': emb_dims,\n","    'k': k,\n","    'resume': resume,\n","    'model_path': model_path,\n","    #'model_img_path': model_img_path,\n","    'save_freq': save_freq,\n","    'print_freq': print_freq,\n","    'enable_wandb': enable_wandb,\n","    'spct_model_path': spct_model_path\n","}\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"g71fP8BIp0Jj"},"source":["### FUNCTIONS ⏩⏩⏩"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1675562733230,"user":{"displayName":"Neural Networks","userId":"08057855560763417429"},"user_tz":-60},"id":"cpk2j28opdiU"},"outputs":[],"source":["def check_checkpoint_folders(): \n","  if not os.path.exists('/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints'):\n","        os.makedirs('/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints')\n","  if not os.path.exists('/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints/'+ args['exp_name']):\n","      os.makedirs('/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints/'+ args['exp_name'])\n","  if not os.path.exists('/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints/'+args['exp_name']+'/'+'models'):\n","      os.makedirs('/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints/'+args['exp_name']+'/'+'models')\n","\n","def knn(x, k):\n","    inner = -2*torch.matmul(x.transpose(2, 1), x)\n","    xx = torch.sum(x**2, dim=1, keepdim=True)\n","    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n"," \n","    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k)\n","    return idx\n","\n","\n","def get_graph_feature(x, k=20, idx=None):\n","    batch_size = x.size(0)\n","    num_points = x.size(2)\n","    x = x.view(batch_size, -1, num_points)\n","    if idx is None:\n","        idx = knn(x, k=k)   # (batch_size, num_points, k)\n","\n","    \n","    #Mio commento----\n","    #device = torch.device('cuda:1')\n","    #----\n","    # if (torch.cuda.is_available()):\n","    #     device = torch.device(\"cuda\")\n","    # else:\n","    #     device = torch.device(\"cpu\")\n","    #------\n","    device = torch.cuda.current_device()\n","\n","    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n","    idx = idx.to(device)\n","    idx = idx + idx_base\n","\n","    idx = idx.view(-1)\n"," \n","    _, num_dims, _ = x.size()\n","\n","    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\n","    #batch_size = batch_size.to(device)\n","    #num_points = num_points.to(device)\n","\n","    x = x.to(device)\n","    idx = idx.to(device)\n","\n","    feature = x.view(batch_size*num_points, -1)[idx, :]\n","    feature = feature.view(batch_size, num_points, k, num_dims) \n","    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n","    \n","    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n","  \n","    return feature\n"]},{"cell_type":"markdown","metadata":{"id":"VI2q7To7pu-S"},"source":["### DGCNN 🔗"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9H2fbfCbptea"},"outputs":[],"source":["class DGCNN(pl.LightningModule):\n","    def __init__(self, args, cls = -1) -> None:\n","        super(DGCNN,self).__init__()\n","        self.k = args['k']\n","\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.bn4 = nn.BatchNorm2d(256)\n","        self.bn5 = nn.BatchNorm1d(args['emb_dims'])\n","\n","        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),self.bn1, nn.LeakyReLU(negative_slope=0.2))\n","        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),self.bn2,nn.LeakyReLU(negative_slope=0.2))\n","        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),self.bn3,nn.LeakyReLU(negative_slope=0.2))\n","        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False), self.bn4, nn.LeakyReLU(negative_slope=0.2))\n","        self.conv5 = nn.Sequential(nn.Conv1d(512, args['emb_dims'], kernel_size=1, bias=False), self.bn5, nn.LeakyReLU(negative_slope=0.2))\n","\n","        if cls != -1:\n","            self.linear1 = nn.Linear(args['emb_dims']*2, 512, bias=False)\n","            self.bn6 = nn.BatchNorm1d(512)\n","            self.dp1 = nn.Dropout(p=args['dropout'])\n","            self.linear2 = nn.Linear(512, 256)\n","            self.bn7 = nn.BatchNorm1d(256)\n","            self.dp2 = nn.Dropout(p=args['dropout'])\n","            self.linear3 = nn.Linear(256, output_channels)\n","        \n","        self.cls = cls\n","\n","        self.inv_head = nn.Sequential(\n","              nn.Linear(args['emb_dims'] * 2, args['emb_dims']),\n","              nn.BatchNorm1d(args['emb_dims']),\n","              nn.ReLU(inplace=True),\n","              nn.Linear(args['emb_dims'], 256)\n","          )\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = get_graph_feature(x, k=self.k)\n","        print(\"x ->\"+str(x.shape))\n","        x = self.conv1(x)\n","        print(\"x conv 1 ->\"+str(x.shape))\n","        x1 = x.max(dim=-1, keepdim=False)[0]\n","        print(\"x1 ->\"+str(x1.shape))\n","\n","\n","        x = get_graph_feature(x1, k=self.k)\n","        print(\"x ->\"+str(x.shape))\n","        x = self.conv2(x)\n","        print(\"x conv 2 ->\"+str(x.shape))\n","        x2 = x.max(dim=-1, keepdim=False)[0]\n","        print(\"x2 ->\"+str(x2.shape))\n","\n","        x = get_graph_feature(x2, k=self.k)\n","        print(\"x ->\"+str(x.shape))\n","        x = self.conv3(x)\n","        print(\"x conv 3 ->\"+str(x.shape))\n","        x3 = x.max(dim=-1, keepdim=False)[0]\n","        print(\"x3 ->\"+str(x3.shape))\n","\n","        x = get_graph_feature(x3, k=self.k)\n","        print(\"x ->\"+str(x.shape))\n","        x = self.conv4(x)\n","        print(\"x conv 4 ->\"+str(x.shape))\n","        x4 = x.max(dim=-1, keepdim=False)[0]\n","        print(\"x4 ->\"+str(x4.shape))\n","\n","        x = torch.cat((x1, x2, x3, x4), dim=1)\n","        print(\"x cat->\"+str(x.shape))\n","\n","\n","        x = self.conv5(x)\n","        print(\"x conv 5 ->\"+str(x.shape))\n","        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n","        print(\"x1 ->\"+str(x1.shape))\n","        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)\n","        print(\"x2 ->\"+str(x2.shape))\n","        x = torch.cat((x1, x2), 1)\n","        print(\"x ->\"+str(x.shape))\n","\n","        \n","        feat = x\n","        if self.cls != -1:\n","            x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2)\n","            x = self.dp1(x)\n","            x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2)\n","            x = self.dp2(x)\n","            x = self.linear3(x)\n","        \n","        inv_feat = self.inv_head(feat)\n","        print(\"inv_feat ->\"+str(inv_feat.shape))\n","\n","        \n","        return x, inv_feat, feat \n","\n"]},{"cell_type":"markdown","metadata":{"id":"jN5esaF3p5cS"},"source":["### RESNET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qSZ0BNqTp6EY"},"outputs":[],"source":["class ResNet(pl.LightningModule):\n","    def __init__(self, model, feat_dim = 2048):\n","        super(ResNet, self).__init__()\n","        self.resnet = model\n","        self.resnet.fc = nn.Identity()\n","        \n","        self.inv_head = nn.Sequential(\n","                            nn.Linear(feat_dim, 512, bias = False),\n","                            nn.BatchNorm1d(512),\n","                            nn.ReLU(inplace=True),\n","                            nn.Linear(512, 256, bias = False)\n","                            ) \n","        \n","    def forward(self, x):\n","        x = self.resnet(x)\n","        #print(\"SHAPE DI X in RESNET ---->\",x.shape) # (batchsize x 2048)\n","        x = self.inv_head(x)\n","        \n","        return x"]},{"cell_type":"markdown","metadata":{"id":"Bc0lqOkTqIQ7"},"source":["### VISION TRANSFORMER 🎉🎉🎉"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yRJoU3C1qM9r"},"outputs":[],"source":["class VisionTransformer(pl.LightningModule):\n","    def __init__(self, model, feat_dim = 1000):\n","        super(VisionTransformer, self).__init__()\n","        self.vision_transformer = model\n","        self.vision_transformer.output_hidden_states = True\n","        \n","        self.inv_head = nn.Sequential(\n","                            nn.Linear(feat_dim, 512, bias = False),\n","                            nn.BatchNorm1d(512),\n","                            nn.ReLU(inplace=True),\n","                            nn.Linear(512, 256, bias = False)\n","                            ) \n","        \n","    def forward(self, x):\n","        x = self.vision_transformer(x) #get output of hidden states\n","        #print(\"SHAPE DI X in ViT ---->\",x.shape) # (batchsize, numclasses) -> (2,1000)\n","        #x = x[:, 0, :]\n","        x = self.inv_head(x)\n","        \n","        return x"]},{"cell_type":"markdown","metadata":{"id":"vGkdq9qMqN6g"},"source":[]},{"cell_type":"markdown","metadata":{"id":"nb6iWR5aH55d"},"source":["### Vision Transformer V2"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1675562721620,"user":{"displayName":"Neural Networks","userId":"08057855560763417429"},"user_tz":-60},"id":"ou96Blm4H5EE"},"outputs":[],"source":["import torchvision.models as models\n","class VisionTransformer(pl.LightningModule):\n","    def __init__(self, model, feat_dim = 1000):\n","        super(VisionTransformer, self).__init__()\n","        self.vision_transformer = model\n","\n","        for param in self.vision_transformer.parameters():\n","            param.requires_grad = False\n","\n","        self.inv_head = nn.Sequential(\n","            nn.Linear(feat_dim, 512, bias=False),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(512, 256, bias=False)\n","        )\n","        \n","    def forward(self, x):\n","        x = self.vision_transformer(x) #get output of hidden states\n","        #print(\"SHAPE DI X in ViT ---->\",x.shape) # (batchsize, numclasses) -> (2,1000)\n","        #x = x[:, 0, :]\n","        x = self.inv_head(x)\n","        \n","        return x"]},{"cell_type":"markdown","metadata":{"id":"Ls9dXASggzhn"},"source":["### PointCloudTransformer (Naive)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1675562721620,"user":{"displayName":"Neural Networks","userId":"08057855560763417429"},"user_tz":-60},"id":"x_eMhHkogbiG"},"outputs":[],"source":["import math\n","def messingWithKeys():\n","  state_dict = torch.load(args['spct_model_path'])\n","  point_model = Pct()\n","\n","  new_state_dict = {}\n","  not_desired_keys = [\"module.cls.linear1.weight\", \"module.cls.linear2.weight\", \"module.cls.linear2.bias\", \"module.cls.bn1.weight\", \"module.cls.bn1.bias\", \"module.cls.bn1.running_mean\", \"module.cls.bn1.running_var\", \"module.cls.bn1.num_batches_tracked\", \"module.cls.bn2.weight\", \"module.cls.bn2.bias\", \"module.cls.bn2.running_mean\", \"module.cls.bn2.running_var\", \"module.cls.bn2.num_batches_tracked\"]\n","  for k, v in state_dict.items():\n","      if k not in not_desired_keys:\n","        new_k = k.replace(\"module.encoder.\", \"\")\n","        new_state_dict[new_k] = v\n","\n","  point_model.load_state_dict(new_state_dict)\n","  return point_model\n","\n","class Embedding(nn.Module):\n","    \"\"\"\n","    Input Embedding layer which consist of 2 stacked LBR layer.\n","    \"\"\"\n","\n","    def __init__(self, in_channels=3, out_channels=128):\n","        super(Embedding, self).__init__()\n","\n","        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False)\n","        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=1, bias=False)\n","\n","        self.bn1 = nn.BatchNorm1d(out_channels)\n","        self.bn2 = nn.BatchNorm1d(out_channels)\n","    \n","    def forward(self, x):\n","        \"\"\"\n","        Input\n","            x: [B, in_channels, N]\n","        \n","        Output\n","            x: [B, out_channels, N]\n","        \"\"\"\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        return x\n","\n","\n","class SA(nn.Module):\n","    \"\"\"\n","    Self Attention module.\n","    \"\"\"\n","\n","    def __init__(self, channels):\n","        super(SA, self).__init__()\n","\n","        self.da = channels // 4\n","\n","        self.q_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n","        self.k_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n","        self.q_conv.weight = self.k_conv.weight\n","        self.v_conv = nn.Conv1d(channels, channels, 1)\n","        \n","        self.trans_conv = nn.Conv1d(channels, channels, 1)\n","        self.after_norm = nn.BatchNorm1d(channels)\n","        \n","        self.act = nn.ReLU()\n","        self.softmax = nn.Softmax(dim=-1)\n","    \n","    def forward(self, x):\n","        \"\"\"\n","        Input\n","            x: [B, de, N]\n","        \n","        Output\n","            x: [B, de, N]\n","        \"\"\"\n","        # compute query, key and value matrix\n","        x_q = self.q_conv(x).permute(0, 2, 1)  # [B, N, da]\n","        x_k = self.k_conv(x)                   # [B, da, N]        \n","        x_v = self.v_conv(x)                   # [B, de, N]\n","\n","        # compute attention map and scale, the sorfmax\n","        energy = torch.bmm(x_q, x_k) / (math.sqrt(self.da))   # [B, N, N]\n","        attention = self.softmax(energy)                      # [B, N, N]\n","\n","        # weighted sum\n","        x_s = torch.bmm(x_v, attention)  # [B, de, N]\n","        x_s = self.act(self.after_norm(self.trans_conv(x_s)))\n","        \n","        # residual\n","        x = x + x_s\n","\n","        return x\n","\n","class Pct(pl.LightningModule):\n","    def __init__(self,args):\n","        super().__init__()\n","        self.args = args \n","\n","        self.embedding = Embedding(3, 128)\n","\n","        self.sa1 = SA(128)\n","        self.sa2 = SA(128)\n","        self.sa3 = SA(128)\n","        self.sa4 = SA(128)\n","\n","        self.linear = nn.Sequential(\n","            nn.Conv1d(512, 1024, kernel_size=1, bias=False),\n","            nn.BatchNorm1d(1024),\n","            nn.LeakyReLU(negative_slope=0.2)\n","        )\n","\n","        self.inv_head = nn.Sequential(\n","              nn.Linear(args['emb_dims'] * 2, args['emb_dims']),\n","              nn.BatchNorm1d(args['emb_dims']),\n","              nn.ReLU(inplace=True),\n","              nn.Linear(args['emb_dims'], 256)\n","          )\n","\n","       \n","    def forward(self, x):\n","        batch_size = x.size(0)\n","\n","        x = self.embedding(x) #x shape->torch.Size([2bs, 3, 2048])\n","        \n","        x1 = self.sa1(x) #x1 shape->torch.Size([2bs, 128, 2048])\n","        x2 = self.sa2(x1) #x2 shape->torch.Size([2bs, 128, 2048])\n","        x3 = self.sa3(x2) #x3 shape->torch.Size([2bs, 128, 2048])\n","        x4 = self.sa4(x3) #x4 shape->torch.Size([2bs, 128, 2048])\n","        x = torch.cat([x1, x2, x3, x4], dim=1) #x shape after cat->torch.Size([10, 512, 2048])\n","\n","        x = self.linear(x) #x shape after linear->torch.Size([10, 1024, 2048])\n","    \n","\n","        # x = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n","        \n","        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1) # 2bs,1024\n","        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1) # 2bs,1024\n","        x = torch.cat((x1, x2), 1) # 2bs,2048\n","        feat = x\n","        inv_feat = self.inv_head(feat) # torch.Size([2bs, 256])\n","\n","        x_max = torch.max(x, dim=-1)[0]\n","        x_mean = torch.mean(x, dim=-1)\n","\n","        return inv_feat, x_max, x_mean, feat\n"]},{"cell_type":"markdown","metadata":{"id":"z-fAdvM-_rQu"},"source":["### ⚡️⚡️⚡️⚡️⚡️⚡️⚡️⚡️ CROSSPOINT LIGHTNING (the lightning module). ⚡️⚡️⚡️⚡️⚡️⚡️⚡️⚡️"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1675562738050,"user":{"displayName":"Neural Networks","userId":"08057855560763417429"},"user_tz":-60},"id":"nKYl2vm8DwL9"},"outputs":[],"source":["class CrosspointLightning (pl.LightningModule):\n","    def __init__(self, args):\n","        super().__init__()\n","        self.args = args\n","        self.best_acc = 0\n","        \n","        if self.args['enable_wandb'] == True:\n","          self.wandb_log = {}\n","\n","\n","        print(\"Init CrosspointLightning v4\")\n","        \n","        \n","        # ------------\n","        # models\n","        # ------------\n","        if args['model_point'] == 'dgcnn':\n","            self.point_model = DGCNN(args) # forse aggiungere .to(device) ?\n","        elif args['model_point'] == 'pct':\n","            #import spct from path\n","            #self.point_model = messingWithKeys()\n","\n","\n","            #import for train pct\n","            self.point_model = Pct(args)\n","        elif args['model_point'] == 'dgcnn_seg':\n","            self.point_model = DGCNN_partseg(args) #todo in lightning # forse aggiungere .to(device) ?\n","        elif args['model_point'] == 'pointbert':\n","           raise Exception(\"@Deprecated PointBert\")            \n","        else:\n","            raise Exception(\"Not implemented\")\n","\n","        if args['model_img'] == 'resnet':\n","            self.img_model = ResNet(resnet50(), feat_dim = 2048) \n","        elif args['model_img'] == 'visiontransformer':\n","            self.img_model = VisionTransformer(vit_l_16(), feat_dim = 1000) \n","        else:\n","            raise Exception(\"Not implemented\")\n","\n","        \n","        self.criterion = NTXentLoss(temperature = 0.1)\n","\n","        if args['enable_wandb'] == True:\n","            wandb.watch(self.point_model)\n","\n","        if args['resume']:\n","            # self.point_model = self.point_model.load_state_dict(torch.load(args['model_point_path']))\n","            # self.img_model = self.img_model.load_state_dict(torch.load(args['model_img_path']))\n","            model.load_state_dict(torch.load(args['model_path']))\n","            print(\"Model Loaded !!\")\n","\n","    def on_train_epoch_start(self):\n","        print(\"Starting epoch ->\",self.current_epoch,\" (training)\")\n","        self.train_losses = AverageMeter()\n","        self.train_imid_losses = AverageMeter()\n","        self.train_cmid_losses = AverageMeter()\n","\n","        \n","        self.point_model.train()\n","        self.img_model.train()\n","\n","    def on_train_epoch_end(self):\n","      if self.args['enable_wandb'] == True:\n","          self.wandb_log['Train Loss'] = self.train_losses.avg\n","          self.wandb_log['Train IMID Loss'] = self.train_imid_losses.avg\n","          self.wandb_log['Train CMID Loss'] = self.train_cmid_losses.avg\n","      print(\"Ending epoch ->\",self.current_epoch,\" (training)\")     \n","      outstr = 'Training %d, loss: %.6f' % (self.current_epoch, self.train_losses.avg)\n","      self.custom_validation_step(self.args)\n","      io.cprint(outstr)  \n","        \n","    def training_step(self, batch, batch_idx):\n","        # if per skippare le epoche \n","        # if self.current_epoch <= self.args['start_epoch']:\n","        #     return 0\n","\n","        (data_t1 ,data_t2), imgs = batch\n","        batch_size = data_t1.size()[0]\n","\n","        if args['model_point'] == 'dgcnn' or args['model_point'] == 'dgcnn_seg':\n","            data = torch.cat((data_t1, data_t2)) #data_t1,data_t2 shape -> [bs,2048,3]\n","            #data shape -> [2bs,2048,3]\n","            data = data.transpose(2, 1).contiguous() #data shape after transpose-> [2bs,3,2048]\n","            _, point_feats, _ = self.point_model(data) #point_feats shape-> [2bs,256]\n","            point_t1_feats = point_feats[:batch_size, :] #point_t1_feats shape-> [bs,256]\n","            point_t2_feats = point_feats[batch_size: , :] #point_t2_feats shape-> [bs,256]\n","\n","            loss_imid = self.criterion(point_t1_feats, point_t2_feats)        \n","            point_feats = torch.stack([point_t1_feats,point_t2_feats]).mean(dim=0) #point_feats after mean shape-> [bs,256]\n","        elif args['model_point'] == 'pct':\n","            data = torch.cat((data_t1, data_t2)) #data shape -> [2bs,2048,3]\n","            data = data.transpose(2, 1).contiguous() #data shape after transpose-> [2bs,3,2048]\n","            embbedded_x, _, _, _  = self.point_model(data) \n","            point_t1_feats = embbedded_x[:batch_size, :]\n","            point_t2_feats = embbedded_x[batch_size: , :]\n","            loss_imid = self.criterion(point_t1_feats, point_t2_feats)        \n","            point_feats = torch.stack([point_t1_feats,point_t2_feats]).mean(dim=0)\n","        else:\n","            raise Exception(\"Not implemented\")\n","        \n","        img_feats = self.img_model(imgs) #imgs_feats shape->[5,256]\n","        \n","        loss_cmid = self.criterion(point_feats, img_feats)\n","\n","        total_loss = loss_imid + loss_cmid\n","        \n","        if self.args['enable_wandb'] == True:\n","          self.wandb_log['Total train loss'+args['exp_name']] = total_loss\n","          self.wandb_log['Imid loss'+args['exp_name']] = loss_imid\n","          self.wandb_log['Cmid loss'+args['exp_name']] = loss_cmid\n","          wandb.log(self.wandb_log)\n","\n","        if batch_idx % self.args['print_freq'] == 0:\n","                print('Epoch (%d), Batch(%d/%d), loss: %.6f, imid loss: %.6f, cmid loss: %.6f ' % (self.current_epoch, batch_idx, self.args['train_loader_len'], total_loss, loss_imid, loss_cmid))\n","        \n","        self.train_losses.update(total_loss.item(), batch_size)\n","        self.train_imid_losses.update(loss_imid.item(), batch_size)\n","        self.train_cmid_losses.update(loss_cmid.item(), batch_size)\n","        \n","        return total_loss\n","              \n","    def forward(self, x):\n","        return x\n","\n","    def custom_validation_step(self,args):\n","      print(\"Starting epoch \",self.current_epoch,\" (validation_epoch_start)\")\n","      self.train_val_loader = DataLoader(ModelNet40SVM(partition='train', num_points=1024),num_workers=12, batch_size=5, shuffle=True)\n","      self.test_val_loader = DataLoader(ModelNet40SVM(partition='test', num_points=1024),num_workers=12, batch_size=2, shuffle=True)\n","\n","      feats_train = []\n","      labels_train = []\n","\n","      self.point_model.eval()\n","\n","      print(\"Starting epoch \",self.current_epoch,\" (validation_step)\")\n","      if torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","      else: device = torch.device('cpu')\n","\n","      for i, (data, label) in enumerate(self.train_val_loader):\n","            labels = list(map(lambda x: x[0],label.numpy().tolist()))\n","            data = data.permute(0, 2, 1)\n","            data = data.to(device)\n","            \n","            with torch.no_grad():\n","                if self.args['model_point'] == 'dgcnn':\n","                  feats = self.point_model(data)[2]\n","                elif self.args['model_point'] == 'pct':\n","                  feats = self.point_model(data)[3]\n","                else:\n","                  raise (\"Not implemented\")\n","\n","            feats = feats.detach().cpu().numpy()\n","            for feat in feats:\n","                feats_train.append(feat)\n","            labels_train += labels\n","\n","      feats_train = np.array(feats_train)\n","      labels_train = np.array(labels_train)\n","\n","      feats_test = []\n","      labels_test = []\n","\n","      for i, (data, label) in enumerate(self.test_val_loader):\n","          labels = list(map(lambda x: x[0],label.numpy().tolist()))\n","          data = data.permute(0, 2, 1)\n","          data = data.to(device)\n","\n","          with torch.no_grad():\n","              if self.args['model_point'] == 'dgcnn':\n","                feats = self.point_model(data)[2]\n","              elif self.args['model_point'] == 'pct':\n","                feats = self.point_model(data)[3]\n","              else:\n","                  raise (\"Not implemented\")\n","\n","          feats = feats.detach().cpu().numpy()\n","          for feat in feats:\n","              feats_test.append(feat)\n","          labels_test += labels\n","\n","      feats_test = np.array(feats_test)\n","      labels_test = np.array(labels_test)\n","      \n","      model_tl = SVC(C = 0.1, kernel ='linear')\n","      model_tl.fit(feats_train, labels_train)\n","      test_accuracy = model_tl.score(feats_test, labels_test)\n","\n","      if args['enable_wandb'] == True:\n","        self.wandb_log['Linear Accuracy'] = test_accuracy\n","      \n","      print(f\"Linear Accuracy : {test_accuracy}\")\n","      \n","      if test_accuracy > self.best_acc:\n","          self.best_acc = test_accuracy\n","          print('==> NEW RECORD on accuracy on epoch ',self.current_epoch,' --- Accuracy = ',test_accuracy,' ----> SAVING Best Model...')\n","          file_name = 'best_model'+self.args['model_point']+'.pth'\n","          save_file = os.path.join('/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints/' + self.args['exp_name'] + '/models/', file_name.format(epoch=self.current_epoch) )\n","          torch.save(self.point_model.state_dict(), save_file)\n","          \n","\n","          file_name = 'best_model'+self.args['model_img']+'.pth'\n","          save_img_model_file = os.path.join('/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints/' + self.args['exp_name'] + '/models/', 'img_model_best'+self.args['model_img']+'.pth' )\n","          torch.save(self.img_model.state_dict(), save_img_model_file)\n","\n","      if self.current_epoch % self.args['save_freq'] == 0:\n","          print('==> Saving for frequency...')\n","          save_file = os.path.join(f'/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints/{self.args[\"exp_name\"]}/models/','ckpt_epoch_{'+str(self.current_epoch)+'}'+self.args['model_point']+'.pth'.format(epoch=self.current_epoch))\n","          torch.save(self.point_model.state_dict(), save_file)\n","\n","      if args['enable_wandb'] == True:\n","        wandb.log(self.wandb_log)\n","\n","      return {'val_acc': test_accuracy}\n","\n","\n","    def configure_optimizers(self):\n","        parameters = list(self.point_model.parameters()) + list(self.img_model.parameters())\n","        \n","        # ------------\n","        # optimizer\n","        # ------------\n","        if args['use_sgd']:\n","            print(\"Use SGD\")\n","            optimizer = torch.optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'], weight_decay=1e-6)\n","        else:\n","            print(\"Use Adam\")\n","            optimizer = torch.optim.Adam(parameters, lr=args['lr'], weight_decay=1e-6)\n","        \n","        # ------------\n","        # scheduler\n","        # ------------\n","        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args['epochs'], eta_min=0, last_epoch=-1)\n","\n","\n","        return [optimizer], [lr_scheduler]"]},{"cell_type":"markdown","metadata":{"id":"Z_yVOvUsEmbd"},"source":["### THE TRAIN FUNCTION 🎉🎉🎉🎉"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1675562742117,"user":{"displayName":"Neural Networks","userId":"08057855560763417429"},"user_tz":-60},"id":"HSbTucjWEpLM"},"outputs":[],"source":["def train(args,io):\n","\n","    if args['enable_wandb'] == True:\n","        print('Wandb Enabled')\n","        wandb.init(project=\"CrossPoint\", name=args['exp_name'])\n","\n","    \n","    # ------------\n","    # data\n","    # ------------\n","    transform = transforms.Compose([transforms.Resize((224, 224)),\n","                                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n","                                transforms.RandomHorizontalFlip(),\n","                                transforms.ToTensor(), \n","                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","    \n","    train_loader = DataLoader(ShapeNetRender(transform, n_imgs = 2), num_workers=12, batch_size=args['batch_size'], shuffle=True, drop_last=True)\n","    args['train_loader_len'] = len(train_loader)\n","    # device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","     \n","    # ------------\n","    # model\n","    # ------------\n","    model = CrosspointLightning(args)\n","    \n","    # ------------\n","    # training\n","    # ------------\n","    parsed_args = argparse.Namespace(**args)\n","    \n","    trainer = pl.Trainer.from_argparse_args(parsed_args,max_epochs=args['epochs'],accelerator='gpu') #??? devices = 1 ???\n","    \n","    trainer.fit(model, train_loader)"]},{"cell_type":"markdown","metadata":{"id":"6ytk1eAjELJs"},"source":["### 🚀🚀🚀🚀 THE MAIN FUNCTION 🚀🚀🚀🚀"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9d61e858c872444fb136f2e252304b7b","9499781c1e244cffae40f46c5b054a1e","fc2e5618be574c92bf9080bf128ac0c6","6057521411c944fc8bfe40db1b61f9bb","74630514a4ef432e89286059fc550c1d","7e88433848394b11b02bc536a0d049f5","35df70bedbb8479db5736c86c0f5b481","0f0af6de4aa7405ea79f2058f15dc62d","c591daf894834208894cc662f7427692","444e3ea07fac49d7b200be511a83e6a5","e5cbe3c7cc5349ca8ac71d2fe46f1458","f0c77a7856184aaf86af04bd98681bbd","3d5f76bf51e54f29b3e21792ccd9c0f6","0c0a889bc775441b97c0fd9547e1f985","05eb21e578d449b6bc21c0fecfbb93c6","4cf574578d4249e796faa249bbe91df2","4c8115b14564473689b0010fd0a78214","1645d670966546409357466519f81a9d","85473093b6e44a1d97d5b034ba23ad25"]},"executionInfo":{"elapsed":34271551,"status":"ok","timestamp":1675597118133,"user":{"displayName":"Neural Networks","userId":"08057855560763417429"},"user_tz":-60},"id":"i20ZRMhkrvLx","outputId":"70724408-03b7-431c-8d3b-627a5e2df67f"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'exp_name': 'PCT+VisionTransformer', 'model_point': 'pct', 'model_img': 'visiontransformer', 'batch_size': 5, 'val_batch_size': 2, 'test_batch_size': 2, 'epochs': 100, 'start_epoch': 0, 'use_sgd': False, 'lr': 0.001, 'momentum': 0.9, 'no_cuda': False, 'seed': 1, 'evalu': False, 'num_points': 2048, 'dropout': 0.5, 'emb_dims': 1024, 'k': 20, 'resume': False, 'model_path': '', 'save_freq': 2, 'print_freq': 50, 'enable_wandb': True, 'spct_model_path': '/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/naive_pct.t7'}\n","Using GPU : 0 from 1 devices\n","Wandb Enabled\n"]},{"data":{"text/html":["Finishing last run (ID:3bh20eci) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d61e858c872444fb136f2e252304b7b","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">PCT+VisionTransformer</strong> at: <a href=\"https://wandb.ai/sapienza_ml_2022_23/CrossPoint/runs/3bh20eci\" target=\"_blank\">https://wandb.ai/sapienza_ml_2022_23/CrossPoint/runs/3bh20eci</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230205_020557-3bh20eci/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:3bh20eci). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230205_020726-tq2g603e</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/sapienza_ml_2022_23/CrossPoint/runs/tq2g603e\" target=\"_blank\">PCT+VisionTransformer</a></strong> to <a href=\"https://wandb.ai/sapienza_ml_2022_23/CrossPoint\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href=\"https://wandb.ai/sapienza_ml_2022_23/CrossPoint\" target=\"_blank\">https://wandb.ai/sapienza_ml_2022_23/CrossPoint</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href=\"https://wandb.ai/sapienza_ml_2022_23/CrossPoint/runs/tq2g603e\" target=\"_blank\">https://wandb.ai/sapienza_ml_2022_23/CrossPoint/runs/tq2g603e</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Init CrosspointLightning v4\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n","  warning_cache.warn(\n","WARNING:lightning_fabric.loggers.csv_logs:Missing logger folder: /content/lightning_logs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name        | Type              | Params\n","--------------------------------------------------\n","0 | point_model | Pct               | 3.1 M \n","1 | img_model   | VisionTransformer | 304 M \n","2 | criterion   | NTXentLoss        | 0     \n","--------------------------------------------------\n","3.7 M     Trainable params\n","304 M     Non-trainable params\n","308 M     Total params\n","1,232.106 Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Use Adam\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c591daf894834208894cc662f7427692","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Starting epoch -> 0  (training)\n","Epoch (0), Batch(0/809), loss: 11.390156, imid loss: 7.261144, cmid loss: 4.129012 \n","Epoch (0), Batch(50/809), loss: 8.605150, imid loss: 2.096662, cmid loss: 6.508489 \n","Epoch (0), Batch(100/809), loss: 8.877796, imid loss: 2.339185, cmid loss: 6.538611 \n","Epoch (0), Batch(150/809), loss: 9.073814, imid loss: 2.448655, cmid loss: 6.625159 \n","Epoch (0), Batch(200/809), loss: 8.885295, imid loss: 2.238160, cmid loss: 6.647135 \n","Epoch (0), Batch(250/809), loss: 8.924202, imid loss: 2.358346, cmid loss: 6.565856 \n","Epoch (0), Batch(300/809), loss: 8.920462, imid loss: 2.534516, cmid loss: 6.385945 \n","Epoch (0), Batch(350/809), loss: 8.665723, imid loss: 2.044464, cmid loss: 6.621259 \n","Epoch (0), Batch(400/809), loss: 8.921461, imid loss: 2.356117, cmid loss: 6.565345 \n","Epoch (0), Batch(450/809), loss: 9.238537, imid loss: 2.787683, cmid loss: 6.450854 \n","Epoch (0), Batch(500/809), loss: 9.107101, imid loss: 2.569872, cmid loss: 6.537229 \n","Epoch (0), Batch(550/809), loss: 8.773457, imid loss: 2.304284, cmid loss: 6.469172 \n","Epoch (0), Batch(600/809), loss: 8.763580, imid loss: 2.313686, cmid loss: 6.449894 \n","Epoch (0), Batch(650/809), loss: 8.627122, imid loss: 2.217523, cmid loss: 6.409598 \n","Epoch (0), Batch(700/809), loss: 8.884832, imid loss: 2.523764, cmid loss: 6.361068 \n","Epoch (0), Batch(750/809), loss: 8.815639, imid loss: 2.457198, cmid loss: 6.358441 \n","Epoch (0), Batch(800/809), loss: 8.984946, imid loss: 2.520799, cmid loss: 6.464147 \n","Ending epoch -> 0  (training)\n","Starting epoch  0  (validation_epoch_start)\n","Starting epoch  0  (validation_step)\n","Linear Accuracy : 0.8018638573743923\n","==> NEW RECORD on accuracy on epoch  0  --- Accuracy =  0.8018638573743923  ----> SAVING Best Model...\n","==> Saving for frequency...\n","Training 0, loss: 8.851836\n","Starting epoch -> 1  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (1), Batch(0/809), loss: 8.963644, imid loss: 2.612006, cmid loss: 6.351638 \n","Epoch (1), Batch(50/809), loss: 9.029841, imid loss: 2.494397, cmid loss: 6.535445 \n","Epoch (1), Batch(100/809), loss: 8.365295, imid loss: 2.031594, cmid loss: 6.333702 \n","Epoch (1), Batch(150/809), loss: 8.623876, imid loss: 2.199074, cmid loss: 6.424802 \n","Epoch (1), Batch(200/809), loss: 9.318932, imid loss: 3.012312, cmid loss: 6.306620 \n","Epoch (1), Batch(250/809), loss: 8.543841, imid loss: 2.219639, cmid loss: 6.324203 \n","Epoch (1), Batch(300/809), loss: 8.747166, imid loss: 2.217431, cmid loss: 6.529735 \n","Epoch (1), Batch(350/809), loss: 8.423361, imid loss: 2.256994, cmid loss: 6.166367 \n","Epoch (1), Batch(400/809), loss: 8.412827, imid loss: 2.088771, cmid loss: 6.324056 \n","Epoch (1), Batch(450/809), loss: 8.872932, imid loss: 2.683220, cmid loss: 6.189712 \n","Epoch (1), Batch(500/809), loss: 7.673657, imid loss: 1.743438, cmid loss: 5.930219 \n","Epoch (1), Batch(550/809), loss: 8.481095, imid loss: 2.368214, cmid loss: 6.112881 \n","Epoch (1), Batch(600/809), loss: 9.275833, imid loss: 3.055165, cmid loss: 6.220668 \n","Epoch (1), Batch(650/809), loss: 8.863175, imid loss: 2.662976, cmid loss: 6.200200 \n","Epoch (1), Batch(700/809), loss: 8.737285, imid loss: 2.475036, cmid loss: 6.262249 \n","Epoch (1), Batch(750/809), loss: 8.499904, imid loss: 2.467966, cmid loss: 6.031938 \n","Epoch (1), Batch(800/809), loss: 8.631940, imid loss: 2.599020, cmid loss: 6.032920 \n","Ending epoch -> 1  (training)\n","Starting epoch  1  (validation_epoch_start)\n","Starting epoch  1  (validation_step)\n","Linear Accuracy : 0.7568881685575365\n","Training 1, loss: 8.716359\n","Starting epoch -> 2  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (2), Batch(0/809), loss: 9.079532, imid loss: 2.857977, cmid loss: 6.221555 \n","Epoch (2), Batch(50/809), loss: 8.910108, imid loss: 2.787094, cmid loss: 6.123014 \n","Epoch (2), Batch(100/809), loss: 8.052865, imid loss: 2.029549, cmid loss: 6.023316 \n","Epoch (2), Batch(150/809), loss: 9.094459, imid loss: 2.896271, cmid loss: 6.198188 \n","Epoch (2), Batch(200/809), loss: 9.484068, imid loss: 3.547667, cmid loss: 5.936401 \n","Epoch (2), Batch(250/809), loss: 8.378153, imid loss: 2.393619, cmid loss: 5.984533 \n","Epoch (2), Batch(300/809), loss: 8.140117, imid loss: 2.416925, cmid loss: 5.723191 \n","Epoch (2), Batch(350/809), loss: 8.760988, imid loss: 2.575962, cmid loss: 6.185026 \n","Epoch (2), Batch(400/809), loss: 6.866042, imid loss: 1.350024, cmid loss: 5.516018 \n","Epoch (2), Batch(450/809), loss: 7.188449, imid loss: 1.392969, cmid loss: 5.795480 \n","Epoch (2), Batch(500/809), loss: 8.146844, imid loss: 2.086319, cmid loss: 6.060525 \n","Epoch (2), Batch(550/809), loss: 8.307556, imid loss: 2.680331, cmid loss: 5.627225 \n","Epoch (2), Batch(600/809), loss: 8.123547, imid loss: 2.354467, cmid loss: 5.769080 \n","Epoch (2), Batch(650/809), loss: 7.879564, imid loss: 2.363639, cmid loss: 5.515925 \n","Epoch (2), Batch(700/809), loss: 8.668127, imid loss: 3.289272, cmid loss: 5.378856 \n","Epoch (2), Batch(750/809), loss: 8.864394, imid loss: 3.333648, cmid loss: 5.530746 \n","Epoch (2), Batch(800/809), loss: 8.605589, imid loss: 2.826099, cmid loss: 5.779490 \n","Ending epoch -> 2  (training)\n","Starting epoch  2  (validation_epoch_start)\n","Starting epoch  2  (validation_step)\n","Linear Accuracy : 0.7690437601296597\n","==> Saving for frequency...\n","Training 2, loss: 8.548005\n","Starting epoch -> 3  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (3), Batch(0/809), loss: 8.421102, imid loss: 2.560221, cmid loss: 5.860881 \n","Epoch (3), Batch(50/809), loss: 8.273183, imid loss: 2.292408, cmid loss: 5.980774 \n","Epoch (3), Batch(100/809), loss: 8.465749, imid loss: 3.042062, cmid loss: 5.423687 \n","Epoch (3), Batch(150/809), loss: 7.764714, imid loss: 2.379724, cmid loss: 5.384991 \n","Epoch (3), Batch(200/809), loss: 8.952728, imid loss: 3.279122, cmid loss: 5.673606 \n","Epoch (3), Batch(250/809), loss: 8.809044, imid loss: 3.581108, cmid loss: 5.227937 \n","Epoch (3), Batch(300/809), loss: 8.706963, imid loss: 3.149786, cmid loss: 5.557177 \n","Epoch (3), Batch(350/809), loss: 7.745667, imid loss: 2.662989, cmid loss: 5.082678 \n","Epoch (3), Batch(400/809), loss: 8.148979, imid loss: 3.596452, cmid loss: 4.552527 \n","Epoch (3), Batch(450/809), loss: 7.947564, imid loss: 2.767217, cmid loss: 5.180346 \n","Epoch (3), Batch(500/809), loss: 8.937762, imid loss: 3.946735, cmid loss: 4.991027 \n","Epoch (3), Batch(550/809), loss: 7.243577, imid loss: 2.687311, cmid loss: 4.556266 \n","Epoch (3), Batch(600/809), loss: 8.105770, imid loss: 2.569055, cmid loss: 5.536716 \n","Epoch (3), Batch(650/809), loss: 9.072365, imid loss: 4.274191, cmid loss: 4.798173 \n","Epoch (3), Batch(700/809), loss: 8.939728, imid loss: 4.319369, cmid loss: 4.620358 \n","Epoch (3), Batch(750/809), loss: 9.436529, imid loss: 4.494990, cmid loss: 4.941539 \n","Epoch (3), Batch(800/809), loss: 9.031871, imid loss: 4.625653, cmid loss: 4.406218 \n","Ending epoch -> 3  (training)\n","Starting epoch  3  (validation_epoch_start)\n","Starting epoch  3  (validation_step)\n","Linear Accuracy : 0.784035656401945\n","Training 3, loss: 8.346032\n","Starting epoch -> 4  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (4), Batch(0/809), loss: 9.190630, imid loss: 4.737098, cmid loss: 4.453532 \n","Epoch (4), Batch(50/809), loss: 7.094519, imid loss: 2.760021, cmid loss: 4.334498 \n","Epoch (4), Batch(100/809), loss: 6.495675, imid loss: 2.384476, cmid loss: 4.111199 \n","Epoch (4), Batch(150/809), loss: 8.047873, imid loss: 3.283189, cmid loss: 4.764684 \n","Epoch (4), Batch(200/809), loss: 8.488485, imid loss: 3.569778, cmid loss: 4.918708 \n","Epoch (4), Batch(250/809), loss: 7.731560, imid loss: 3.370261, cmid loss: 4.361299 \n","Epoch (4), Batch(300/809), loss: 8.675832, imid loss: 4.095294, cmid loss: 4.580538 \n","Epoch (4), Batch(350/809), loss: 8.402939, imid loss: 4.496503, cmid loss: 3.906436 \n","Epoch (4), Batch(400/809), loss: 7.772303, imid loss: 4.286644, cmid loss: 3.485659 \n","Epoch (4), Batch(450/809), loss: 6.571201, imid loss: 3.398137, cmid loss: 3.173064 \n","Epoch (4), Batch(500/809), loss: 6.720730, imid loss: 3.785359, cmid loss: 2.935371 \n","Epoch (4), Batch(550/809), loss: 7.708437, imid loss: 5.020644, cmid loss: 2.687794 \n","Epoch (4), Batch(600/809), loss: 8.418337, imid loss: 4.456457, cmid loss: 3.961879 \n","Epoch (4), Batch(650/809), loss: 7.382552, imid loss: 3.792262, cmid loss: 3.590290 \n","Epoch (4), Batch(700/809), loss: 7.553215, imid loss: 4.548612, cmid loss: 3.004602 \n","Epoch (4), Batch(750/809), loss: 4.603361, imid loss: 2.237566, cmid loss: 2.365794 \n","Epoch (4), Batch(800/809), loss: 4.464573, imid loss: 2.118858, cmid loss: 2.345715 \n","Ending epoch -> 4  (training)\n","Starting epoch  4  (validation_epoch_start)\n","Starting epoch  4  (validation_step)\n","Linear Accuracy : 0.7722852512155591\n","==> Saving for frequency...\n","Training 4, loss: 7.886487\n","Starting epoch -> 5  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (5), Batch(0/809), loss: 7.994325, imid loss: 5.406413, cmid loss: 2.587912 \n","Epoch (5), Batch(50/809), loss: 4.299253, imid loss: 1.843694, cmid loss: 2.455559 \n","Epoch (5), Batch(100/809), loss: 10.182085, imid loss: 6.754697, cmid loss: 3.427388 \n","Epoch (5), Batch(150/809), loss: 5.428939, imid loss: 3.152817, cmid loss: 2.276121 \n","Epoch (5), Batch(200/809), loss: 7.617129, imid loss: 5.205471, cmid loss: 2.411659 \n","Epoch (5), Batch(250/809), loss: 7.640207, imid loss: 5.260690, cmid loss: 2.379517 \n","Epoch (5), Batch(300/809), loss: 6.585935, imid loss: 4.203040, cmid loss: 2.382895 \n","Epoch (5), Batch(350/809), loss: 6.084188, imid loss: 3.626726, cmid loss: 2.457462 \n","Epoch (5), Batch(400/809), loss: 5.720849, imid loss: 3.522869, cmid loss: 2.197979 \n","Epoch (5), Batch(450/809), loss: 7.894424, imid loss: 5.418504, cmid loss: 2.475920 \n","Epoch (5), Batch(500/809), loss: 9.360398, imid loss: 6.843473, cmid loss: 2.516925 \n","Epoch (5), Batch(550/809), loss: 9.583179, imid loss: 6.739837, cmid loss: 2.843343 \n","Epoch (5), Batch(600/809), loss: 6.779154, imid loss: 4.490276, cmid loss: 2.288878 \n","Epoch (5), Batch(650/809), loss: 7.631700, imid loss: 5.503247, cmid loss: 2.128453 \n","Epoch (5), Batch(700/809), loss: 5.291915, imid loss: 3.198931, cmid loss: 2.092983 \n","Epoch (5), Batch(750/809), loss: 7.806406, imid loss: 5.340159, cmid loss: 2.466247 \n","Epoch (5), Batch(800/809), loss: 8.129322, imid loss: 5.502543, cmid loss: 2.626779 \n","Ending epoch -> 5  (training)\n","Starting epoch  5  (validation_epoch_start)\n","Starting epoch  5  (validation_step)\n","Linear Accuracy : 0.7706645056726094\n","Training 5, loss: 7.021985\n","Starting epoch -> 6  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (6), Batch(0/809), loss: 6.412769, imid loss: 4.227131, cmid loss: 2.185638 \n","Epoch (6), Batch(50/809), loss: 6.572513, imid loss: 4.402169, cmid loss: 2.170344 \n","Epoch (6), Batch(100/809), loss: 5.443299, imid loss: 3.176058, cmid loss: 2.267241 \n","Epoch (6), Batch(150/809), loss: 7.406054, imid loss: 4.685206, cmid loss: 2.720848 \n","Epoch (6), Batch(200/809), loss: 5.076081, imid loss: 2.877067, cmid loss: 2.199015 \n","Epoch (6), Batch(250/809), loss: 4.232367, imid loss: 2.201791, cmid loss: 2.030576 \n","Epoch (6), Batch(300/809), loss: 9.411009, imid loss: 7.207891, cmid loss: 2.203118 \n","Epoch (6), Batch(350/809), loss: 4.026355, imid loss: 1.912791, cmid loss: 2.113564 \n","Epoch (6), Batch(400/809), loss: 5.770935, imid loss: 3.535836, cmid loss: 2.235099 \n","Epoch (6), Batch(450/809), loss: 6.146206, imid loss: 4.018867, cmid loss: 2.127339 \n","Epoch (6), Batch(500/809), loss: 6.117046, imid loss: 3.946119, cmid loss: 2.170928 \n","Epoch (6), Batch(550/809), loss: 5.046324, imid loss: 2.829452, cmid loss: 2.216871 \n","Epoch (6), Batch(600/809), loss: 3.898295, imid loss: 1.845583, cmid loss: 2.052712 \n","Epoch (6), Batch(650/809), loss: 5.129636, imid loss: 3.038371, cmid loss: 2.091265 \n","Epoch (6), Batch(700/809), loss: 4.395789, imid loss: 2.197090, cmid loss: 2.198699 \n","Epoch (6), Batch(750/809), loss: 6.490627, imid loss: 4.318288, cmid loss: 2.172339 \n","Epoch (6), Batch(800/809), loss: 7.723310, imid loss: 5.715646, cmid loss: 2.007664 \n","Ending epoch -> 6  (training)\n","Starting epoch  6  (validation_epoch_start)\n","Starting epoch  6  (validation_step)\n","Linear Accuracy : 0.7674230145867099\n","==> Saving for frequency...\n","Training 6, loss: 6.415110\n","Starting epoch -> 7  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (7), Batch(0/809), loss: 6.754689, imid loss: 4.602390, cmid loss: 2.152299 \n","Epoch (7), Batch(50/809), loss: 7.177259, imid loss: 5.109344, cmid loss: 2.067915 \n","Epoch (7), Batch(100/809), loss: 6.400790, imid loss: 4.065262, cmid loss: 2.335528 \n","Epoch (7), Batch(150/809), loss: 4.879029, imid loss: 2.806098, cmid loss: 2.072931 \n","Epoch (7), Batch(200/809), loss: 4.000963, imid loss: 1.946658, cmid loss: 2.054305 \n","Epoch (7), Batch(250/809), loss: 5.249990, imid loss: 3.174477, cmid loss: 2.075513 \n","Epoch (7), Batch(300/809), loss: 5.649526, imid loss: 3.588434, cmid loss: 2.061091 \n","Epoch (7), Batch(350/809), loss: 5.536973, imid loss: 3.487894, cmid loss: 2.049079 \n","Epoch (7), Batch(400/809), loss: 6.042175, imid loss: 3.785868, cmid loss: 2.256307 \n","Epoch (7), Batch(450/809), loss: 6.152536, imid loss: 4.120142, cmid loss: 2.032394 \n","Epoch (7), Batch(500/809), loss: 5.852935, imid loss: 3.660474, cmid loss: 2.192462 \n","Epoch (7), Batch(550/809), loss: 5.414792, imid loss: 3.262208, cmid loss: 2.152584 \n","Epoch (7), Batch(600/809), loss: 7.409794, imid loss: 5.354066, cmid loss: 2.055728 \n","Epoch (7), Batch(650/809), loss: 4.408959, imid loss: 2.365026, cmid loss: 2.043933 \n","Epoch (7), Batch(700/809), loss: 5.979161, imid loss: 3.752829, cmid loss: 2.226332 \n","Epoch (7), Batch(750/809), loss: 5.353599, imid loss: 3.120496, cmid loss: 2.233103 \n","Epoch (7), Batch(800/809), loss: 6.728053, imid loss: 4.180076, cmid loss: 2.547977 \n","Ending epoch -> 7  (training)\n","Starting epoch  7  (validation_epoch_start)\n","Starting epoch  7  (validation_step)\n","Linear Accuracy : 0.7872771474878444\n","Training 7, loss: 6.157925\n","Starting epoch -> 8  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (8), Batch(0/809), loss: 5.844771, imid loss: 3.804570, cmid loss: 2.040202 \n","Epoch (8), Batch(50/809), loss: 5.695334, imid loss: 3.675360, cmid loss: 2.019974 \n","Epoch (8), Batch(100/809), loss: 7.283841, imid loss: 4.855021, cmid loss: 2.428819 \n","Epoch (8), Batch(150/809), loss: 6.862025, imid loss: 4.409133, cmid loss: 2.452892 \n","Epoch (8), Batch(200/809), loss: 5.179477, imid loss: 3.165171, cmid loss: 2.014306 \n","Epoch (8), Batch(250/809), loss: 5.933034, imid loss: 3.908260, cmid loss: 2.024775 \n","Epoch (8), Batch(300/809), loss: 5.157515, imid loss: 3.124074, cmid loss: 2.033440 \n","Epoch (8), Batch(350/809), loss: 4.841048, imid loss: 2.817498, cmid loss: 2.023551 \n","Epoch (8), Batch(400/809), loss: 6.250875, imid loss: 4.104168, cmid loss: 2.146706 \n","Epoch (8), Batch(450/809), loss: 4.803463, imid loss: 2.813544, cmid loss: 1.989919 \n","Epoch (8), Batch(500/809), loss: 7.283825, imid loss: 4.824460, cmid loss: 2.459365 \n","Epoch (8), Batch(550/809), loss: 5.822534, imid loss: 3.742992, cmid loss: 2.079541 \n","Epoch (8), Batch(600/809), loss: 5.520282, imid loss: 3.497335, cmid loss: 2.022947 \n","Epoch (8), Batch(650/809), loss: 7.500732, imid loss: 4.936060, cmid loss: 2.564672 \n","Epoch (8), Batch(700/809), loss: 5.877007, imid loss: 3.900697, cmid loss: 1.976310 \n","Epoch (8), Batch(750/809), loss: 4.997693, imid loss: 2.982184, cmid loss: 2.015509 \n","Epoch (8), Batch(800/809), loss: 5.458270, imid loss: 3.329318, cmid loss: 2.128952 \n","Ending epoch -> 8  (training)\n","Starting epoch  8  (validation_epoch_start)\n","Starting epoch  8  (validation_step)\n","Linear Accuracy : 0.7621555915721232\n","==> Saving for frequency...\n","Training 8, loss: 5.795866\n","Starting epoch -> 9  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (9), Batch(0/809), loss: 4.432990, imid loss: 2.430401, cmid loss: 2.002589 \n","Epoch (9), Batch(50/809), loss: 4.015599, imid loss: 1.962285, cmid loss: 2.053314 \n","Epoch (9), Batch(100/809), loss: 5.449674, imid loss: 3.259209, cmid loss: 2.190465 \n","Epoch (9), Batch(150/809), loss: 7.299785, imid loss: 5.139756, cmid loss: 2.160028 \n","Epoch (9), Batch(200/809), loss: 5.438946, imid loss: 3.452294, cmid loss: 1.986652 \n","Epoch (9), Batch(250/809), loss: 6.557957, imid loss: 4.316195, cmid loss: 2.241762 \n","Epoch (9), Batch(300/809), loss: 5.972692, imid loss: 3.950696, cmid loss: 2.021996 \n","Epoch (9), Batch(350/809), loss: 5.424265, imid loss: 3.255217, cmid loss: 2.169049 \n","Epoch (9), Batch(400/809), loss: 6.881718, imid loss: 4.814413, cmid loss: 2.067305 \n","Epoch (9), Batch(450/809), loss: 5.501991, imid loss: 3.489454, cmid loss: 2.012537 \n","Epoch (9), Batch(500/809), loss: 5.928541, imid loss: 3.586581, cmid loss: 2.341960 \n","Epoch (9), Batch(550/809), loss: 5.835722, imid loss: 3.827808, cmid loss: 2.007915 \n","Epoch (9), Batch(600/809), loss: 6.616224, imid loss: 4.601464, cmid loss: 2.014760 \n","Epoch (9), Batch(650/809), loss: 5.564331, imid loss: 3.483143, cmid loss: 2.081188 \n","Epoch (9), Batch(700/809), loss: 6.236386, imid loss: 4.135864, cmid loss: 2.100522 \n","Epoch (9), Batch(750/809), loss: 5.315730, imid loss: 3.334185, cmid loss: 1.981545 \n","Epoch (9), Batch(800/809), loss: 5.076366, imid loss: 3.061262, cmid loss: 2.015105 \n","Ending epoch -> 9  (training)\n","Starting epoch  9  (validation_epoch_start)\n","Starting epoch  9  (validation_step)\n","Linear Accuracy : 0.7803889789303079\n","Training 9, loss: 5.610324\n","Starting epoch -> 10  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (10), Batch(0/809), loss: 4.870202, imid loss: 2.850192, cmid loss: 2.020010 \n","Epoch (10), Batch(50/809), loss: 5.686065, imid loss: 3.638081, cmid loss: 2.047984 \n","Epoch (10), Batch(100/809), loss: 3.135740, imid loss: 1.130301, cmid loss: 2.005439 \n","Epoch (10), Batch(150/809), loss: 4.880520, imid loss: 2.841406, cmid loss: 2.039113 \n","Epoch (10), Batch(200/809), loss: 8.132046, imid loss: 5.651925, cmid loss: 2.480120 \n","Epoch (10), Batch(250/809), loss: 7.419227, imid loss: 5.428289, cmid loss: 1.990937 \n","Epoch (10), Batch(300/809), loss: 7.264501, imid loss: 5.222426, cmid loss: 2.042075 \n","Epoch (10), Batch(350/809), loss: 6.234305, imid loss: 4.105719, cmid loss: 2.128586 \n","Epoch (10), Batch(400/809), loss: 5.864467, imid loss: 3.704557, cmid loss: 2.159910 \n","Epoch (10), Batch(450/809), loss: 4.186725, imid loss: 2.159626, cmid loss: 2.027098 \n","Epoch (10), Batch(500/809), loss: 5.800808, imid loss: 3.612606, cmid loss: 2.188202 \n","Epoch (10), Batch(550/809), loss: 4.456505, imid loss: 2.449608, cmid loss: 2.006896 \n","Epoch (10), Batch(600/809), loss: 6.091215, imid loss: 4.065309, cmid loss: 2.025906 \n","Epoch (10), Batch(650/809), loss: 5.791772, imid loss: 3.797263, cmid loss: 1.994509 \n","Epoch (10), Batch(700/809), loss: 5.259171, imid loss: 3.286762, cmid loss: 1.972410 \n","Epoch (10), Batch(750/809), loss: 4.489969, imid loss: 2.497680, cmid loss: 1.992289 \n","Epoch (10), Batch(800/809), loss: 6.160804, imid loss: 4.127879, cmid loss: 2.032925 \n","Ending epoch -> 10  (training)\n","Starting epoch  10  (validation_epoch_start)\n","Starting epoch  10  (validation_step)\n","Linear Accuracy : 0.7832252836304701\n","==> Saving for frequency...\n","Training 10, loss: 5.376398\n","Starting epoch -> 11  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (11), Batch(0/809), loss: 7.552433, imid loss: 5.405755, cmid loss: 2.146678 \n","Epoch (11), Batch(50/809), loss: 4.195391, imid loss: 2.223791, cmid loss: 1.971600 \n","Epoch (11), Batch(100/809), loss: 5.976504, imid loss: 3.988193, cmid loss: 1.988312 \n","Epoch (11), Batch(150/809), loss: 4.159595, imid loss: 2.183946, cmid loss: 1.975649 \n","Epoch (11), Batch(200/809), loss: 6.106048, imid loss: 3.912340, cmid loss: 2.193708 \n","Epoch (11), Batch(250/809), loss: 6.227104, imid loss: 4.207179, cmid loss: 2.019925 \n","Epoch (11), Batch(300/809), loss: 5.240693, imid loss: 3.138538, cmid loss: 2.102155 \n","Epoch (11), Batch(350/809), loss: 5.353813, imid loss: 3.365013, cmid loss: 1.988801 \n","Epoch (11), Batch(400/809), loss: 4.065333, imid loss: 2.084201, cmid loss: 1.981132 \n","Epoch (11), Batch(450/809), loss: 4.484716, imid loss: 2.477548, cmid loss: 2.007168 \n","Epoch (11), Batch(500/809), loss: 3.822867, imid loss: 1.843812, cmid loss: 1.979055 \n","Epoch (11), Batch(550/809), loss: 3.963850, imid loss: 1.953244, cmid loss: 2.010606 \n","Epoch (11), Batch(600/809), loss: 6.395350, imid loss: 4.350873, cmid loss: 2.044478 \n","Epoch (11), Batch(650/809), loss: 4.052830, imid loss: 2.074989, cmid loss: 1.977841 \n","Epoch (11), Batch(700/809), loss: 5.453192, imid loss: 3.458514, cmid loss: 1.994678 \n","Epoch (11), Batch(750/809), loss: 5.233322, imid loss: 3.266529, cmid loss: 1.966794 \n","Epoch (11), Batch(800/809), loss: 5.199605, imid loss: 3.203475, cmid loss: 1.996130 \n","Ending epoch -> 11  (training)\n","Starting epoch  11  (validation_epoch_start)\n","Starting epoch  11  (validation_step)\n","Linear Accuracy : 0.7832252836304701\n","Training 11, loss: 5.323122\n","Starting epoch -> 12  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (12), Batch(0/809), loss: 4.681365, imid loss: 2.710581, cmid loss: 1.970784 \n","Epoch (12), Batch(50/809), loss: 5.836393, imid loss: 3.824115, cmid loss: 2.012279 \n","Epoch (12), Batch(100/809), loss: 5.194468, imid loss: 3.149501, cmid loss: 2.044967 \n","Epoch (12), Batch(150/809), loss: 5.189839, imid loss: 3.195490, cmid loss: 1.994349 \n","Epoch (12), Batch(200/809), loss: 4.613827, imid loss: 2.585941, cmid loss: 2.027885 \n","Epoch (12), Batch(250/809), loss: 6.060808, imid loss: 4.029951, cmid loss: 2.030858 \n","Epoch (12), Batch(300/809), loss: 4.505720, imid loss: 2.534491, cmid loss: 1.971229 \n","Epoch (12), Batch(350/809), loss: 4.606998, imid loss: 2.632557, cmid loss: 1.974441 \n","Epoch (12), Batch(400/809), loss: 5.706744, imid loss: 3.726329, cmid loss: 1.980416 \n","Epoch (12), Batch(450/809), loss: 5.312125, imid loss: 3.334905, cmid loss: 1.977220 \n","Epoch (12), Batch(500/809), loss: 4.547874, imid loss: 2.561981, cmid loss: 1.985893 \n","Epoch (12), Batch(550/809), loss: 4.732943, imid loss: 2.724143, cmid loss: 2.008800 \n","Epoch (12), Batch(600/809), loss: 4.682899, imid loss: 2.686675, cmid loss: 1.996224 \n","Epoch (12), Batch(650/809), loss: 5.980764, imid loss: 3.939804, cmid loss: 2.040960 \n","Epoch (12), Batch(700/809), loss: 4.952292, imid loss: 2.950537, cmid loss: 2.001755 \n","Epoch (12), Batch(750/809), loss: 5.680867, imid loss: 3.537810, cmid loss: 2.143057 \n","Epoch (12), Batch(800/809), loss: 4.998796, imid loss: 3.012991, cmid loss: 1.985805 \n","Ending epoch -> 12  (training)\n","Starting epoch  12  (validation_epoch_start)\n","Starting epoch  12  (validation_step)\n","Linear Accuracy : 0.7783630470016207\n","==> Saving for frequency...\n","Training 12, loss: 5.164476\n","Starting epoch -> 13  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (13), Batch(0/809), loss: 4.414543, imid loss: 2.416862, cmid loss: 1.997681 \n","Epoch (13), Batch(50/809), loss: 5.732066, imid loss: 3.693143, cmid loss: 2.038923 \n","Epoch (13), Batch(100/809), loss: 4.405875, imid loss: 2.434288, cmid loss: 1.971587 \n","Epoch (13), Batch(150/809), loss: 5.772026, imid loss: 3.747390, cmid loss: 2.024637 \n","Epoch (13), Batch(200/809), loss: 4.942271, imid loss: 2.964415, cmid loss: 1.977856 \n","Epoch (13), Batch(250/809), loss: 4.612010, imid loss: 2.602545, cmid loss: 2.009464 \n","Epoch (13), Batch(300/809), loss: 5.257565, imid loss: 3.256938, cmid loss: 2.000628 \n","Epoch (13), Batch(350/809), loss: 6.152088, imid loss: 4.039102, cmid loss: 2.112987 \n","Epoch (13), Batch(400/809), loss: 3.478416, imid loss: 1.463689, cmid loss: 2.014727 \n","Epoch (13), Batch(450/809), loss: 4.566854, imid loss: 2.571910, cmid loss: 1.994944 \n","Epoch (13), Batch(500/809), loss: 4.652261, imid loss: 2.683249, cmid loss: 1.969012 \n","Epoch (13), Batch(550/809), loss: 3.871405, imid loss: 1.891190, cmid loss: 1.980215 \n","Epoch (13), Batch(600/809), loss: 4.540601, imid loss: 2.561729, cmid loss: 1.978872 \n","Epoch (13), Batch(650/809), loss: 4.592111, imid loss: 2.602675, cmid loss: 1.989435 \n","Epoch (13), Batch(700/809), loss: 5.570771, imid loss: 3.584389, cmid loss: 1.986383 \n","Epoch (13), Batch(750/809), loss: 4.805124, imid loss: 2.830454, cmid loss: 1.974670 \n","Epoch (13), Batch(800/809), loss: 5.650661, imid loss: 3.645355, cmid loss: 2.005307 \n","Ending epoch -> 13  (training)\n","Starting epoch  13  (validation_epoch_start)\n","Starting epoch  13  (validation_step)\n","Linear Accuracy : 0.7791734197730956\n","Training 13, loss: 5.071342\n","Starting epoch -> 14  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (14), Batch(0/809), loss: 5.333107, imid loss: 3.341292, cmid loss: 1.991815 \n","Epoch (14), Batch(50/809), loss: 4.447649, imid loss: 2.478102, cmid loss: 1.969547 \n","Epoch (14), Batch(100/809), loss: 6.111956, imid loss: 4.136914, cmid loss: 1.975042 \n","Epoch (14), Batch(150/809), loss: 5.032962, imid loss: 3.059769, cmid loss: 1.973193 \n","Epoch (14), Batch(200/809), loss: 5.070406, imid loss: 3.031614, cmid loss: 2.038793 \n","Epoch (14), Batch(250/809), loss: 5.752066, imid loss: 3.767757, cmid loss: 1.984309 \n","Epoch (14), Batch(300/809), loss: 4.378051, imid loss: 2.414091, cmid loss: 1.963960 \n","Epoch (14), Batch(350/809), loss: 4.474129, imid loss: 2.480970, cmid loss: 1.993159 \n","Epoch (14), Batch(400/809), loss: 6.109826, imid loss: 4.136315, cmid loss: 1.973511 \n","Epoch (14), Batch(450/809), loss: 4.428107, imid loss: 2.457116, cmid loss: 1.970991 \n","Epoch (14), Batch(500/809), loss: 3.806961, imid loss: 1.832713, cmid loss: 1.974248 \n","Epoch (14), Batch(550/809), loss: 4.541104, imid loss: 2.553941, cmid loss: 1.987163 \n","Epoch (14), Batch(600/809), loss: 5.140814, imid loss: 3.170601, cmid loss: 1.970213 \n","Epoch (14), Batch(650/809), loss: 5.198081, imid loss: 3.197938, cmid loss: 2.000143 \n","Epoch (14), Batch(700/809), loss: 5.285378, imid loss: 3.323206, cmid loss: 1.962172 \n","Epoch (14), Batch(750/809), loss: 4.644274, imid loss: 2.662151, cmid loss: 1.982124 \n","Epoch (14), Batch(800/809), loss: 4.506294, imid loss: 2.520088, cmid loss: 1.986206 \n","Ending epoch -> 14  (training)\n","Starting epoch  14  (validation_epoch_start)\n","Starting epoch  14  (validation_step)\n","Linear Accuracy : 0.7771474878444085\n","==> Saving for frequency...\n","Training 14, loss: 4.984933\n","Starting epoch -> 15  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (15), Batch(0/809), loss: 4.057122, imid loss: 2.074621, cmid loss: 1.982500 \n","Epoch (15), Batch(50/809), loss: 4.455490, imid loss: 2.480593, cmid loss: 1.974897 \n","Epoch (15), Batch(100/809), loss: 5.286280, imid loss: 3.321831, cmid loss: 1.964449 \n","Epoch (15), Batch(150/809), loss: 4.020120, imid loss: 2.044846, cmid loss: 1.975273 \n","Epoch (15), Batch(200/809), loss: 4.256052, imid loss: 2.280855, cmid loss: 1.975197 \n","Epoch (15), Batch(250/809), loss: 4.801107, imid loss: 2.824675, cmid loss: 1.976433 \n","Epoch (15), Batch(300/809), loss: 5.965475, imid loss: 3.969237, cmid loss: 1.996238 \n","Epoch (15), Batch(350/809), loss: 5.158965, imid loss: 3.162833, cmid loss: 1.996132 \n","Epoch (15), Batch(400/809), loss: 5.121842, imid loss: 3.130896, cmid loss: 1.990946 \n","Epoch (15), Batch(450/809), loss: 5.482620, imid loss: 3.504737, cmid loss: 1.977883 \n","Epoch (15), Batch(500/809), loss: 4.413418, imid loss: 2.415511, cmid loss: 1.997906 \n","Epoch (15), Batch(550/809), loss: 3.704878, imid loss: 1.742412, cmid loss: 1.962465 \n","Epoch (15), Batch(600/809), loss: 4.873863, imid loss: 2.901796, cmid loss: 1.972067 \n","Epoch (15), Batch(650/809), loss: 5.198210, imid loss: 3.215287, cmid loss: 1.982923 \n","Epoch (15), Batch(700/809), loss: 3.680655, imid loss: 1.707670, cmid loss: 1.972985 \n","Epoch (15), Batch(750/809), loss: 4.480910, imid loss: 2.507152, cmid loss: 1.973758 \n","Epoch (15), Batch(800/809), loss: 5.488202, imid loss: 3.494909, cmid loss: 1.993292 \n","Ending epoch -> 15  (training)\n","Starting epoch  15  (validation_epoch_start)\n","Starting epoch  15  (validation_step)\n","Linear Accuracy : 0.7949756888168558\n","Training 15, loss: 4.911107\n","Starting epoch -> 16  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (16), Batch(0/809), loss: 4.023807, imid loss: 2.045450, cmid loss: 1.978357 \n","Epoch (16), Batch(50/809), loss: 5.473268, imid loss: 3.481999, cmid loss: 1.991269 \n","Epoch (16), Batch(100/809), loss: 4.698441, imid loss: 2.713495, cmid loss: 1.984945 \n","Epoch (16), Batch(150/809), loss: 5.164348, imid loss: 3.047523, cmid loss: 2.116824 \n","Epoch (16), Batch(200/809), loss: 4.774371, imid loss: 2.794803, cmid loss: 1.979568 \n","Epoch (16), Batch(250/809), loss: 3.989932, imid loss: 2.018674, cmid loss: 1.971258 \n","Epoch (16), Batch(300/809), loss: 5.861847, imid loss: 3.529877, cmid loss: 2.331971 \n","Epoch (16), Batch(350/809), loss: 4.614364, imid loss: 2.642191, cmid loss: 1.972172 \n","Epoch (16), Batch(400/809), loss: 4.826900, imid loss: 2.836201, cmid loss: 1.990700 \n","Epoch (16), Batch(450/809), loss: 3.971406, imid loss: 2.001722, cmid loss: 1.969683 \n","Epoch (16), Batch(500/809), loss: 4.300958, imid loss: 2.320149, cmid loss: 1.980809 \n","Epoch (16), Batch(550/809), loss: 4.094934, imid loss: 2.112498, cmid loss: 1.982436 \n","Epoch (16), Batch(600/809), loss: 4.533490, imid loss: 2.542024, cmid loss: 1.991466 \n","Epoch (16), Batch(650/809), loss: 4.328590, imid loss: 2.322494, cmid loss: 2.006096 \n","Epoch (16), Batch(700/809), loss: 4.699599, imid loss: 2.693944, cmid loss: 2.005656 \n","Epoch (16), Batch(750/809), loss: 5.173688, imid loss: 3.192586, cmid loss: 1.981102 \n","Epoch (16), Batch(800/809), loss: 4.000416, imid loss: 2.026900, cmid loss: 1.973516 \n","Ending epoch -> 16  (training)\n","Starting epoch  16  (validation_epoch_start)\n","Starting epoch  16  (validation_step)\n","Linear Accuracy : 0.7860615883306321\n","==> Saving for frequency...\n","Training 16, loss: 4.758963\n","Starting epoch -> 17  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (17), Batch(0/809), loss: 4.339592, imid loss: 2.358097, cmid loss: 1.981495 \n","Epoch (17), Batch(50/809), loss: 4.309543, imid loss: 2.257946, cmid loss: 2.051598 \n","Epoch (17), Batch(100/809), loss: 5.406278, imid loss: 3.392916, cmid loss: 2.013361 \n","Epoch (17), Batch(150/809), loss: 4.667089, imid loss: 2.697696, cmid loss: 1.969393 \n","Epoch (17), Batch(200/809), loss: 4.167789, imid loss: 2.151791, cmid loss: 2.015997 \n","Epoch (17), Batch(250/809), loss: 4.472144, imid loss: 2.504500, cmid loss: 1.967644 \n","Epoch (17), Batch(300/809), loss: 4.544935, imid loss: 2.573087, cmid loss: 1.971848 \n","Epoch (17), Batch(350/809), loss: 4.250321, imid loss: 2.267050, cmid loss: 1.983271 \n","Epoch (17), Batch(400/809), loss: 4.131373, imid loss: 2.164212, cmid loss: 1.967161 \n","Epoch (17), Batch(450/809), loss: 5.585775, imid loss: 3.549122, cmid loss: 2.036653 \n","Epoch (17), Batch(500/809), loss: 4.702345, imid loss: 2.679156, cmid loss: 2.023190 \n","Epoch (17), Batch(550/809), loss: 4.139857, imid loss: 2.132026, cmid loss: 2.007832 \n","Epoch (17), Batch(600/809), loss: 5.670011, imid loss: 3.695171, cmid loss: 1.974839 \n","Epoch (17), Batch(650/809), loss: 4.414087, imid loss: 2.432278, cmid loss: 1.981809 \n","Epoch (17), Batch(700/809), loss: 4.290065, imid loss: 2.300992, cmid loss: 1.989073 \n","Epoch (17), Batch(750/809), loss: 4.472536, imid loss: 2.502515, cmid loss: 1.970021 \n","Epoch (17), Batch(800/809), loss: 5.373013, imid loss: 3.397699, cmid loss: 1.975314 \n","Ending epoch -> 17  (training)\n","Starting epoch  17  (validation_epoch_start)\n","Starting epoch  17  (validation_step)\n","Linear Accuracy : 0.7860615883306321\n","Training 17, loss: 4.783106\n","Starting epoch -> 18  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (18), Batch(0/809), loss: 5.360289, imid loss: 3.353632, cmid loss: 2.006657 \n","Epoch (18), Batch(50/809), loss: 4.542712, imid loss: 2.552449, cmid loss: 1.990263 \n","Epoch (18), Batch(100/809), loss: 5.502481, imid loss: 3.508983, cmid loss: 1.993497 \n","Epoch (18), Batch(150/809), loss: 5.350646, imid loss: 3.382050, cmid loss: 1.968596 \n","Epoch (18), Batch(200/809), loss: 4.042327, imid loss: 2.070969, cmid loss: 1.971358 \n","Epoch (18), Batch(250/809), loss: 4.880741, imid loss: 2.875250, cmid loss: 2.005491 \n","Epoch (18), Batch(300/809), loss: 4.314771, imid loss: 2.350631, cmid loss: 1.964140 \n","Epoch (18), Batch(350/809), loss: 4.516298, imid loss: 2.520206, cmid loss: 1.996092 \n","Epoch (18), Batch(400/809), loss: 4.532266, imid loss: 2.547282, cmid loss: 1.984984 \n","Epoch (18), Batch(450/809), loss: 4.705765, imid loss: 2.687293, cmid loss: 2.018472 \n","Epoch (18), Batch(500/809), loss: 4.385233, imid loss: 2.414452, cmid loss: 1.970782 \n","Epoch (18), Batch(550/809), loss: 3.767986, imid loss: 1.802276, cmid loss: 1.965709 \n","Epoch (18), Batch(600/809), loss: 5.041307, imid loss: 3.065592, cmid loss: 1.975715 \n","Epoch (18), Batch(650/809), loss: 4.227697, imid loss: 2.252007, cmid loss: 1.975690 \n","Epoch (18), Batch(700/809), loss: 4.699179, imid loss: 2.722491, cmid loss: 1.976688 \n","Epoch (18), Batch(750/809), loss: 4.660654, imid loss: 2.695194, cmid loss: 1.965460 \n","Epoch (18), Batch(800/809), loss: 4.911915, imid loss: 2.938811, cmid loss: 1.973104 \n","Ending epoch -> 18  (training)\n","Starting epoch  18  (validation_epoch_start)\n","Starting epoch  18  (validation_step)\n","Linear Accuracy : 0.7787682333873582\n","==> Saving for frequency...\n","Training 18, loss: 4.670246\n","Starting epoch -> 19  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (19), Batch(0/809), loss: 3.267831, imid loss: 1.310427, cmid loss: 1.957404 \n","Epoch (19), Batch(50/809), loss: 4.992273, imid loss: 2.979184, cmid loss: 2.013089 \n","Epoch (19), Batch(100/809), loss: 4.858920, imid loss: 2.873760, cmid loss: 1.985159 \n","Epoch (19), Batch(150/809), loss: 4.656077, imid loss: 2.686108, cmid loss: 1.969970 \n","Epoch (19), Batch(200/809), loss: 4.906243, imid loss: 2.931925, cmid loss: 1.974318 \n","Epoch (19), Batch(250/809), loss: 5.558022, imid loss: 3.358123, cmid loss: 2.199899 \n","Epoch (19), Batch(300/809), loss: 4.700288, imid loss: 2.718070, cmid loss: 1.982218 \n","Epoch (19), Batch(350/809), loss: 5.267136, imid loss: 3.195472, cmid loss: 2.071664 \n","Epoch (19), Batch(400/809), loss: 5.629700, imid loss: 3.609097, cmid loss: 2.020603 \n","Epoch (19), Batch(450/809), loss: 4.422990, imid loss: 2.444993, cmid loss: 1.977996 \n","Epoch (19), Batch(500/809), loss: 4.694622, imid loss: 2.719461, cmid loss: 1.975161 \n","Epoch (19), Batch(550/809), loss: 4.523263, imid loss: 2.542830, cmid loss: 1.980432 \n","Epoch (19), Batch(600/809), loss: 4.314312, imid loss: 2.322834, cmid loss: 1.991478 \n","Epoch (19), Batch(650/809), loss: 4.715996, imid loss: 2.746675, cmid loss: 1.969321 \n","Epoch (19), Batch(700/809), loss: 4.270007, imid loss: 2.294777, cmid loss: 1.975229 \n","Epoch (19), Batch(750/809), loss: 4.320664, imid loss: 2.355021, cmid loss: 1.965643 \n","Epoch (19), Batch(800/809), loss: 4.288787, imid loss: 2.312709, cmid loss: 1.976078 \n","Ending epoch -> 19  (training)\n","Starting epoch  19  (validation_epoch_start)\n","Starting epoch  19  (validation_step)\n","Linear Accuracy : 0.7824149108589952\n","Training 19, loss: 4.634643\n","Starting epoch -> 20  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (20), Batch(0/809), loss: 5.185854, imid loss: 3.176598, cmid loss: 2.009256 \n","Epoch (20), Batch(50/809), loss: 5.944851, imid loss: 3.963775, cmid loss: 1.981076 \n","Epoch (20), Batch(100/809), loss: 3.992142, imid loss: 2.026840, cmid loss: 1.965302 \n","Epoch (20), Batch(150/809), loss: 3.795445, imid loss: 1.823427, cmid loss: 1.972019 \n","Epoch (20), Batch(200/809), loss: 4.936575, imid loss: 2.978760, cmid loss: 1.957815 \n","Epoch (20), Batch(250/809), loss: 4.263232, imid loss: 2.306839, cmid loss: 1.956392 \n","Epoch (20), Batch(300/809), loss: 4.467136, imid loss: 2.492388, cmid loss: 1.974748 \n","Epoch (20), Batch(350/809), loss: 4.298749, imid loss: 2.328782, cmid loss: 1.969968 \n","Epoch (20), Batch(400/809), loss: 5.222363, imid loss: 3.255401, cmid loss: 1.966962 \n","Epoch (20), Batch(450/809), loss: 3.689956, imid loss: 1.707282, cmid loss: 1.982674 \n","Epoch (20), Batch(500/809), loss: 4.406256, imid loss: 2.436973, cmid loss: 1.969283 \n","Epoch (20), Batch(550/809), loss: 4.874339, imid loss: 2.881605, cmid loss: 1.992734 \n","Epoch (20), Batch(600/809), loss: 3.965475, imid loss: 2.000405, cmid loss: 1.965070 \n","Epoch (20), Batch(650/809), loss: 4.409353, imid loss: 2.439111, cmid loss: 1.970242 \n","Epoch (20), Batch(700/809), loss: 5.085468, imid loss: 3.116193, cmid loss: 1.969275 \n","Epoch (20), Batch(750/809), loss: 4.572023, imid loss: 2.575146, cmid loss: 1.996877 \n","Epoch (20), Batch(800/809), loss: 4.725640, imid loss: 2.624111, cmid loss: 2.101529 \n","Ending epoch -> 20  (training)\n","Starting epoch  20  (validation_epoch_start)\n","Starting epoch  20  (validation_step)\n","Linear Accuracy : 0.7909238249594813\n","==> Saving for frequency...\n","Training 20, loss: 4.575289\n","Starting epoch -> 21  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (21), Batch(0/809), loss: 4.280965, imid loss: 2.303087, cmid loss: 1.977879 \n","Epoch (21), Batch(50/809), loss: 4.951952, imid loss: 2.954887, cmid loss: 1.997064 \n","Epoch (21), Batch(100/809), loss: 4.715650, imid loss: 2.716567, cmid loss: 1.999083 \n","Epoch (21), Batch(150/809), loss: 3.831696, imid loss: 1.835989, cmid loss: 1.995707 \n","Epoch (21), Batch(200/809), loss: 4.685140, imid loss: 2.713001, cmid loss: 1.972139 \n","Epoch (21), Batch(250/809), loss: 3.748385, imid loss: 1.764368, cmid loss: 1.984017 \n","Epoch (21), Batch(300/809), loss: 5.395618, imid loss: 3.379933, cmid loss: 2.015686 \n","Epoch (21), Batch(350/809), loss: 3.768611, imid loss: 1.805171, cmid loss: 1.963440 \n","Epoch (21), Batch(400/809), loss: 4.626155, imid loss: 2.643889, cmid loss: 1.982266 \n","Epoch (21), Batch(450/809), loss: 5.391942, imid loss: 3.395657, cmid loss: 1.996285 \n","Epoch (21), Batch(500/809), loss: 3.650253, imid loss: 1.678725, cmid loss: 1.971527 \n","Epoch (21), Batch(550/809), loss: 5.244519, imid loss: 3.277358, cmid loss: 1.967162 \n","Epoch (21), Batch(600/809), loss: 4.730261, imid loss: 2.765687, cmid loss: 1.964574 \n","Epoch (21), Batch(650/809), loss: 4.189094, imid loss: 2.211084, cmid loss: 1.978009 \n","Epoch (21), Batch(700/809), loss: 4.904206, imid loss: 2.927197, cmid loss: 1.977009 \n","Epoch (21), Batch(750/809), loss: 4.126662, imid loss: 2.152491, cmid loss: 1.974171 \n","Epoch (21), Batch(800/809), loss: 4.819493, imid loss: 2.821788, cmid loss: 1.997705 \n","Ending epoch -> 21  (training)\n","Starting epoch  21  (validation_epoch_start)\n","Starting epoch  21  (validation_step)\n","Linear Accuracy : 0.7978119935170178\n","Training 21, loss: 4.553675\n","Starting epoch -> 22  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (22), Batch(0/809), loss: 4.078197, imid loss: 2.097008, cmid loss: 1.981190 \n","Epoch (22), Batch(50/809), loss: 4.425204, imid loss: 2.451537, cmid loss: 1.973666 \n","Epoch (22), Batch(100/809), loss: 4.050768, imid loss: 2.073812, cmid loss: 1.976956 \n","Epoch (22), Batch(150/809), loss: 4.504176, imid loss: 2.532135, cmid loss: 1.972041 \n","Epoch (22), Batch(200/809), loss: 4.833280, imid loss: 2.855184, cmid loss: 1.978096 \n","Epoch (22), Batch(250/809), loss: 4.724486, imid loss: 2.754759, cmid loss: 1.969727 \n","Epoch (22), Batch(300/809), loss: 4.648860, imid loss: 2.677338, cmid loss: 1.971523 \n","Epoch (22), Batch(350/809), loss: 4.380245, imid loss: 2.328927, cmid loss: 2.051318 \n","Epoch (22), Batch(400/809), loss: 4.662645, imid loss: 2.686588, cmid loss: 1.976058 \n","Epoch (22), Batch(450/809), loss: 3.661787, imid loss: 1.701225, cmid loss: 1.960562 \n","Epoch (22), Batch(500/809), loss: 6.780844, imid loss: 4.714356, cmid loss: 2.066488 \n","Epoch (22), Batch(550/809), loss: 5.145373, imid loss: 3.164132, cmid loss: 1.981242 \n","Epoch (22), Batch(600/809), loss: 4.455672, imid loss: 2.498626, cmid loss: 1.957045 \n","Epoch (22), Batch(650/809), loss: 4.751667, imid loss: 2.768052, cmid loss: 1.983615 \n","Epoch (22), Batch(700/809), loss: 4.410753, imid loss: 2.401668, cmid loss: 2.009085 \n","Epoch (22), Batch(750/809), loss: 4.338598, imid loss: 2.369199, cmid loss: 1.969399 \n","Epoch (22), Batch(800/809), loss: 4.883840, imid loss: 2.879100, cmid loss: 2.004739 \n","Ending epoch -> 22  (training)\n","Starting epoch  22  (validation_epoch_start)\n","Starting epoch  22  (validation_step)\n","Linear Accuracy : 0.7929497568881686\n","==> Saving for frequency...\n","Training 22, loss: 4.518925\n","Starting epoch -> 23  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (23), Batch(0/809), loss: 3.916924, imid loss: 1.931128, cmid loss: 1.985797 \n","Epoch (23), Batch(50/809), loss: 4.663486, imid loss: 2.690141, cmid loss: 1.973346 \n","Epoch (23), Batch(100/809), loss: 4.308781, imid loss: 2.344084, cmid loss: 1.964696 \n","Epoch (23), Batch(150/809), loss: 4.304946, imid loss: 2.341102, cmid loss: 1.963844 \n","Epoch (23), Batch(200/809), loss: 4.379858, imid loss: 2.400276, cmid loss: 1.979582 \n","Epoch (23), Batch(250/809), loss: 3.558131, imid loss: 1.595047, cmid loss: 1.963084 \n","Epoch (23), Batch(300/809), loss: 3.839774, imid loss: 1.875007, cmid loss: 1.964767 \n","Epoch (23), Batch(350/809), loss: 3.706590, imid loss: 1.734916, cmid loss: 1.971674 \n","Epoch (23), Batch(400/809), loss: 4.291909, imid loss: 2.309611, cmid loss: 1.982298 \n","Epoch (23), Batch(450/809), loss: 4.762255, imid loss: 2.789085, cmid loss: 1.973170 \n","Epoch (23), Batch(500/809), loss: 4.216771, imid loss: 2.242404, cmid loss: 1.974367 \n","Epoch (23), Batch(550/809), loss: 4.962226, imid loss: 2.987408, cmid loss: 1.974818 \n","Epoch (23), Batch(600/809), loss: 5.003254, imid loss: 3.012133, cmid loss: 1.991121 \n","Epoch (23), Batch(650/809), loss: 4.519157, imid loss: 2.513202, cmid loss: 2.005955 \n","Epoch (23), Batch(700/809), loss: 4.000888, imid loss: 2.020799, cmid loss: 1.980089 \n","Epoch (23), Batch(750/809), loss: 5.156088, imid loss: 3.186178, cmid loss: 1.969910 \n","Epoch (23), Batch(800/809), loss: 4.692492, imid loss: 2.721940, cmid loss: 1.970553 \n","Ending epoch -> 23  (training)\n","Starting epoch  23  (validation_epoch_start)\n","Starting epoch  23  (validation_step)\n","Linear Accuracy : 0.7925445705024311\n","Training 23, loss: 4.494829\n","Starting epoch -> 24  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (24), Batch(0/809), loss: 3.996755, imid loss: 2.030532, cmid loss: 1.966223 \n","Epoch (24), Batch(50/809), loss: 5.062904, imid loss: 3.093679, cmid loss: 1.969226 \n","Epoch (24), Batch(100/809), loss: 4.614737, imid loss: 2.609296, cmid loss: 2.005440 \n","Epoch (24), Batch(150/809), loss: 4.656852, imid loss: 2.643325, cmid loss: 2.013527 \n","Epoch (24), Batch(200/809), loss: 4.076348, imid loss: 2.113288, cmid loss: 1.963060 \n","Epoch (24), Batch(250/809), loss: 5.883448, imid loss: 3.873310, cmid loss: 2.010138 \n","Epoch (24), Batch(300/809), loss: 4.220232, imid loss: 2.245435, cmid loss: 1.974798 \n","Epoch (24), Batch(350/809), loss: 4.176072, imid loss: 2.208402, cmid loss: 1.967670 \n","Epoch (24), Batch(400/809), loss: 4.274203, imid loss: 2.290675, cmid loss: 1.983527 \n","Epoch (24), Batch(450/809), loss: 4.614740, imid loss: 2.649736, cmid loss: 1.965004 \n","Epoch (24), Batch(500/809), loss: 4.021786, imid loss: 2.052912, cmid loss: 1.968874 \n","Epoch (24), Batch(550/809), loss: 4.572814, imid loss: 2.603293, cmid loss: 1.969521 \n","Epoch (24), Batch(600/809), loss: 4.378454, imid loss: 2.397179, cmid loss: 1.981275 \n","Epoch (24), Batch(650/809), loss: 4.669394, imid loss: 2.678815, cmid loss: 1.990578 \n","Epoch (24), Batch(700/809), loss: 4.560172, imid loss: 2.588227, cmid loss: 1.971945 \n","Epoch (24), Batch(750/809), loss: 3.821278, imid loss: 1.825547, cmid loss: 1.995731 \n","Epoch (24), Batch(800/809), loss: 4.345111, imid loss: 2.359828, cmid loss: 1.985283 \n","Ending epoch -> 24  (training)\n","Starting epoch  24  (validation_epoch_start)\n","Starting epoch  24  (validation_step)\n","Linear Accuracy : 0.7799837925445705\n","==> Saving for frequency...\n","Training 24, loss: 4.463030\n","Starting epoch -> 25  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (25), Batch(0/809), loss: 4.616409, imid loss: 2.636590, cmid loss: 1.979820 \n","Epoch (25), Batch(50/809), loss: 4.407179, imid loss: 2.450167, cmid loss: 1.957011 \n","Epoch (25), Batch(100/809), loss: 4.278710, imid loss: 2.302010, cmid loss: 1.976701 \n","Epoch (25), Batch(150/809), loss: 3.931517, imid loss: 1.965752, cmid loss: 1.965765 \n","Epoch (25), Batch(200/809), loss: 5.935535, imid loss: 3.936876, cmid loss: 1.998659 \n","Epoch (25), Batch(250/809), loss: 4.134541, imid loss: 2.153937, cmid loss: 1.980603 \n","Epoch (25), Batch(300/809), loss: 4.522576, imid loss: 2.515101, cmid loss: 2.007475 \n","Epoch (25), Batch(350/809), loss: 4.048573, imid loss: 2.056949, cmid loss: 1.991625 \n","Epoch (25), Batch(400/809), loss: 5.351560, imid loss: 3.362780, cmid loss: 1.988779 \n","Epoch (25), Batch(450/809), loss: 4.763892, imid loss: 2.718998, cmid loss: 2.044894 \n","Epoch (25), Batch(500/809), loss: 4.362710, imid loss: 2.338699, cmid loss: 2.024011 \n","Epoch (25), Batch(550/809), loss: 4.939396, imid loss: 2.965417, cmid loss: 1.973979 \n","Epoch (25), Batch(600/809), loss: 4.181009, imid loss: 2.194609, cmid loss: 1.986400 \n","Epoch (25), Batch(650/809), loss: 4.809903, imid loss: 2.805238, cmid loss: 2.004665 \n","Epoch (25), Batch(700/809), loss: 5.313601, imid loss: 3.315549, cmid loss: 1.998053 \n","Epoch (25), Batch(750/809), loss: 5.595600, imid loss: 3.580975, cmid loss: 2.014625 \n","Epoch (25), Batch(800/809), loss: 4.636213, imid loss: 2.650280, cmid loss: 1.985934 \n","Ending epoch -> 25  (training)\n","Starting epoch  25  (validation_epoch_start)\n","Starting epoch  25  (validation_step)\n","Linear Accuracy : 0.7556726094003241\n","Training 25, loss: 4.660372\n","Starting epoch -> 26  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (26), Batch(0/809), loss: 5.014593, imid loss: 2.969139, cmid loss: 2.045454 \n","Epoch (26), Batch(50/809), loss: 5.374300, imid loss: 3.406337, cmid loss: 1.967963 \n","Epoch (26), Batch(100/809), loss: 4.107634, imid loss: 2.136805, cmid loss: 1.970829 \n","Epoch (26), Batch(150/809), loss: 4.270044, imid loss: 2.271535, cmid loss: 1.998509 \n","Epoch (26), Batch(200/809), loss: 4.626944, imid loss: 2.637855, cmid loss: 1.989089 \n","Epoch (26), Batch(250/809), loss: 4.473562, imid loss: 2.491870, cmid loss: 1.981691 \n","Epoch (26), Batch(300/809), loss: 4.813509, imid loss: 2.771007, cmid loss: 2.042502 \n","Epoch (26), Batch(350/809), loss: 4.217205, imid loss: 2.196196, cmid loss: 2.021009 \n","Epoch (26), Batch(400/809), loss: 5.004102, imid loss: 2.979249, cmid loss: 2.024853 \n","Epoch (26), Batch(450/809), loss: 6.229295, imid loss: 4.245961, cmid loss: 1.983334 \n","Epoch (26), Batch(500/809), loss: 4.968064, imid loss: 2.983069, cmid loss: 1.984995 \n","Epoch (26), Batch(550/809), loss: 4.655892, imid loss: 2.674041, cmid loss: 1.981852 \n","Epoch (26), Batch(600/809), loss: 4.691908, imid loss: 2.706372, cmid loss: 1.985536 \n","Epoch (26), Batch(650/809), loss: 4.155342, imid loss: 2.143218, cmid loss: 2.012125 \n","Epoch (26), Batch(700/809), loss: 4.153910, imid loss: 2.170027, cmid loss: 1.983883 \n","Epoch (26), Batch(750/809), loss: 3.908716, imid loss: 1.932512, cmid loss: 1.976204 \n","Epoch (26), Batch(800/809), loss: 4.327638, imid loss: 2.353502, cmid loss: 1.974136 \n","Ending epoch -> 26  (training)\n","Starting epoch  26  (validation_epoch_start)\n","Starting epoch  26  (validation_step)\n","Linear Accuracy : 0.7593192868719612\n","==> Saving for frequency...\n","Training 26, loss: 4.565119\n","Starting epoch -> 27  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (27), Batch(0/809), loss: 4.302148, imid loss: 2.314750, cmid loss: 1.987398 \n","Epoch (27), Batch(50/809), loss: 4.860689, imid loss: 2.876178, cmid loss: 1.984512 \n","Epoch (27), Batch(100/809), loss: 4.312249, imid loss: 2.339182, cmid loss: 1.973066 \n","Epoch (27), Batch(150/809), loss: 4.006978, imid loss: 2.033380, cmid loss: 1.973598 \n","Epoch (27), Batch(200/809), loss: 4.574705, imid loss: 2.591845, cmid loss: 1.982860 \n","Epoch (27), Batch(250/809), loss: 4.453040, imid loss: 2.472375, cmid loss: 1.980665 \n","Epoch (27), Batch(300/809), loss: 4.176455, imid loss: 2.202151, cmid loss: 1.974305 \n","Epoch (27), Batch(350/809), loss: 5.154958, imid loss: 3.126875, cmid loss: 2.028083 \n","Epoch (27), Batch(400/809), loss: 4.553210, imid loss: 2.558314, cmid loss: 1.994897 \n","Epoch (27), Batch(450/809), loss: 4.149785, imid loss: 2.187029, cmid loss: 1.962756 \n","Epoch (27), Batch(500/809), loss: 4.786186, imid loss: 2.796713, cmid loss: 1.989474 \n","Epoch (27), Batch(550/809), loss: 4.302832, imid loss: 2.311876, cmid loss: 1.990957 \n","Epoch (27), Batch(600/809), loss: 4.501820, imid loss: 2.512482, cmid loss: 1.989338 \n","Epoch (27), Batch(650/809), loss: 4.574498, imid loss: 2.588425, cmid loss: 1.986073 \n","Epoch (27), Batch(700/809), loss: 4.227976, imid loss: 2.255913, cmid loss: 1.972064 \n","Epoch (27), Batch(750/809), loss: 3.742200, imid loss: 1.772429, cmid loss: 1.969771 \n","Epoch (27), Batch(800/809), loss: 4.342170, imid loss: 2.365559, cmid loss: 1.976611 \n","Ending epoch -> 27  (training)\n","Starting epoch  27  (validation_epoch_start)\n","Starting epoch  27  (validation_step)\n","Linear Accuracy : 0.7791734197730956\n","Training 27, loss: 4.486638\n","Starting epoch -> 28  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (28), Batch(0/809), loss: 4.588058, imid loss: 2.610006, cmid loss: 1.978053 \n","Epoch (28), Batch(50/809), loss: 3.884875, imid loss: 1.922203, cmid loss: 1.962672 \n","Epoch (28), Batch(100/809), loss: 3.949512, imid loss: 1.988618, cmid loss: 1.960894 \n","Epoch (28), Batch(150/809), loss: 5.030490, imid loss: 3.044296, cmid loss: 1.986194 \n","Epoch (28), Batch(200/809), loss: 4.597730, imid loss: 2.609700, cmid loss: 1.988029 \n","Epoch (28), Batch(250/809), loss: 4.625561, imid loss: 2.649420, cmid loss: 1.976141 \n","Epoch (28), Batch(300/809), loss: 4.358788, imid loss: 2.383478, cmid loss: 1.975311 \n","Epoch (28), Batch(350/809), loss: 3.970001, imid loss: 2.001079, cmid loss: 1.968922 \n","Epoch (28), Batch(400/809), loss: 5.294952, imid loss: 3.324310, cmid loss: 1.970642 \n","Epoch (28), Batch(450/809), loss: 4.816192, imid loss: 2.819679, cmid loss: 1.996512 \n","Epoch (28), Batch(500/809), loss: 4.660680, imid loss: 2.664856, cmid loss: 1.995823 \n","Epoch (28), Batch(550/809), loss: 5.072126, imid loss: 3.099552, cmid loss: 1.972574 \n","Epoch (28), Batch(600/809), loss: 4.721879, imid loss: 2.744694, cmid loss: 1.977184 \n","Epoch (28), Batch(650/809), loss: 4.425219, imid loss: 2.449153, cmid loss: 1.976066 \n","Epoch (28), Batch(700/809), loss: 3.853712, imid loss: 1.868418, cmid loss: 1.985294 \n","Epoch (28), Batch(750/809), loss: 4.356329, imid loss: 2.391822, cmid loss: 1.964507 \n","Epoch (28), Batch(800/809), loss: 5.718611, imid loss: 3.744825, cmid loss: 1.973786 \n","Ending epoch -> 28  (training)\n","Starting epoch  28  (validation_epoch_start)\n","Starting epoch  28  (validation_step)\n","Linear Accuracy : 0.7487844408427877\n","==> Saving for frequency...\n","Training 28, loss: 4.454013\n","Starting epoch -> 29  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (29), Batch(0/809), loss: 4.711887, imid loss: 2.722371, cmid loss: 1.989516 \n","Epoch (29), Batch(50/809), loss: 5.017659, imid loss: 3.044212, cmid loss: 1.973447 \n","Epoch (29), Batch(100/809), loss: 4.103761, imid loss: 2.131718, cmid loss: 1.972043 \n","Epoch (29), Batch(150/809), loss: 4.271449, imid loss: 2.291559, cmid loss: 1.979890 \n","Epoch (29), Batch(200/809), loss: 4.432642, imid loss: 2.457995, cmid loss: 1.974647 \n","Epoch (29), Batch(250/809), loss: 4.151061, imid loss: 2.167246, cmid loss: 1.983815 \n","Epoch (29), Batch(300/809), loss: 4.330917, imid loss: 2.357092, cmid loss: 1.973825 \n","Epoch (29), Batch(350/809), loss: 5.111316, imid loss: 3.105439, cmid loss: 2.005877 \n","Epoch (29), Batch(400/809), loss: 5.103839, imid loss: 3.125452, cmid loss: 1.978387 \n","Epoch (29), Batch(450/809), loss: 4.766241, imid loss: 2.779806, cmid loss: 1.986435 \n","Epoch (29), Batch(500/809), loss: 4.460021, imid loss: 2.472658, cmid loss: 1.987363 \n","Epoch (29), Batch(550/809), loss: 4.890445, imid loss: 2.906317, cmid loss: 1.984127 \n","Epoch (29), Batch(600/809), loss: 4.080856, imid loss: 2.094754, cmid loss: 1.986103 \n","Epoch (29), Batch(650/809), loss: 4.647063, imid loss: 2.665907, cmid loss: 1.981156 \n","Epoch (29), Batch(700/809), loss: 4.290411, imid loss: 2.314343, cmid loss: 1.976068 \n","Epoch (29), Batch(750/809), loss: 4.092602, imid loss: 2.116435, cmid loss: 1.976167 \n","Epoch (29), Batch(800/809), loss: 4.441490, imid loss: 2.470001, cmid loss: 1.971489 \n","Ending epoch -> 29  (training)\n","Starting epoch  29  (validation_epoch_start)\n","Starting epoch  29  (validation_step)\n","Linear Accuracy : 0.7398703403565641\n","Training 29, loss: 4.415184\n","Starting epoch -> 30  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (30), Batch(0/809), loss: 4.338509, imid loss: 2.370666, cmid loss: 1.967842 \n","Epoch (30), Batch(50/809), loss: 3.943885, imid loss: 1.961772, cmid loss: 1.982113 \n","Epoch (30), Batch(100/809), loss: 3.855632, imid loss: 1.883584, cmid loss: 1.972049 \n","Epoch (30), Batch(150/809), loss: 3.734154, imid loss: 1.750338, cmid loss: 1.983815 \n","Epoch (30), Batch(200/809), loss: 4.620327, imid loss: 2.627980, cmid loss: 1.992346 \n","Epoch (30), Batch(250/809), loss: 4.290679, imid loss: 2.294469, cmid loss: 1.996210 \n","Epoch (30), Batch(300/809), loss: 4.794986, imid loss: 2.813357, cmid loss: 1.981630 \n","Epoch (30), Batch(350/809), loss: 4.095834, imid loss: 2.110972, cmid loss: 1.984862 \n","Epoch (30), Batch(400/809), loss: 3.877495, imid loss: 1.881404, cmid loss: 1.996091 \n","Epoch (30), Batch(450/809), loss: 4.355869, imid loss: 2.381066, cmid loss: 1.974803 \n","Epoch (30), Batch(500/809), loss: 4.746906, imid loss: 2.717973, cmid loss: 2.028933 \n","Epoch (30), Batch(550/809), loss: 4.344213, imid loss: 2.353207, cmid loss: 1.991006 \n","Epoch (30), Batch(600/809), loss: 4.379151, imid loss: 2.410173, cmid loss: 1.968979 \n","Epoch (30), Batch(650/809), loss: 4.451469, imid loss: 2.482746, cmid loss: 1.968723 \n","Epoch (30), Batch(700/809), loss: 3.576238, imid loss: 1.605442, cmid loss: 1.970796 \n","Epoch (30), Batch(750/809), loss: 4.931224, imid loss: 2.907072, cmid loss: 2.024152 \n","Epoch (30), Batch(800/809), loss: 4.268626, imid loss: 2.293554, cmid loss: 1.975072 \n","Ending epoch -> 30  (training)\n","Starting epoch  30  (validation_epoch_start)\n","Starting epoch  30  (validation_step)\n","Linear Accuracy : 0.7483792544570502\n","==> Saving for frequency...\n","Training 30, loss: 4.361588\n","Starting epoch -> 31  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (31), Batch(0/809), loss: 4.653137, imid loss: 2.669337, cmid loss: 1.983801 \n","Epoch (31), Batch(50/809), loss: 3.754271, imid loss: 1.783442, cmid loss: 1.970830 \n","Epoch (31), Batch(100/809), loss: 4.770595, imid loss: 2.809702, cmid loss: 1.960893 \n","Epoch (31), Batch(150/809), loss: 4.059456, imid loss: 2.075296, cmid loss: 1.984159 \n","Epoch (31), Batch(200/809), loss: 4.626773, imid loss: 2.626632, cmid loss: 2.000141 \n","Epoch (31), Batch(250/809), loss: 4.510131, imid loss: 2.538956, cmid loss: 1.971175 \n","Epoch (31), Batch(300/809), loss: 3.975638, imid loss: 1.992395, cmid loss: 1.983243 \n","Epoch (31), Batch(350/809), loss: 4.190081, imid loss: 2.214238, cmid loss: 1.975842 \n","Epoch (31), Batch(400/809), loss: 4.576411, imid loss: 2.603396, cmid loss: 1.973015 \n","Epoch (31), Batch(450/809), loss: 4.182589, imid loss: 2.217608, cmid loss: 1.964981 \n","Epoch (31), Batch(500/809), loss: 4.511401, imid loss: 2.533829, cmid loss: 1.977572 \n","Epoch (31), Batch(550/809), loss: 3.755609, imid loss: 1.779849, cmid loss: 1.975759 \n","Epoch (31), Batch(600/809), loss: 4.205451, imid loss: 2.226667, cmid loss: 1.978784 \n","Epoch (31), Batch(650/809), loss: 4.712810, imid loss: 2.748491, cmid loss: 1.964320 \n","Epoch (31), Batch(700/809), loss: 4.112718, imid loss: 2.116756, cmid loss: 1.995961 \n","Epoch (31), Batch(750/809), loss: 4.065688, imid loss: 2.082598, cmid loss: 1.983090 \n","Epoch (31), Batch(800/809), loss: 4.220687, imid loss: 2.254357, cmid loss: 1.966330 \n","Ending epoch -> 31  (training)\n","Starting epoch  31  (validation_epoch_start)\n","Starting epoch  31  (validation_step)\n","Linear Accuracy : 0.7487844408427877\n","Training 31, loss: 4.414266\n","Starting epoch -> 32  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (32), Batch(0/809), loss: 4.680515, imid loss: 2.690497, cmid loss: 1.990018 \n","Epoch (32), Batch(50/809), loss: 4.343032, imid loss: 2.363163, cmid loss: 1.979869 \n","Epoch (32), Batch(100/809), loss: 3.935942, imid loss: 1.962854, cmid loss: 1.973088 \n","Epoch (32), Batch(150/809), loss: 4.491972, imid loss: 2.512847, cmid loss: 1.979125 \n","Epoch (32), Batch(200/809), loss: 3.852568, imid loss: 1.860185, cmid loss: 1.992384 \n","Epoch (32), Batch(250/809), loss: 3.740139, imid loss: 1.781313, cmid loss: 1.958826 \n","Epoch (32), Batch(300/809), loss: 4.677617, imid loss: 2.701659, cmid loss: 1.975958 \n","Epoch (32), Batch(350/809), loss: 4.540546, imid loss: 2.558352, cmid loss: 1.982194 \n","Epoch (32), Batch(400/809), loss: 4.033464, imid loss: 2.052341, cmid loss: 1.981123 \n","Epoch (32), Batch(450/809), loss: 4.009580, imid loss: 2.023912, cmid loss: 1.985668 \n","Epoch (32), Batch(500/809), loss: 4.667652, imid loss: 2.689312, cmid loss: 1.978341 \n","Epoch (32), Batch(550/809), loss: 3.803937, imid loss: 1.781685, cmid loss: 2.022252 \n","Epoch (32), Batch(600/809), loss: 4.290864, imid loss: 2.288536, cmid loss: 2.002328 \n","Epoch (32), Batch(650/809), loss: 3.892117, imid loss: 1.918064, cmid loss: 1.974053 \n","Epoch (32), Batch(700/809), loss: 4.352866, imid loss: 2.389226, cmid loss: 1.963640 \n","Epoch (32), Batch(750/809), loss: 4.127089, imid loss: 2.150809, cmid loss: 1.976279 \n","Epoch (32), Batch(800/809), loss: 4.362012, imid loss: 2.391098, cmid loss: 1.970914 \n","Ending epoch -> 32  (training)\n","Starting epoch  32  (validation_epoch_start)\n","Starting epoch  32  (validation_step)\n","Linear Accuracy : 0.7410858995137763\n","==> Saving for frequency...\n","Training 32, loss: 4.372942\n","Starting epoch -> 33  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (33), Batch(0/809), loss: 4.825771, imid loss: 2.852090, cmid loss: 1.973681 \n","Epoch (33), Batch(50/809), loss: 4.225698, imid loss: 2.255818, cmid loss: 1.969879 \n","Epoch (33), Batch(100/809), loss: 4.586138, imid loss: 2.611560, cmid loss: 1.974578 \n","Epoch (33), Batch(150/809), loss: 4.485383, imid loss: 2.510412, cmid loss: 1.974971 \n","Epoch (33), Batch(200/809), loss: 4.290761, imid loss: 2.309975, cmid loss: 1.980785 \n","Epoch (33), Batch(250/809), loss: 4.751433, imid loss: 2.765890, cmid loss: 1.985543 \n","Epoch (33), Batch(300/809), loss: 4.121429, imid loss: 2.157037, cmid loss: 1.964393 \n","Epoch (33), Batch(350/809), loss: 4.597528, imid loss: 2.601724, cmid loss: 1.995804 \n","Epoch (33), Batch(400/809), loss: 3.719007, imid loss: 1.726285, cmid loss: 1.992722 \n","Epoch (33), Batch(450/809), loss: 4.724095, imid loss: 2.737096, cmid loss: 1.986999 \n","Epoch (33), Batch(500/809), loss: 4.598522, imid loss: 2.626798, cmid loss: 1.971724 \n","Epoch (33), Batch(550/809), loss: 4.525988, imid loss: 2.548556, cmid loss: 1.977432 \n","Epoch (33), Batch(600/809), loss: 5.178532, imid loss: 3.182641, cmid loss: 1.995891 \n","Epoch (33), Batch(650/809), loss: 4.182817, imid loss: 2.215071, cmid loss: 1.967746 \n","Epoch (33), Batch(700/809), loss: 4.104652, imid loss: 2.075440, cmid loss: 2.029212 \n","Epoch (33), Batch(750/809), loss: 4.031711, imid loss: 2.069281, cmid loss: 1.962429 \n","Epoch (33), Batch(800/809), loss: 4.128850, imid loss: 2.156750, cmid loss: 1.972100 \n","Ending epoch -> 33  (training)\n","Starting epoch  33  (validation_epoch_start)\n","Starting epoch  33  (validation_step)\n","Linear Accuracy : 0.747163695299838\n","Training 33, loss: 4.377487\n","Starting epoch -> 34  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (34), Batch(0/809), loss: 4.260279, imid loss: 2.276546, cmid loss: 1.983733 \n","Epoch (34), Batch(50/809), loss: 4.454703, imid loss: 2.482728, cmid loss: 1.971975 \n","Epoch (34), Batch(100/809), loss: 4.283245, imid loss: 2.286822, cmid loss: 1.996423 \n","Epoch (34), Batch(150/809), loss: 4.390943, imid loss: 2.409942, cmid loss: 1.981001 \n","Epoch (34), Batch(200/809), loss: 4.521939, imid loss: 2.548831, cmid loss: 1.973108 \n","Epoch (34), Batch(250/809), loss: 4.506351, imid loss: 2.527376, cmid loss: 1.978975 \n","Epoch (34), Batch(300/809), loss: 4.078445, imid loss: 2.087432, cmid loss: 1.991013 \n","Epoch (34), Batch(350/809), loss: 4.382916, imid loss: 2.401054, cmid loss: 1.981862 \n","Epoch (34), Batch(400/809), loss: 4.000810, imid loss: 2.023830, cmid loss: 1.976979 \n","Epoch (34), Batch(450/809), loss: 4.295636, imid loss: 2.324882, cmid loss: 1.970754 \n","Epoch (34), Batch(500/809), loss: 4.604718, imid loss: 2.640179, cmid loss: 1.964539 \n","Epoch (34), Batch(550/809), loss: 4.416164, imid loss: 2.448780, cmid loss: 1.967385 \n","Epoch (34), Batch(600/809), loss: 4.349478, imid loss: 2.367110, cmid loss: 1.982367 \n","Epoch (34), Batch(650/809), loss: 4.215832, imid loss: 2.247145, cmid loss: 1.968687 \n","Epoch (34), Batch(700/809), loss: 4.512710, imid loss: 2.538797, cmid loss: 1.973913 \n","Epoch (34), Batch(750/809), loss: 4.421649, imid loss: 2.461469, cmid loss: 1.960180 \n","Epoch (34), Batch(800/809), loss: 4.199354, imid loss: 2.227991, cmid loss: 1.971363 \n","Ending epoch -> 34  (training)\n","Starting epoch  34  (validation_epoch_start)\n","Starting epoch  34  (validation_step)\n","Linear Accuracy : 0.7491896272285251\n","==> Saving for frequency...\n","Training 34, loss: 4.362051\n","Starting epoch -> 35  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (35), Batch(0/809), loss: 4.277043, imid loss: 2.299028, cmid loss: 1.978016 \n","Epoch (35), Batch(50/809), loss: 4.013872, imid loss: 2.021106, cmid loss: 1.992765 \n","Epoch (35), Batch(100/809), loss: 4.542145, imid loss: 2.561655, cmid loss: 1.980490 \n","Epoch (35), Batch(150/809), loss: 4.145149, imid loss: 2.171867, cmid loss: 1.973282 \n","Epoch (35), Batch(200/809), loss: 5.037197, imid loss: 3.060793, cmid loss: 1.976403 \n","Epoch (35), Batch(250/809), loss: 5.137881, imid loss: 3.160755, cmid loss: 1.977127 \n","Epoch (35), Batch(300/809), loss: 4.280019, imid loss: 2.302243, cmid loss: 1.977776 \n","Epoch (35), Batch(350/809), loss: 4.400027, imid loss: 2.421258, cmid loss: 1.978769 \n","Epoch (35), Batch(400/809), loss: 4.149592, imid loss: 2.178308, cmid loss: 1.971284 \n","Epoch (35), Batch(450/809), loss: 4.101345, imid loss: 2.108846, cmid loss: 1.992499 \n","Epoch (35), Batch(500/809), loss: 4.481409, imid loss: 2.485903, cmid loss: 1.995506 \n","Epoch (35), Batch(550/809), loss: 4.160083, imid loss: 2.156547, cmid loss: 2.003536 \n","Epoch (35), Batch(600/809), loss: 4.889570, imid loss: 2.885733, cmid loss: 2.003837 \n","Epoch (35), Batch(650/809), loss: 4.507441, imid loss: 2.532188, cmid loss: 1.975253 \n","Epoch (35), Batch(700/809), loss: 4.048601, imid loss: 2.077825, cmid loss: 1.970776 \n","Epoch (35), Batch(750/809), loss: 4.442985, imid loss: 2.462650, cmid loss: 1.980335 \n","Epoch (35), Batch(800/809), loss: 3.705462, imid loss: 1.733652, cmid loss: 1.971809 \n","Ending epoch -> 35  (training)\n","Starting epoch  35  (validation_epoch_start)\n","Starting epoch  35  (validation_step)\n","Linear Accuracy : 0.7662074554294975\n","Training 35, loss: 4.348617\n","Starting epoch -> 36  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (36), Batch(0/809), loss: 4.159774, imid loss: 2.193539, cmid loss: 1.966236 \n","Epoch (36), Batch(50/809), loss: 4.413470, imid loss: 2.427622, cmid loss: 1.985848 \n","Epoch (36), Batch(100/809), loss: 4.274994, imid loss: 2.299406, cmid loss: 1.975589 \n","Epoch (36), Batch(150/809), loss: 4.692510, imid loss: 2.708394, cmid loss: 1.984116 \n","Epoch (36), Batch(200/809), loss: 4.226297, imid loss: 2.253786, cmid loss: 1.972511 \n","Epoch (36), Batch(250/809), loss: 4.721730, imid loss: 2.757004, cmid loss: 1.964726 \n","Epoch (36), Batch(300/809), loss: 4.687205, imid loss: 2.710099, cmid loss: 1.977106 \n","Epoch (36), Batch(350/809), loss: 4.014193, imid loss: 2.048717, cmid loss: 1.965475 \n","Epoch (36), Batch(400/809), loss: 4.671311, imid loss: 2.702335, cmid loss: 1.968977 \n","Epoch (36), Batch(450/809), loss: 4.256048, imid loss: 2.267238, cmid loss: 1.988810 \n","Epoch (36), Batch(500/809), loss: 3.950991, imid loss: 1.975928, cmid loss: 1.975063 \n","Epoch (36), Batch(550/809), loss: 3.797957, imid loss: 1.835132, cmid loss: 1.962826 \n","Epoch (36), Batch(600/809), loss: 3.893526, imid loss: 1.915037, cmid loss: 1.978489 \n","Epoch (36), Batch(650/809), loss: 4.252356, imid loss: 2.260848, cmid loss: 1.991507 \n","Epoch (36), Batch(700/809), loss: 4.618752, imid loss: 2.642211, cmid loss: 1.976541 \n","Epoch (36), Batch(750/809), loss: 4.373502, imid loss: 2.394555, cmid loss: 1.978947 \n","Epoch (36), Batch(800/809), loss: 4.690098, imid loss: 2.709538, cmid loss: 1.980560 \n","Ending epoch -> 36  (training)\n","Starting epoch  36  (validation_epoch_start)\n","Starting epoch  36  (validation_step)\n","Linear Accuracy : 0.7589141004862237\n","==> Saving for frequency...\n","Training 36, loss: 4.345221\n","Starting epoch -> 37  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (37), Batch(0/809), loss: 4.639638, imid loss: 2.650353, cmid loss: 1.989285 \n","Epoch (37), Batch(50/809), loss: 4.197173, imid loss: 2.206848, cmid loss: 1.990324 \n","Epoch (37), Batch(100/809), loss: 4.706189, imid loss: 2.736452, cmid loss: 1.969737 \n","Epoch (37), Batch(150/809), loss: 4.483755, imid loss: 2.500142, cmid loss: 1.983613 \n","Epoch (37), Batch(200/809), loss: 4.575562, imid loss: 2.594338, cmid loss: 1.981224 \n","Epoch (37), Batch(250/809), loss: 4.503480, imid loss: 2.520290, cmid loss: 1.983190 \n","Epoch (37), Batch(300/809), loss: 4.935194, imid loss: 2.955456, cmid loss: 1.979738 \n","Epoch (37), Batch(350/809), loss: 4.166488, imid loss: 2.193279, cmid loss: 1.973208 \n","Epoch (37), Batch(400/809), loss: 4.318044, imid loss: 2.341998, cmid loss: 1.976046 \n","Epoch (37), Batch(450/809), loss: 3.375336, imid loss: 1.371140, cmid loss: 2.004195 \n","Epoch (37), Batch(500/809), loss: 4.250693, imid loss: 2.254081, cmid loss: 1.996612 \n","Epoch (37), Batch(550/809), loss: 4.091419, imid loss: 2.096098, cmid loss: 1.995321 \n","Epoch (37), Batch(600/809), loss: 4.099762, imid loss: 2.130172, cmid loss: 1.969590 \n","Epoch (37), Batch(650/809), loss: 4.186275, imid loss: 2.203052, cmid loss: 1.983223 \n","Epoch (37), Batch(700/809), loss: 4.568456, imid loss: 2.583581, cmid loss: 1.984875 \n","Epoch (37), Batch(750/809), loss: 4.936506, imid loss: 2.939572, cmid loss: 1.996934 \n","Epoch (37), Batch(800/809), loss: 4.278142, imid loss: 2.311345, cmid loss: 1.966797 \n","Ending epoch -> 37  (training)\n","Starting epoch  37  (validation_epoch_start)\n","Starting epoch  37  (validation_step)\n","Linear Accuracy : 0.7576985413290114\n","Training 37, loss: 4.309688\n","Starting epoch -> 38  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (38), Batch(0/809), loss: 4.040766, imid loss: 2.060853, cmid loss: 1.979913 \n","Epoch (38), Batch(50/809), loss: 4.614745, imid loss: 2.629719, cmid loss: 1.985025 \n","Epoch (38), Batch(100/809), loss: 4.347159, imid loss: 2.370680, cmid loss: 1.976479 \n","Epoch (38), Batch(150/809), loss: 5.085845, imid loss: 3.124899, cmid loss: 1.960947 \n","Epoch (38), Batch(200/809), loss: 4.767711, imid loss: 2.776213, cmid loss: 1.991498 \n","Epoch (38), Batch(250/809), loss: 4.464313, imid loss: 2.480825, cmid loss: 1.983488 \n","Epoch (38), Batch(300/809), loss: 3.874316, imid loss: 1.898451, cmid loss: 1.975865 \n","Epoch (38), Batch(350/809), loss: 4.245970, imid loss: 2.257580, cmid loss: 1.988390 \n","Epoch (38), Batch(400/809), loss: 5.120969, imid loss: 3.152436, cmid loss: 1.968533 \n","Epoch (38), Batch(450/809), loss: 4.757421, imid loss: 2.766948, cmid loss: 1.990473 \n","Epoch (38), Batch(500/809), loss: 4.531902, imid loss: 2.568267, cmid loss: 1.963636 \n","Epoch (38), Batch(550/809), loss: 3.817957, imid loss: 1.844618, cmid loss: 1.973339 \n","Epoch (38), Batch(600/809), loss: 5.145907, imid loss: 3.184273, cmid loss: 1.961634 \n","Epoch (38), Batch(650/809), loss: 4.249423, imid loss: 2.281659, cmid loss: 1.967764 \n","Epoch (38), Batch(700/809), loss: 4.112026, imid loss: 2.138710, cmid loss: 1.973316 \n","Epoch (38), Batch(750/809), loss: 3.811223, imid loss: 1.840236, cmid loss: 1.970987 \n","Epoch (38), Batch(800/809), loss: 4.157074, imid loss: 2.188687, cmid loss: 1.968388 \n","Ending epoch -> 38  (training)\n","Starting epoch  38  (validation_epoch_start)\n","Starting epoch  38  (validation_step)\n","Linear Accuracy : 0.7585089141004863\n","==> Saving for frequency...\n","Training 38, loss: 4.304976\n","Starting epoch -> 39  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (39), Batch(0/809), loss: 4.352442, imid loss: 2.384231, cmid loss: 1.968211 \n","Epoch (39), Batch(50/809), loss: 3.967653, imid loss: 1.990212, cmid loss: 1.977441 \n","Epoch (39), Batch(100/809), loss: 3.954727, imid loss: 1.985085, cmid loss: 1.969642 \n","Epoch (39), Batch(150/809), loss: 4.464396, imid loss: 2.489859, cmid loss: 1.974537 \n","Epoch (39), Batch(200/809), loss: 4.670611, imid loss: 2.697583, cmid loss: 1.973029 \n","Epoch (39), Batch(250/809), loss: 4.411952, imid loss: 2.427501, cmid loss: 1.984452 \n","Epoch (39), Batch(300/809), loss: 4.001568, imid loss: 2.036533, cmid loss: 1.965035 \n","Epoch (39), Batch(350/809), loss: 4.624850, imid loss: 2.641861, cmid loss: 1.982990 \n","Epoch (39), Batch(400/809), loss: 3.840350, imid loss: 1.852866, cmid loss: 1.987484 \n","Epoch (39), Batch(450/809), loss: 4.059236, imid loss: 2.067073, cmid loss: 1.992163 \n","Epoch (39), Batch(500/809), loss: 4.688980, imid loss: 2.513335, cmid loss: 2.175645 \n","Epoch (39), Batch(550/809), loss: 5.447292, imid loss: 3.471770, cmid loss: 1.975522 \n","Epoch (39), Batch(600/809), loss: 4.152304, imid loss: 2.180893, cmid loss: 1.971411 \n","Epoch (39), Batch(650/809), loss: 3.942675, imid loss: 1.985141, cmid loss: 1.957535 \n","Epoch (39), Batch(700/809), loss: 3.799659, imid loss: 1.824383, cmid loss: 1.975276 \n","Epoch (39), Batch(750/809), loss: 4.634912, imid loss: 2.661263, cmid loss: 1.973649 \n","Epoch (39), Batch(800/809), loss: 4.348410, imid loss: 2.381283, cmid loss: 1.967127 \n","Ending epoch -> 39  (training)\n","Starting epoch  39  (validation_epoch_start)\n","Starting epoch  39  (validation_step)\n","Linear Accuracy : 0.7670178282009724\n","Training 39, loss: 4.304196\n","Starting epoch -> 40  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (40), Batch(0/809), loss: 4.322292, imid loss: 2.341721, cmid loss: 1.980571 \n","Epoch (40), Batch(50/809), loss: 4.597081, imid loss: 2.609175, cmid loss: 1.987906 \n","Epoch (40), Batch(100/809), loss: 4.382545, imid loss: 2.394026, cmid loss: 1.988520 \n","Epoch (40), Batch(150/809), loss: 4.506091, imid loss: 2.527234, cmid loss: 1.978857 \n","Epoch (40), Batch(200/809), loss: 3.790125, imid loss: 1.818310, cmid loss: 1.971815 \n","Epoch (40), Batch(250/809), loss: 3.944423, imid loss: 1.983555, cmid loss: 1.960868 \n","Epoch (40), Batch(300/809), loss: 4.118298, imid loss: 2.147744, cmid loss: 1.970553 \n","Epoch (40), Batch(350/809), loss: 4.315716, imid loss: 2.345878, cmid loss: 1.969838 \n","Epoch (40), Batch(400/809), loss: 4.739110, imid loss: 2.763901, cmid loss: 1.975210 \n","Epoch (40), Batch(450/809), loss: 3.393005, imid loss: 1.417022, cmid loss: 1.975984 \n","Epoch (40), Batch(500/809), loss: 4.071233, imid loss: 2.096963, cmid loss: 1.974270 \n","Epoch (40), Batch(550/809), loss: 4.750499, imid loss: 2.759017, cmid loss: 1.991481 \n","Epoch (40), Batch(600/809), loss: 4.055018, imid loss: 2.068788, cmid loss: 1.986230 \n","Epoch (40), Batch(650/809), loss: 4.491783, imid loss: 2.507148, cmid loss: 1.984634 \n","Epoch (40), Batch(700/809), loss: 4.005123, imid loss: 2.023810, cmid loss: 1.981313 \n","Epoch (40), Batch(750/809), loss: 4.011541, imid loss: 2.028179, cmid loss: 1.983362 \n","Epoch (40), Batch(800/809), loss: 4.130854, imid loss: 2.164024, cmid loss: 1.966830 \n","Ending epoch -> 40  (training)\n","Starting epoch  40  (validation_epoch_start)\n","Starting epoch  40  (validation_step)\n","Linear Accuracy : 0.770259319286872\n","==> Saving for frequency...\n","Training 40, loss: 4.250495\n","Starting epoch -> 41  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (41), Batch(0/809), loss: 4.231423, imid loss: 2.252422, cmid loss: 1.979002 \n","Epoch (41), Batch(50/809), loss: 4.650351, imid loss: 2.690236, cmid loss: 1.960115 \n","Epoch (41), Batch(100/809), loss: 4.061300, imid loss: 2.077580, cmid loss: 1.983720 \n","Epoch (41), Batch(150/809), loss: 4.191760, imid loss: 2.217939, cmid loss: 1.973822 \n","Epoch (41), Batch(200/809), loss: 4.216245, imid loss: 2.247432, cmid loss: 1.968812 \n","Epoch (41), Batch(250/809), loss: 4.365530, imid loss: 2.392889, cmid loss: 1.972641 \n","Epoch (41), Batch(300/809), loss: 4.163414, imid loss: 2.187585, cmid loss: 1.975829 \n","Epoch (41), Batch(350/809), loss: 4.087321, imid loss: 2.116971, cmid loss: 1.970350 \n","Epoch (41), Batch(400/809), loss: 4.041158, imid loss: 2.076407, cmid loss: 1.964751 \n","Epoch (41), Batch(450/809), loss: 3.845300, imid loss: 1.874934, cmid loss: 1.970366 \n","Epoch (41), Batch(500/809), loss: 4.407618, imid loss: 2.433646, cmid loss: 1.973972 \n","Epoch (41), Batch(550/809), loss: 4.169692, imid loss: 2.184071, cmid loss: 1.985621 \n","Epoch (41), Batch(600/809), loss: 3.772811, imid loss: 1.786230, cmid loss: 1.986581 \n","Epoch (41), Batch(650/809), loss: 4.092887, imid loss: 2.107316, cmid loss: 1.985571 \n","Epoch (41), Batch(700/809), loss: 4.056807, imid loss: 2.091516, cmid loss: 1.965292 \n","Epoch (41), Batch(750/809), loss: 4.379079, imid loss: 2.409050, cmid loss: 1.970029 \n","Epoch (41), Batch(800/809), loss: 4.294232, imid loss: 2.318977, cmid loss: 1.975255 \n","Ending epoch -> 41  (training)\n","Starting epoch  41  (validation_epoch_start)\n","Starting epoch  41  (validation_step)\n","Linear Accuracy : 0.7556726094003241\n","Training 41, loss: 4.270574\n","Starting epoch -> 42  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (42), Batch(0/809), loss: 4.143610, imid loss: 2.172265, cmid loss: 1.971345 \n","Epoch (42), Batch(50/809), loss: 4.460607, imid loss: 2.488433, cmid loss: 1.972174 \n","Epoch (42), Batch(100/809), loss: 4.373843, imid loss: 2.402934, cmid loss: 1.970910 \n","Epoch (42), Batch(150/809), loss: 4.641403, imid loss: 2.665632, cmid loss: 1.975771 \n","Epoch (42), Batch(200/809), loss: 4.276934, imid loss: 2.320060, cmid loss: 1.956874 \n","Epoch (42), Batch(250/809), loss: 3.944952, imid loss: 1.948430, cmid loss: 1.996521 \n","Epoch (42), Batch(300/809), loss: 4.132007, imid loss: 2.161568, cmid loss: 1.970439 \n","Epoch (42), Batch(350/809), loss: 4.373995, imid loss: 2.404235, cmid loss: 1.969760 \n","Epoch (42), Batch(400/809), loss: 4.161404, imid loss: 2.189404, cmid loss: 1.972000 \n","Epoch (42), Batch(450/809), loss: 4.723504, imid loss: 2.756075, cmid loss: 1.967429 \n","Epoch (42), Batch(500/809), loss: 4.119674, imid loss: 2.158128, cmid loss: 1.961546 \n","Epoch (42), Batch(550/809), loss: 3.976149, imid loss: 2.005915, cmid loss: 1.970234 \n","Epoch (42), Batch(600/809), loss: 4.423823, imid loss: 2.453609, cmid loss: 1.970214 \n","Epoch (42), Batch(650/809), loss: 4.245270, imid loss: 2.267005, cmid loss: 1.978265 \n","Epoch (42), Batch(700/809), loss: 4.557362, imid loss: 2.532391, cmid loss: 2.024971 \n","Epoch (42), Batch(750/809), loss: 3.794914, imid loss: 1.821322, cmid loss: 1.973592 \n","Epoch (42), Batch(800/809), loss: 4.649610, imid loss: 2.667168, cmid loss: 1.982442 \n","Ending epoch -> 42  (training)\n","Starting epoch  42  (validation_epoch_start)\n","Starting epoch  42  (validation_step)\n","Linear Accuracy : 0.7735008103727715\n","==> Saving for frequency...\n","Training 42, loss: 4.245628\n","Starting epoch -> 43  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (43), Batch(0/809), loss: 4.358342, imid loss: 2.381952, cmid loss: 1.976390 \n","Epoch (43), Batch(50/809), loss: 4.370836, imid loss: 2.392016, cmid loss: 1.978820 \n","Epoch (43), Batch(100/809), loss: 4.348967, imid loss: 2.364306, cmid loss: 1.984660 \n","Epoch (43), Batch(150/809), loss: 4.323408, imid loss: 2.359207, cmid loss: 1.964201 \n","Epoch (43), Batch(200/809), loss: 4.098949, imid loss: 2.134594, cmid loss: 1.964355 \n","Epoch (43), Batch(250/809), loss: 3.984917, imid loss: 2.020628, cmid loss: 1.964289 \n","Epoch (43), Batch(300/809), loss: 4.810441, imid loss: 2.846624, cmid loss: 1.963817 \n","Epoch (43), Batch(350/809), loss: 4.948658, imid loss: 2.983824, cmid loss: 1.964833 \n","Epoch (43), Batch(400/809), loss: 3.911740, imid loss: 1.933188, cmid loss: 1.978551 \n","Epoch (43), Batch(450/809), loss: 3.979142, imid loss: 1.987753, cmid loss: 1.991388 \n","Epoch (43), Batch(500/809), loss: 3.645947, imid loss: 1.674826, cmid loss: 1.971120 \n","Epoch (43), Batch(550/809), loss: 4.333065, imid loss: 2.360501, cmid loss: 1.972564 \n","Epoch (43), Batch(600/809), loss: 4.569240, imid loss: 2.577527, cmid loss: 1.991713 \n","Epoch (43), Batch(650/809), loss: 3.834063, imid loss: 1.876538, cmid loss: 1.957525 \n","Epoch (43), Batch(700/809), loss: 4.515925, imid loss: 2.540517, cmid loss: 1.975409 \n","Epoch (43), Batch(750/809), loss: 4.108160, imid loss: 2.142714, cmid loss: 1.965446 \n","Epoch (43), Batch(800/809), loss: 3.941030, imid loss: 1.954047, cmid loss: 1.986982 \n","Ending epoch -> 43  (training)\n","Starting epoch  43  (validation_epoch_start)\n","Starting epoch  43  (validation_step)\n","Linear Accuracy : 0.7617504051863857\n","Training 43, loss: 4.211628\n","Starting epoch -> 44  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (44), Batch(0/809), loss: 4.465693, imid loss: 2.486731, cmid loss: 1.978963 \n","Epoch (44), Batch(50/809), loss: 3.706705, imid loss: 1.717370, cmid loss: 1.989335 \n","Epoch (44), Batch(100/809), loss: 4.328783, imid loss: 2.361951, cmid loss: 1.966832 \n","Epoch (44), Batch(150/809), loss: 4.059418, imid loss: 2.089705, cmid loss: 1.969713 \n","Epoch (44), Batch(200/809), loss: 4.689084, imid loss: 2.715896, cmid loss: 1.973188 \n","Epoch (44), Batch(250/809), loss: 3.812229, imid loss: 1.831368, cmid loss: 1.980861 \n","Epoch (44), Batch(300/809), loss: 3.984180, imid loss: 1.993559, cmid loss: 1.990621 \n","Epoch (44), Batch(350/809), loss: 3.721412, imid loss: 1.738612, cmid loss: 1.982800 \n","Epoch (44), Batch(400/809), loss: 5.039074, imid loss: 3.072978, cmid loss: 1.966097 \n","Epoch (44), Batch(450/809), loss: 3.714183, imid loss: 1.732187, cmid loss: 1.981997 \n","Epoch (44), Batch(500/809), loss: 4.039729, imid loss: 2.072713, cmid loss: 1.967016 \n","Epoch (44), Batch(550/809), loss: 4.212343, imid loss: 2.236550, cmid loss: 1.975793 \n","Epoch (44), Batch(600/809), loss: 4.374539, imid loss: 2.410027, cmid loss: 1.964512 \n","Epoch (44), Batch(650/809), loss: 4.088298, imid loss: 2.113251, cmid loss: 1.975048 \n","Epoch (44), Batch(700/809), loss: 4.227488, imid loss: 2.248625, cmid loss: 1.978863 \n","Epoch (44), Batch(750/809), loss: 4.448622, imid loss: 2.484540, cmid loss: 1.964082 \n","Epoch (44), Batch(800/809), loss: 4.994504, imid loss: 3.013075, cmid loss: 1.981429 \n","Ending epoch -> 44  (training)\n","Starting epoch  44  (validation_epoch_start)\n","Starting epoch  44  (validation_step)\n","Linear Accuracy : 0.7714748784440842\n","==> Saving for frequency...\n","Training 44, loss: 4.234005\n","Starting epoch -> 45  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (45), Batch(0/809), loss: 4.003450, imid loss: 2.017160, cmid loss: 1.986290 \n","Epoch (45), Batch(50/809), loss: 4.140812, imid loss: 2.162867, cmid loss: 1.977945 \n","Epoch (45), Batch(100/809), loss: 3.942668, imid loss: 1.979832, cmid loss: 1.962836 \n","Epoch (45), Batch(150/809), loss: 4.221050, imid loss: 2.253623, cmid loss: 1.967427 \n","Epoch (45), Batch(200/809), loss: 4.464232, imid loss: 2.492168, cmid loss: 1.972064 \n","Epoch (45), Batch(250/809), loss: 4.087540, imid loss: 2.117608, cmid loss: 1.969932 \n","Epoch (45), Batch(300/809), loss: 3.978861, imid loss: 2.003999, cmid loss: 1.974862 \n","Epoch (45), Batch(350/809), loss: 4.043912, imid loss: 2.080787, cmid loss: 1.963125 \n","Epoch (45), Batch(400/809), loss: 4.096502, imid loss: 2.114413, cmid loss: 1.982089 \n","Epoch (45), Batch(450/809), loss: 4.081580, imid loss: 2.105010, cmid loss: 1.976570 \n","Epoch (45), Batch(500/809), loss: 4.375113, imid loss: 2.395080, cmid loss: 1.980032 \n","Epoch (45), Batch(550/809), loss: 4.089674, imid loss: 2.105963, cmid loss: 1.983712 \n","Epoch (45), Batch(600/809), loss: 4.275846, imid loss: 2.299950, cmid loss: 1.975895 \n","Epoch (45), Batch(650/809), loss: 4.379305, imid loss: 2.413402, cmid loss: 1.965904 \n","Epoch (45), Batch(700/809), loss: 4.177785, imid loss: 2.197019, cmid loss: 1.980766 \n","Epoch (45), Batch(750/809), loss: 3.758107, imid loss: 1.783119, cmid loss: 1.974988 \n","Epoch (45), Batch(800/809), loss: 4.286531, imid loss: 2.280697, cmid loss: 2.005835 \n","Ending epoch -> 45  (training)\n","Starting epoch  45  (validation_epoch_start)\n","Starting epoch  45  (validation_step)\n","Linear Accuracy : 0.7945705024311183\n","Training 45, loss: 4.223270\n","Starting epoch -> 46  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (46), Batch(0/809), loss: 4.549625, imid loss: 2.559646, cmid loss: 1.989979 \n","Epoch (46), Batch(50/809), loss: 4.134325, imid loss: 2.155361, cmid loss: 1.978965 \n","Epoch (46), Batch(100/809), loss: 4.242774, imid loss: 2.265431, cmid loss: 1.977342 \n","Epoch (46), Batch(150/809), loss: 4.289574, imid loss: 2.325283, cmid loss: 1.964291 \n","Epoch (46), Batch(200/809), loss: 5.241972, imid loss: 3.272435, cmid loss: 1.969537 \n","Epoch (46), Batch(250/809), loss: 4.146375, imid loss: 2.177800, cmid loss: 1.968575 \n","Epoch (46), Batch(300/809), loss: 3.723601, imid loss: 1.750418, cmid loss: 1.973182 \n","Epoch (46), Batch(350/809), loss: 3.973793, imid loss: 1.996314, cmid loss: 1.977478 \n","Epoch (46), Batch(400/809), loss: 4.783560, imid loss: 2.790015, cmid loss: 1.993545 \n","Epoch (46), Batch(450/809), loss: 3.596644, imid loss: 1.604731, cmid loss: 1.991913 \n","Epoch (46), Batch(500/809), loss: 4.353961, imid loss: 2.382304, cmid loss: 1.971657 \n","Epoch (46), Batch(550/809), loss: 4.320374, imid loss: 2.357464, cmid loss: 1.962911 \n","Epoch (46), Batch(600/809), loss: 4.135334, imid loss: 2.153969, cmid loss: 1.981365 \n","Epoch (46), Batch(650/809), loss: 4.425978, imid loss: 2.441451, cmid loss: 1.984527 \n","Epoch (46), Batch(700/809), loss: 4.237559, imid loss: 2.262888, cmid loss: 1.974671 \n","Epoch (46), Batch(750/809), loss: 4.647836, imid loss: 2.666065, cmid loss: 1.981771 \n","Epoch (46), Batch(800/809), loss: 3.998153, imid loss: 2.022525, cmid loss: 1.975629 \n","Ending epoch -> 46  (training)\n","Starting epoch  46  (validation_epoch_start)\n","Starting epoch  46  (validation_step)\n","Linear Accuracy : 0.793354943273906\n","==> Saving for frequency...\n","Training 46, loss: 4.217501\n","Starting epoch -> 47  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (47), Batch(0/809), loss: 3.901569, imid loss: 1.934035, cmid loss: 1.967534 \n","Epoch (47), Batch(50/809), loss: 3.820160, imid loss: 1.851993, cmid loss: 1.968167 \n","Epoch (47), Batch(100/809), loss: 4.067644, imid loss: 2.110319, cmid loss: 1.957325 \n","Epoch (47), Batch(150/809), loss: 4.171501, imid loss: 2.196834, cmid loss: 1.974667 \n","Epoch (47), Batch(200/809), loss: 4.941410, imid loss: 2.896303, cmid loss: 2.045106 \n","Epoch (47), Batch(250/809), loss: 3.984535, imid loss: 2.014864, cmid loss: 1.969671 \n","Epoch (47), Batch(300/809), loss: 4.352089, imid loss: 2.392012, cmid loss: 1.960077 \n","Epoch (47), Batch(350/809), loss: 3.842067, imid loss: 1.884812, cmid loss: 1.957255 \n","Epoch (47), Batch(400/809), loss: 4.194093, imid loss: 2.227213, cmid loss: 1.966880 \n","Epoch (47), Batch(450/809), loss: 4.227922, imid loss: 2.257297, cmid loss: 1.970625 \n","Epoch (47), Batch(500/809), loss: 4.258650, imid loss: 2.286473, cmid loss: 1.972177 \n","Epoch (47), Batch(550/809), loss: 4.434940, imid loss: 2.437971, cmid loss: 1.996969 \n","Epoch (47), Batch(600/809), loss: 4.793484, imid loss: 2.772443, cmid loss: 2.021041 \n","Epoch (47), Batch(650/809), loss: 3.866098, imid loss: 1.893428, cmid loss: 1.972670 \n","Epoch (47), Batch(700/809), loss: 3.433178, imid loss: 1.454629, cmid loss: 1.978548 \n","Epoch (47), Batch(750/809), loss: 4.820042, imid loss: 2.856380, cmid loss: 1.963662 \n","Epoch (47), Batch(800/809), loss: 3.886711, imid loss: 1.923896, cmid loss: 1.962815 \n","Ending epoch -> 47  (training)\n","Starting epoch  47  (validation_epoch_start)\n","Starting epoch  47  (validation_step)\n","Linear Accuracy : 0.784035656401945\n","Training 47, loss: 4.191753\n","Starting epoch -> 48  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (48), Batch(0/809), loss: 4.328690, imid loss: 2.336970, cmid loss: 1.991720 \n","Epoch (48), Batch(50/809), loss: 4.043435, imid loss: 2.071883, cmid loss: 1.971552 \n","Epoch (48), Batch(100/809), loss: 4.102389, imid loss: 2.136459, cmid loss: 1.965930 \n","Epoch (48), Batch(150/809), loss: 4.185524, imid loss: 2.213347, cmid loss: 1.972176 \n","Epoch (48), Batch(200/809), loss: 4.178623, imid loss: 2.216892, cmid loss: 1.961731 \n","Epoch (48), Batch(250/809), loss: 3.663329, imid loss: 1.695536, cmid loss: 1.967793 \n","Epoch (48), Batch(300/809), loss: 3.790586, imid loss: 1.822538, cmid loss: 1.968047 \n","Epoch (48), Batch(350/809), loss: 4.129750, imid loss: 2.162179, cmid loss: 1.967571 \n","Epoch (48), Batch(400/809), loss: 4.460950, imid loss: 2.472060, cmid loss: 1.988890 \n","Epoch (48), Batch(450/809), loss: 4.375049, imid loss: 2.416211, cmid loss: 1.958838 \n","Epoch (48), Batch(500/809), loss: 4.263856, imid loss: 2.297472, cmid loss: 1.966384 \n","Epoch (48), Batch(550/809), loss: 4.251387, imid loss: 2.283072, cmid loss: 1.968314 \n","Epoch (48), Batch(600/809), loss: 3.803300, imid loss: 1.756747, cmid loss: 2.046553 \n","Epoch (48), Batch(650/809), loss: 4.198174, imid loss: 2.226708, cmid loss: 1.971466 \n","Epoch (48), Batch(700/809), loss: 4.083405, imid loss: 2.074028, cmid loss: 2.009377 \n","Epoch (48), Batch(750/809), loss: 3.786007, imid loss: 1.793295, cmid loss: 1.992713 \n","Epoch (48), Batch(800/809), loss: 4.862697, imid loss: 2.862664, cmid loss: 2.000032 \n","Ending epoch -> 48  (training)\n","Starting epoch  48  (validation_epoch_start)\n","Starting epoch  48  (validation_step)\n","Linear Accuracy : 0.7653970826580226\n","==> Saving for frequency...\n","Training 48, loss: 4.187535\n","Starting epoch -> 49  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (49), Batch(0/809), loss: 4.004690, imid loss: 2.025074, cmid loss: 1.979617 \n","Epoch (49), Batch(50/809), loss: 4.410834, imid loss: 2.441026, cmid loss: 1.969809 \n","Epoch (49), Batch(100/809), loss: 4.975729, imid loss: 2.980443, cmid loss: 1.995286 \n","Epoch (49), Batch(150/809), loss: 4.310755, imid loss: 2.333001, cmid loss: 1.977755 \n","Epoch (49), Batch(200/809), loss: 4.353748, imid loss: 2.388398, cmid loss: 1.965350 \n","Epoch (49), Batch(250/809), loss: 4.011742, imid loss: 2.038390, cmid loss: 1.973352 \n","Epoch (49), Batch(300/809), loss: 3.943085, imid loss: 1.976847, cmid loss: 1.966238 \n","Epoch (49), Batch(350/809), loss: 4.258646, imid loss: 2.293763, cmid loss: 1.964883 \n","Epoch (49), Batch(400/809), loss: 4.747110, imid loss: 2.769151, cmid loss: 1.977959 \n","Epoch (49), Batch(450/809), loss: 4.894333, imid loss: 2.902607, cmid loss: 1.991726 \n","Epoch (49), Batch(500/809), loss: 4.053335, imid loss: 2.072768, cmid loss: 1.980567 \n","Epoch (49), Batch(550/809), loss: 3.552343, imid loss: 1.592883, cmid loss: 1.959461 \n","Epoch (49), Batch(600/809), loss: 3.832738, imid loss: 1.863606, cmid loss: 1.969132 \n","Epoch (49), Batch(650/809), loss: 3.783516, imid loss: 1.820625, cmid loss: 1.962891 \n","Epoch (49), Batch(700/809), loss: 4.028909, imid loss: 2.049956, cmid loss: 1.978953 \n","Epoch (49), Batch(750/809), loss: 4.296416, imid loss: 2.308631, cmid loss: 1.987785 \n","Epoch (49), Batch(800/809), loss: 4.462117, imid loss: 2.479529, cmid loss: 1.982588 \n","Ending epoch -> 49  (training)\n","Starting epoch  49  (validation_epoch_start)\n","Starting epoch  49  (validation_step)\n","Linear Accuracy : 0.7771474878444085\n","Training 49, loss: 4.179654\n","Starting epoch -> 50  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (50), Batch(0/809), loss: 4.218400, imid loss: 2.251773, cmid loss: 1.966627 \n","Epoch (50), Batch(50/809), loss: 4.250260, imid loss: 2.272367, cmid loss: 1.977893 \n","Epoch (50), Batch(100/809), loss: 4.059658, imid loss: 2.090860, cmid loss: 1.968798 \n","Epoch (50), Batch(150/809), loss: 3.902966, imid loss: 1.935252, cmid loss: 1.967714 \n","Epoch (50), Batch(200/809), loss: 4.903549, imid loss: 2.932726, cmid loss: 1.970823 \n","Epoch (50), Batch(250/809), loss: 4.240500, imid loss: 2.264668, cmid loss: 1.975832 \n","Epoch (50), Batch(300/809), loss: 4.534204, imid loss: 2.563519, cmid loss: 1.970684 \n","Epoch (50), Batch(350/809), loss: 4.160156, imid loss: 2.193426, cmid loss: 1.966731 \n","Epoch (50), Batch(400/809), loss: 4.272801, imid loss: 2.289843, cmid loss: 1.982959 \n","Epoch (50), Batch(450/809), loss: 3.681691, imid loss: 1.712242, cmid loss: 1.969450 \n","Epoch (50), Batch(500/809), loss: 3.832878, imid loss: 1.847479, cmid loss: 1.985399 \n","Epoch (50), Batch(550/809), loss: 4.023200, imid loss: 2.041605, cmid loss: 1.981595 \n","Epoch (50), Batch(600/809), loss: 3.934200, imid loss: 1.957784, cmid loss: 1.976416 \n","Epoch (50), Batch(650/809), loss: 3.986404, imid loss: 1.952708, cmid loss: 2.033696 \n","Epoch (50), Batch(700/809), loss: 4.308600, imid loss: 2.326603, cmid loss: 1.981997 \n","Epoch (50), Batch(750/809), loss: 4.734417, imid loss: 2.768622, cmid loss: 1.965794 \n","Epoch (50), Batch(800/809), loss: 4.475831, imid loss: 2.473455, cmid loss: 2.002377 \n","Ending epoch -> 50  (training)\n","Starting epoch  50  (validation_epoch_start)\n","Starting epoch  50  (validation_step)\n","Linear Accuracy : 0.776742301458671\n","==> Saving for frequency...\n","Training 50, loss: 4.139952\n","Starting epoch -> 51  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (51), Batch(0/809), loss: 4.094512, imid loss: 2.106420, cmid loss: 1.988092 \n","Epoch (51), Batch(50/809), loss: 3.841409, imid loss: 1.868198, cmid loss: 1.973211 \n","Epoch (51), Batch(100/809), loss: 4.569408, imid loss: 2.592998, cmid loss: 1.976410 \n","Epoch (51), Batch(150/809), loss: 4.262383, imid loss: 2.285296, cmid loss: 1.977087 \n","Epoch (51), Batch(200/809), loss: 4.216151, imid loss: 2.246442, cmid loss: 1.969709 \n","Epoch (51), Batch(250/809), loss: 3.777518, imid loss: 1.804230, cmid loss: 1.973288 \n","Epoch (51), Batch(300/809), loss: 4.106442, imid loss: 2.126363, cmid loss: 1.980079 \n","Epoch (51), Batch(350/809), loss: 4.312370, imid loss: 2.323724, cmid loss: 1.988647 \n","Epoch (51), Batch(400/809), loss: 4.414481, imid loss: 2.455430, cmid loss: 1.959051 \n","Epoch (51), Batch(450/809), loss: 3.936675, imid loss: 1.948115, cmid loss: 1.988560 \n","Epoch (51), Batch(500/809), loss: 3.882892, imid loss: 1.921473, cmid loss: 1.961419 \n","Epoch (51), Batch(550/809), loss: 3.462013, imid loss: 1.471921, cmid loss: 1.990092 \n","Epoch (51), Batch(600/809), loss: 4.530171, imid loss: 2.561340, cmid loss: 1.968831 \n","Epoch (51), Batch(650/809), loss: 4.351261, imid loss: 2.388275, cmid loss: 1.962986 \n","Epoch (51), Batch(700/809), loss: 4.251955, imid loss: 2.273387, cmid loss: 1.978568 \n","Epoch (51), Batch(750/809), loss: 4.402779, imid loss: 2.439023, cmid loss: 1.963755 \n","Epoch (51), Batch(800/809), loss: 4.107758, imid loss: 2.135705, cmid loss: 1.972053 \n","Ending epoch -> 51  (training)\n","Starting epoch  51  (validation_epoch_start)\n","Starting epoch  51  (validation_step)\n","Linear Accuracy : 0.7763371150729336\n","Training 51, loss: 4.144077\n","Starting epoch -> 52  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (52), Batch(0/809), loss: 4.372133, imid loss: 2.409237, cmid loss: 1.962896 \n","Epoch (52), Batch(50/809), loss: 3.800732, imid loss: 1.833816, cmid loss: 1.966916 \n","Epoch (52), Batch(100/809), loss: 3.594520, imid loss: 1.625240, cmid loss: 1.969280 \n","Epoch (52), Batch(150/809), loss: 4.323452, imid loss: 2.360185, cmid loss: 1.963267 \n","Epoch (52), Batch(200/809), loss: 4.176465, imid loss: 2.217785, cmid loss: 1.958680 \n","Epoch (52), Batch(250/809), loss: 4.258250, imid loss: 2.295675, cmid loss: 1.962576 \n","Epoch (52), Batch(300/809), loss: 4.209071, imid loss: 2.243127, cmid loss: 1.965944 \n","Epoch (52), Batch(350/809), loss: 4.054224, imid loss: 2.066332, cmid loss: 1.987891 \n","Epoch (52), Batch(400/809), loss: 4.630855, imid loss: 2.637675, cmid loss: 1.993180 \n","Epoch (52), Batch(450/809), loss: 3.923521, imid loss: 1.940273, cmid loss: 1.983248 \n","Epoch (52), Batch(500/809), loss: 4.602484, imid loss: 2.634992, cmid loss: 1.967492 \n","Epoch (52), Batch(550/809), loss: 3.811036, imid loss: 1.828408, cmid loss: 1.982629 \n","Epoch (52), Batch(600/809), loss: 4.020459, imid loss: 2.046895, cmid loss: 1.973564 \n","Epoch (52), Batch(650/809), loss: 4.460414, imid loss: 2.493594, cmid loss: 1.966820 \n","Epoch (52), Batch(700/809), loss: 3.941081, imid loss: 1.974066, cmid loss: 1.967015 \n","Epoch (52), Batch(750/809), loss: 4.118604, imid loss: 2.104503, cmid loss: 2.014101 \n","Epoch (52), Batch(800/809), loss: 3.932271, imid loss: 1.965853, cmid loss: 1.966419 \n","Ending epoch -> 52  (training)\n","Starting epoch  52  (validation_epoch_start)\n","Starting epoch  52  (validation_step)\n","Linear Accuracy : 0.784035656401945\n","==> Saving for frequency...\n","Training 52, loss: 4.139431\n","Starting epoch -> 53  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (53), Batch(0/809), loss: 4.051219, imid loss: 2.082866, cmid loss: 1.968353 \n","Epoch (53), Batch(50/809), loss: 5.191482, imid loss: 3.209736, cmid loss: 1.981745 \n","Epoch (53), Batch(100/809), loss: 3.589016, imid loss: 1.607284, cmid loss: 1.981732 \n","Epoch (53), Batch(150/809), loss: 4.034417, imid loss: 2.052585, cmid loss: 1.981832 \n","Epoch (53), Batch(200/809), loss: 3.915403, imid loss: 1.935122, cmid loss: 1.980281 \n","Epoch (53), Batch(250/809), loss: 3.520091, imid loss: 1.551723, cmid loss: 1.968368 \n","Epoch (53), Batch(300/809), loss: 3.972306, imid loss: 2.009846, cmid loss: 1.962460 \n","Epoch (53), Batch(350/809), loss: 4.298601, imid loss: 2.297673, cmid loss: 2.000928 \n","Epoch (53), Batch(400/809), loss: 4.369334, imid loss: 2.408234, cmid loss: 1.961100 \n","Epoch (53), Batch(450/809), loss: 4.688503, imid loss: 2.705199, cmid loss: 1.983304 \n","Epoch (53), Batch(500/809), loss: 4.265451, imid loss: 2.299081, cmid loss: 1.966370 \n","Epoch (53), Batch(550/809), loss: 4.249939, imid loss: 2.283247, cmid loss: 1.966692 \n","Epoch (53), Batch(600/809), loss: 4.022604, imid loss: 1.951586, cmid loss: 2.071019 \n","Epoch (53), Batch(650/809), loss: 4.451915, imid loss: 2.418722, cmid loss: 2.033193 \n","Epoch (53), Batch(700/809), loss: 3.931694, imid loss: 1.963383, cmid loss: 1.968310 \n","Epoch (53), Batch(750/809), loss: 3.539325, imid loss: 1.587525, cmid loss: 1.951800 \n","Epoch (53), Batch(800/809), loss: 3.646962, imid loss: 1.670619, cmid loss: 1.976343 \n","Ending epoch -> 53  (training)\n","Starting epoch  53  (validation_epoch_start)\n","Starting epoch  53  (validation_step)\n","Linear Accuracy : 0.7872771474878444\n","Training 53, loss: 4.157811\n","Starting epoch -> 54  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (54), Batch(0/809), loss: 4.029108, imid loss: 2.009255, cmid loss: 2.019853 \n","Epoch (54), Batch(50/809), loss: 3.846963, imid loss: 1.871394, cmid loss: 1.975570 \n","Epoch (54), Batch(100/809), loss: 4.538709, imid loss: 2.559431, cmid loss: 1.979279 \n","Epoch (54), Batch(150/809), loss: 3.284618, imid loss: 1.322384, cmid loss: 1.962234 \n","Epoch (54), Batch(200/809), loss: 3.678641, imid loss: 1.710922, cmid loss: 1.967718 \n","Epoch (54), Batch(250/809), loss: 4.147806, imid loss: 2.180161, cmid loss: 1.967644 \n","Epoch (54), Batch(300/809), loss: 3.998872, imid loss: 2.034024, cmid loss: 1.964847 \n","Epoch (54), Batch(350/809), loss: 3.861181, imid loss: 1.872384, cmid loss: 1.988797 \n","Epoch (54), Batch(400/809), loss: 4.075418, imid loss: 2.104058, cmid loss: 1.971360 \n","Epoch (54), Batch(450/809), loss: 4.156861, imid loss: 2.180739, cmid loss: 1.976123 \n","Epoch (54), Batch(500/809), loss: 3.908772, imid loss: 1.922688, cmid loss: 1.986083 \n","Epoch (54), Batch(550/809), loss: 4.287048, imid loss: 2.291595, cmid loss: 1.995453 \n","Epoch (54), Batch(600/809), loss: 4.590649, imid loss: 2.594341, cmid loss: 1.996307 \n","Epoch (54), Batch(650/809), loss: 4.669183, imid loss: 2.696461, cmid loss: 1.972722 \n","Epoch (54), Batch(700/809), loss: 5.037460, imid loss: 2.694267, cmid loss: 2.343193 \n","Epoch (54), Batch(750/809), loss: 4.253615, imid loss: 2.285249, cmid loss: 1.968366 \n","Epoch (54), Batch(800/809), loss: 3.985369, imid loss: 2.014259, cmid loss: 1.971111 \n","Ending epoch -> 54  (training)\n","Starting epoch  54  (validation_epoch_start)\n","Starting epoch  54  (validation_step)\n","Linear Accuracy : 0.7735008103727715\n","==> Saving for frequency...\n","Training 54, loss: 4.121596\n","Starting epoch -> 55  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (55), Batch(0/809), loss: 3.697944, imid loss: 1.738650, cmid loss: 1.959293 \n","Epoch (55), Batch(50/809), loss: 4.204687, imid loss: 2.240608, cmid loss: 1.964079 \n","Epoch (55), Batch(100/809), loss: 4.106157, imid loss: 2.134274, cmid loss: 1.971883 \n","Epoch (55), Batch(150/809), loss: 4.562953, imid loss: 2.603960, cmid loss: 1.958994 \n","Epoch (55), Batch(200/809), loss: 4.570044, imid loss: 2.597506, cmid loss: 1.972538 \n","Epoch (55), Batch(250/809), loss: 3.474404, imid loss: 1.487705, cmid loss: 1.986698 \n","Epoch (55), Batch(300/809), loss: 3.816782, imid loss: 1.861169, cmid loss: 1.955613 \n","Epoch (55), Batch(350/809), loss: 4.080293, imid loss: 2.116035, cmid loss: 1.964258 \n","Epoch (55), Batch(400/809), loss: 3.984701, imid loss: 2.008640, cmid loss: 1.976062 \n","Epoch (55), Batch(450/809), loss: 3.738346, imid loss: 1.779894, cmid loss: 1.958452 \n","Epoch (55), Batch(500/809), loss: 3.977325, imid loss: 2.008581, cmid loss: 1.968744 \n","Epoch (55), Batch(550/809), loss: 4.239638, imid loss: 2.272408, cmid loss: 1.967229 \n","Epoch (55), Batch(600/809), loss: 3.913124, imid loss: 1.945998, cmid loss: 1.967126 \n","Epoch (55), Batch(650/809), loss: 4.340731, imid loss: 2.368987, cmid loss: 1.971744 \n","Epoch (55), Batch(700/809), loss: 3.647398, imid loss: 1.646569, cmid loss: 2.000829 \n","Epoch (55), Batch(750/809), loss: 3.854137, imid loss: 1.871552, cmid loss: 1.982586 \n","Epoch (55), Batch(800/809), loss: 4.839712, imid loss: 2.875875, cmid loss: 1.963837 \n","Ending epoch -> 55  (training)\n","Starting epoch  55  (validation_epoch_start)\n","Starting epoch  55  (validation_step)\n","Linear Accuracy : 0.7811993517017828\n","Training 55, loss: 4.118110\n","Starting epoch -> 56  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (56), Batch(0/809), loss: 3.993919, imid loss: 2.022846, cmid loss: 1.971073 \n","Epoch (56), Batch(50/809), loss: 4.448048, imid loss: 2.482796, cmid loss: 1.965252 \n","Epoch (56), Batch(100/809), loss: 3.972167, imid loss: 1.997296, cmid loss: 1.974871 \n","Epoch (56), Batch(150/809), loss: 3.823006, imid loss: 1.855760, cmid loss: 1.967246 \n","Epoch (56), Batch(200/809), loss: 3.723369, imid loss: 1.636393, cmid loss: 2.086976 \n","Epoch (56), Batch(250/809), loss: 3.617476, imid loss: 1.635104, cmid loss: 1.982373 \n","Epoch (56), Batch(300/809), loss: 3.690711, imid loss: 1.725973, cmid loss: 1.964738 \n","Epoch (56), Batch(350/809), loss: 3.819442, imid loss: 1.850795, cmid loss: 1.968648 \n","Epoch (56), Batch(400/809), loss: 4.130908, imid loss: 2.148949, cmid loss: 1.981960 \n","Epoch (56), Batch(450/809), loss: 4.737348, imid loss: 2.756006, cmid loss: 1.981342 \n","Epoch (56), Batch(500/809), loss: 4.123544, imid loss: 2.154114, cmid loss: 1.969431 \n","Epoch (56), Batch(550/809), loss: 3.554219, imid loss: 1.584637, cmid loss: 1.969582 \n","Epoch (56), Batch(600/809), loss: 4.484551, imid loss: 2.522270, cmid loss: 1.962281 \n","Epoch (56), Batch(650/809), loss: 4.494546, imid loss: 2.529773, cmid loss: 1.964774 \n","Epoch (56), Batch(700/809), loss: 3.895518, imid loss: 1.916936, cmid loss: 1.978582 \n","Epoch (56), Batch(750/809), loss: 3.936445, imid loss: 1.973018, cmid loss: 1.963427 \n","Epoch (56), Batch(800/809), loss: 4.144770, imid loss: 1.947818, cmid loss: 2.196951 \n","Ending epoch -> 56  (training)\n","Starting epoch  56  (validation_epoch_start)\n","Starting epoch  56  (validation_step)\n","Linear Accuracy : 0.7893030794165316\n","==> Saving for frequency...\n","Training 56, loss: 4.104933\n","Starting epoch -> 57  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (57), Batch(0/809), loss: 3.763780, imid loss: 1.795608, cmid loss: 1.968172 \n","Epoch (57), Batch(50/809), loss: 3.886823, imid loss: 1.919394, cmid loss: 1.967429 \n","Epoch (57), Batch(100/809), loss: 3.758766, imid loss: 1.786600, cmid loss: 1.972166 \n","Epoch (57), Batch(150/809), loss: 3.770162, imid loss: 1.789562, cmid loss: 1.980600 \n","Epoch (57), Batch(200/809), loss: 4.294074, imid loss: 2.302049, cmid loss: 1.992025 \n","Epoch (57), Batch(250/809), loss: 4.068793, imid loss: 2.091774, cmid loss: 1.977020 \n","Epoch (57), Batch(300/809), loss: 4.070420, imid loss: 2.103941, cmid loss: 1.966479 \n","Epoch (57), Batch(350/809), loss: 3.676988, imid loss: 1.687294, cmid loss: 1.989694 \n","Epoch (57), Batch(400/809), loss: 4.361542, imid loss: 2.385985, cmid loss: 1.975557 \n","Epoch (57), Batch(450/809), loss: 4.699381, imid loss: 2.699022, cmid loss: 2.000359 \n","Epoch (57), Batch(500/809), loss: 4.660047, imid loss: 2.687619, cmid loss: 1.972427 \n","Epoch (57), Batch(550/809), loss: 4.078137, imid loss: 2.104729, cmid loss: 1.973408 \n","Epoch (57), Batch(600/809), loss: 4.103103, imid loss: 2.133508, cmid loss: 1.969595 \n","Epoch (57), Batch(650/809), loss: 4.089659, imid loss: 2.124976, cmid loss: 1.964683 \n","Epoch (57), Batch(700/809), loss: 3.894929, imid loss: 1.906117, cmid loss: 1.988812 \n","Epoch (57), Batch(750/809), loss: 3.991927, imid loss: 1.957466, cmid loss: 2.034461 \n","Epoch (57), Batch(800/809), loss: 3.971730, imid loss: 1.991591, cmid loss: 1.980139 \n","Ending epoch -> 57  (training)\n","Starting epoch  57  (validation_epoch_start)\n","Starting epoch  57  (validation_step)\n","Linear Accuracy : 0.7807941653160454\n","Training 57, loss: 4.075712\n","Starting epoch -> 58  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (58), Batch(0/809), loss: 3.956079, imid loss: 1.991691, cmid loss: 1.964388 \n","Epoch (58), Batch(50/809), loss: 3.891644, imid loss: 1.927954, cmid loss: 1.963689 \n","Epoch (58), Batch(100/809), loss: 4.441349, imid loss: 2.466302, cmid loss: 1.975047 \n","Epoch (58), Batch(150/809), loss: 3.780032, imid loss: 1.806022, cmid loss: 1.974010 \n","Epoch (58), Batch(200/809), loss: 3.854788, imid loss: 1.871809, cmid loss: 1.982979 \n","Epoch (58), Batch(250/809), loss: 3.568627, imid loss: 1.598210, cmid loss: 1.970417 \n","Epoch (58), Batch(300/809), loss: 4.031627, imid loss: 2.047186, cmid loss: 1.984441 \n","Epoch (58), Batch(350/809), loss: 3.786318, imid loss: 1.808852, cmid loss: 1.977467 \n","Epoch (58), Batch(400/809), loss: 3.753289, imid loss: 1.785816, cmid loss: 1.967474 \n","Epoch (58), Batch(450/809), loss: 3.450399, imid loss: 1.452252, cmid loss: 1.998147 \n","Epoch (58), Batch(500/809), loss: 3.614472, imid loss: 1.619856, cmid loss: 1.994616 \n","Epoch (58), Batch(550/809), loss: 4.531781, imid loss: 2.446503, cmid loss: 2.085278 \n","Epoch (58), Batch(600/809), loss: 4.281331, imid loss: 2.310608, cmid loss: 1.970723 \n","Epoch (58), Batch(650/809), loss: 4.731876, imid loss: 2.740894, cmid loss: 1.990982 \n","Epoch (58), Batch(700/809), loss: 3.910959, imid loss: 1.944244, cmid loss: 1.966715 \n","Epoch (58), Batch(750/809), loss: 4.524224, imid loss: 2.542725, cmid loss: 1.981499 \n","Epoch (58), Batch(800/809), loss: 3.928167, imid loss: 1.949907, cmid loss: 1.978260 \n","Ending epoch -> 58  (training)\n","Starting epoch  58  (validation_epoch_start)\n","Starting epoch  58  (validation_step)\n","Linear Accuracy : 0.7718800648298217\n","==> Saving for frequency...\n","Training 58, loss: 4.065508\n","Starting epoch -> 59  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (59), Batch(0/809), loss: 3.873706, imid loss: 1.884110, cmid loss: 1.989596 \n","Epoch (59), Batch(50/809), loss: 5.075361, imid loss: 3.114324, cmid loss: 1.961037 \n","Epoch (59), Batch(100/809), loss: 4.161730, imid loss: 2.196506, cmid loss: 1.965225 \n","Epoch (59), Batch(150/809), loss: 4.631420, imid loss: 2.628698, cmid loss: 2.002722 \n","Epoch (59), Batch(200/809), loss: 3.886370, imid loss: 1.920842, cmid loss: 1.965528 \n","Epoch (59), Batch(250/809), loss: 3.632378, imid loss: 1.653353, cmid loss: 1.979025 \n","Epoch (59), Batch(300/809), loss: 4.176733, imid loss: 2.181139, cmid loss: 1.995594 \n","Epoch (59), Batch(350/809), loss: 3.978464, imid loss: 1.998838, cmid loss: 1.979626 \n","Epoch (59), Batch(400/809), loss: 4.333681, imid loss: 2.344023, cmid loss: 1.989658 \n","Epoch (59), Batch(450/809), loss: 4.388749, imid loss: 2.427985, cmid loss: 1.960764 \n","Epoch (59), Batch(500/809), loss: 3.807642, imid loss: 1.836383, cmid loss: 1.971259 \n","Epoch (59), Batch(550/809), loss: 3.788320, imid loss: 1.828436, cmid loss: 1.959884 \n","Epoch (59), Batch(600/809), loss: 4.173397, imid loss: 2.201497, cmid loss: 1.971900 \n","Epoch (59), Batch(650/809), loss: 4.448498, imid loss: 2.483091, cmid loss: 1.965408 \n","Epoch (59), Batch(700/809), loss: 3.716490, imid loss: 1.724140, cmid loss: 1.992350 \n","Epoch (59), Batch(750/809), loss: 4.295440, imid loss: 2.336476, cmid loss: 1.958964 \n","Epoch (59), Batch(800/809), loss: 3.762036, imid loss: 1.790502, cmid loss: 1.971534 \n","Ending epoch -> 59  (training)\n","Starting epoch  59  (validation_epoch_start)\n","Starting epoch  59  (validation_step)\n","Linear Accuracy : 0.7986223662884927\n","Training 59, loss: 4.072504\n","Starting epoch -> 60  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (60), Batch(0/809), loss: 4.059784, imid loss: 2.077056, cmid loss: 1.982728 \n","Epoch (60), Batch(50/809), loss: 4.174604, imid loss: 2.209165, cmid loss: 1.965439 \n","Epoch (60), Batch(100/809), loss: 4.333053, imid loss: 2.357256, cmid loss: 1.975796 \n","Epoch (60), Batch(150/809), loss: 3.940190, imid loss: 1.975880, cmid loss: 1.964310 \n","Epoch (60), Batch(200/809), loss: 4.082854, imid loss: 2.105122, cmid loss: 1.977732 \n","Epoch (60), Batch(250/809), loss: 4.016441, imid loss: 2.042063, cmid loss: 1.974378 \n","Epoch (60), Batch(300/809), loss: 4.221635, imid loss: 2.245100, cmid loss: 1.976535 \n","Epoch (60), Batch(350/809), loss: 3.882441, imid loss: 1.908083, cmid loss: 1.974358 \n","Epoch (60), Batch(400/809), loss: 3.861647, imid loss: 1.890615, cmid loss: 1.971032 \n","Epoch (60), Batch(450/809), loss: 3.556294, imid loss: 1.592841, cmid loss: 1.963453 \n","Epoch (60), Batch(500/809), loss: 4.230145, imid loss: 2.243495, cmid loss: 1.986650 \n","Epoch (60), Batch(550/809), loss: 4.154985, imid loss: 2.190452, cmid loss: 1.964534 \n","Epoch (60), Batch(600/809), loss: 4.416581, imid loss: 2.429490, cmid loss: 1.987091 \n","Epoch (60), Batch(650/809), loss: 4.778204, imid loss: 2.804784, cmid loss: 1.973420 \n","Epoch (60), Batch(700/809), loss: 3.809478, imid loss: 1.811107, cmid loss: 1.998371 \n","Epoch (60), Batch(750/809), loss: 3.932588, imid loss: 1.967185, cmid loss: 1.965402 \n","Epoch (60), Batch(800/809), loss: 3.644839, imid loss: 1.651114, cmid loss: 1.993725 \n","Ending epoch -> 60  (training)\n","Starting epoch  60  (validation_epoch_start)\n","Starting epoch  60  (validation_step)\n","Linear Accuracy : 0.8087520259319287\n","==> NEW RECORD on accuracy on epoch  60  --- Accuracy =  0.8087520259319287  ----> SAVING Best Model...\n","==> Saving for frequency...\n","Training 60, loss: 4.070412\n","Starting epoch -> 61  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (61), Batch(0/809), loss: 4.105797, imid loss: 2.114877, cmid loss: 1.990919 \n","Epoch (61), Batch(50/809), loss: 4.326453, imid loss: 2.359383, cmid loss: 1.967070 \n","Epoch (61), Batch(100/809), loss: 3.782504, imid loss: 1.811427, cmid loss: 1.971077 \n","Epoch (61), Batch(150/809), loss: 3.075624, imid loss: 1.096388, cmid loss: 1.979236 \n","Epoch (61), Batch(200/809), loss: 3.870469, imid loss: 1.881574, cmid loss: 1.988895 \n","Epoch (61), Batch(250/809), loss: 4.269621, imid loss: 2.250300, cmid loss: 2.019321 \n","Epoch (61), Batch(300/809), loss: 3.969827, imid loss: 2.000698, cmid loss: 1.969129 \n","Epoch (61), Batch(350/809), loss: 3.640116, imid loss: 1.617464, cmid loss: 2.022652 \n","Epoch (61), Batch(400/809), loss: 4.431302, imid loss: 2.474953, cmid loss: 1.956349 \n","Epoch (61), Batch(450/809), loss: 3.575838, imid loss: 1.599725, cmid loss: 1.976112 \n","Epoch (61), Batch(500/809), loss: 4.263314, imid loss: 2.294710, cmid loss: 1.968604 \n","Epoch (61), Batch(550/809), loss: 4.191934, imid loss: 2.227077, cmid loss: 1.964856 \n","Epoch (61), Batch(600/809), loss: 4.808410, imid loss: 2.843782, cmid loss: 1.964628 \n","Epoch (61), Batch(650/809), loss: 4.435453, imid loss: 2.467785, cmid loss: 1.967668 \n","Epoch (61), Batch(700/809), loss: 3.750555, imid loss: 1.775202, cmid loss: 1.975353 \n","Epoch (61), Batch(750/809), loss: 4.153544, imid loss: 2.192196, cmid loss: 1.961349 \n","Epoch (61), Batch(800/809), loss: 4.002835, imid loss: 2.024496, cmid loss: 1.978339 \n","Ending epoch -> 61  (training)\n","Starting epoch  61  (validation_epoch_start)\n","Starting epoch  61  (validation_step)\n","Linear Accuracy : 0.8132090761750406\n","==> NEW RECORD on accuracy on epoch  61  --- Accuracy =  0.8132090761750406  ----> SAVING Best Model...\n","Training 61, loss: 4.039922\n","Starting epoch -> 62  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (62), Batch(0/809), loss: 4.076484, imid loss: 2.112075, cmid loss: 1.964409 \n","Epoch (62), Batch(50/809), loss: 3.933636, imid loss: 1.957064, cmid loss: 1.976573 \n","Epoch (62), Batch(100/809), loss: 4.115264, imid loss: 2.128013, cmid loss: 1.987252 \n","Epoch (62), Batch(150/809), loss: 4.017429, imid loss: 2.040803, cmid loss: 1.976626 \n","Epoch (62), Batch(200/809), loss: 4.042214, imid loss: 2.075075, cmid loss: 1.967140 \n","Epoch (62), Batch(250/809), loss: 4.598827, imid loss: 2.620335, cmid loss: 1.978492 \n","Epoch (62), Batch(300/809), loss: 4.547623, imid loss: 2.566984, cmid loss: 1.980639 \n","Epoch (62), Batch(350/809), loss: 3.621557, imid loss: 1.648027, cmid loss: 1.973530 \n","Epoch (62), Batch(400/809), loss: 3.877606, imid loss: 1.915291, cmid loss: 1.962315 \n","Epoch (62), Batch(450/809), loss: 3.650166, imid loss: 1.672377, cmid loss: 1.977788 \n","Epoch (62), Batch(500/809), loss: 3.978983, imid loss: 2.008778, cmid loss: 1.970205 \n","Epoch (62), Batch(550/809), loss: 3.616058, imid loss: 1.635100, cmid loss: 1.980959 \n","Epoch (62), Batch(600/809), loss: 4.237062, imid loss: 2.279811, cmid loss: 1.957251 \n","Epoch (62), Batch(650/809), loss: 4.029006, imid loss: 2.000852, cmid loss: 2.028154 \n","Epoch (62), Batch(700/809), loss: 3.818537, imid loss: 1.813372, cmid loss: 2.005166 \n","Epoch (62), Batch(750/809), loss: 3.397086, imid loss: 1.425629, cmid loss: 1.971458 \n","Epoch (62), Batch(800/809), loss: 4.270529, imid loss: 2.270732, cmid loss: 1.999797 \n","Ending epoch -> 62  (training)\n","Starting epoch  62  (validation_epoch_start)\n","Starting epoch  62  (validation_step)\n","Linear Accuracy : 0.8209076175040518\n","==> NEW RECORD on accuracy on epoch  62  --- Accuracy =  0.8209076175040518  ----> SAVING Best Model...\n","==> Saving for frequency...\n","Training 62, loss: 4.025800\n","Starting epoch -> 63  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (63), Batch(0/809), loss: 4.167008, imid loss: 2.196603, cmid loss: 1.970405 \n","Epoch (63), Batch(50/809), loss: 4.097732, imid loss: 2.130685, cmid loss: 1.967047 \n","Epoch (63), Batch(100/809), loss: 3.834438, imid loss: 1.787707, cmid loss: 2.046731 \n","Epoch (63), Batch(150/809), loss: 3.723888, imid loss: 1.748564, cmid loss: 1.975323 \n","Epoch (63), Batch(200/809), loss: 3.644398, imid loss: 1.662491, cmid loss: 1.981907 \n","Epoch (63), Batch(250/809), loss: 3.904358, imid loss: 1.927368, cmid loss: 1.976990 \n","Epoch (63), Batch(300/809), loss: 4.663361, imid loss: 2.691099, cmid loss: 1.972261 \n","Epoch (63), Batch(350/809), loss: 3.818588, imid loss: 1.858766, cmid loss: 1.959822 \n","Epoch (63), Batch(400/809), loss: 4.058248, imid loss: 2.100843, cmid loss: 1.957404 \n","Epoch (63), Batch(450/809), loss: 3.474658, imid loss: 1.496627, cmid loss: 1.978032 \n","Epoch (63), Batch(500/809), loss: 4.382321, imid loss: 2.391637, cmid loss: 1.990685 \n","Epoch (63), Batch(550/809), loss: 3.815055, imid loss: 1.860094, cmid loss: 1.954961 \n","Epoch (63), Batch(600/809), loss: 3.486639, imid loss: 1.463531, cmid loss: 2.023109 \n","Epoch (63), Batch(650/809), loss: 3.604736, imid loss: 1.543905, cmid loss: 2.060831 \n","Epoch (63), Batch(700/809), loss: 3.794927, imid loss: 1.819761, cmid loss: 1.975166 \n","Epoch (63), Batch(750/809), loss: 3.977202, imid loss: 2.025092, cmid loss: 1.952110 \n","Epoch (63), Batch(800/809), loss: 4.426052, imid loss: 2.438995, cmid loss: 1.987056 \n","Ending epoch -> 63  (training)\n","Starting epoch  63  (validation_epoch_start)\n","Starting epoch  63  (validation_step)\n","Linear Accuracy : 0.8205024311183144\n","Training 63, loss: 4.003797\n","Starting epoch -> 64  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (64), Batch(0/809), loss: 5.181016, imid loss: 3.180737, cmid loss: 2.000279 \n","Epoch (64), Batch(50/809), loss: 3.677947, imid loss: 1.703343, cmid loss: 1.974604 \n","Epoch (64), Batch(100/809), loss: 3.925717, imid loss: 1.964864, cmid loss: 1.960852 \n","Epoch (64), Batch(150/809), loss: 3.990414, imid loss: 2.032852, cmid loss: 1.957561 \n","Epoch (64), Batch(200/809), loss: 4.262167, imid loss: 2.297909, cmid loss: 1.964259 \n","Epoch (64), Batch(250/809), loss: 4.081771, imid loss: 2.116783, cmid loss: 1.964988 \n","Epoch (64), Batch(300/809), loss: 3.860997, imid loss: 1.898190, cmid loss: 1.962807 \n","Epoch (64), Batch(350/809), loss: 4.083355, imid loss: 2.105325, cmid loss: 1.978030 \n","Epoch (64), Batch(400/809), loss: 4.132966, imid loss: 2.133322, cmid loss: 1.999645 \n","Epoch (64), Batch(450/809), loss: 4.318809, imid loss: 2.336555, cmid loss: 1.982253 \n","Epoch (64), Batch(500/809), loss: 3.578233, imid loss: 1.602689, cmid loss: 1.975544 \n","Epoch (64), Batch(550/809), loss: 3.734443, imid loss: 1.764308, cmid loss: 1.970134 \n","Epoch (64), Batch(600/809), loss: 4.067275, imid loss: 2.084222, cmid loss: 1.983053 \n","Epoch (64), Batch(650/809), loss: 3.612659, imid loss: 1.622599, cmid loss: 1.990060 \n","Epoch (64), Batch(700/809), loss: 3.392208, imid loss: 1.421011, cmid loss: 1.971196 \n","Epoch (64), Batch(750/809), loss: 4.248683, imid loss: 2.266722, cmid loss: 1.981961 \n","Epoch (64), Batch(800/809), loss: 4.024534, imid loss: 2.061346, cmid loss: 1.963188 \n","Ending epoch -> 64  (training)\n","Starting epoch  64  (validation_epoch_start)\n","Starting epoch  64  (validation_step)\n","Linear Accuracy : 0.8180713128038898\n","==> Saving for frequency...\n","Training 64, loss: 3.981067\n","Starting epoch -> 65  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (65), Batch(0/809), loss: 3.394760, imid loss: 1.395984, cmid loss: 1.998775 \n","Epoch (65), Batch(50/809), loss: 3.817109, imid loss: 1.857278, cmid loss: 1.959831 \n","Epoch (65), Batch(100/809), loss: 4.288458, imid loss: 2.316090, cmid loss: 1.972368 \n","Epoch (65), Batch(150/809), loss: 3.876529, imid loss: 1.773483, cmid loss: 2.103046 \n","Epoch (65), Batch(200/809), loss: 4.654148, imid loss: 2.660119, cmid loss: 1.994029 \n","Epoch (65), Batch(250/809), loss: 4.130751, imid loss: 2.150284, cmid loss: 1.980467 \n","Epoch (65), Batch(300/809), loss: 3.716345, imid loss: 1.748111, cmid loss: 1.968234 \n","Epoch (65), Batch(350/809), loss: 3.695619, imid loss: 1.681904, cmid loss: 2.013715 \n","Epoch (65), Batch(400/809), loss: 4.841321, imid loss: 2.872690, cmid loss: 1.968631 \n","Epoch (65), Batch(450/809), loss: 3.502825, imid loss: 1.499870, cmid loss: 2.002954 \n","Epoch (65), Batch(500/809), loss: 4.267709, imid loss: 2.250922, cmid loss: 2.016787 \n","Epoch (65), Batch(550/809), loss: 3.952926, imid loss: 1.979967, cmid loss: 1.972959 \n","Epoch (65), Batch(600/809), loss: 3.966151, imid loss: 1.986934, cmid loss: 1.979217 \n","Epoch (65), Batch(650/809), loss: 3.828894, imid loss: 1.850226, cmid loss: 1.978668 \n","Epoch (65), Batch(700/809), loss: 4.197753, imid loss: 2.234880, cmid loss: 1.962873 \n","Epoch (65), Batch(750/809), loss: 3.659856, imid loss: 1.677802, cmid loss: 1.982054 \n","Epoch (65), Batch(800/809), loss: 4.357584, imid loss: 2.388860, cmid loss: 1.968723 \n","Ending epoch -> 65  (training)\n","Starting epoch  65  (validation_epoch_start)\n","Starting epoch  65  (validation_step)\n","Linear Accuracy : 0.8225283630470016\n","==> NEW RECORD on accuracy on epoch  65  --- Accuracy =  0.8225283630470016  ----> SAVING Best Model...\n","Training 65, loss: 3.966668\n","Starting epoch -> 66  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (66), Batch(0/809), loss: 4.047644, imid loss: 2.078090, cmid loss: 1.969554 \n","Epoch (66), Batch(50/809), loss: 4.142917, imid loss: 2.179003, cmid loss: 1.963915 \n","Epoch (66), Batch(100/809), loss: 4.207587, imid loss: 2.223669, cmid loss: 1.983918 \n","Epoch (66), Batch(150/809), loss: 4.090756, imid loss: 2.125444, cmid loss: 1.965312 \n","Epoch (66), Batch(200/809), loss: 3.789267, imid loss: 1.819795, cmid loss: 1.969472 \n","Epoch (66), Batch(250/809), loss: 4.104730, imid loss: 2.126474, cmid loss: 1.978256 \n","Epoch (66), Batch(300/809), loss: 4.329668, imid loss: 2.360316, cmid loss: 1.969352 \n","Epoch (66), Batch(350/809), loss: 3.406664, imid loss: 1.421201, cmid loss: 1.985463 \n","Epoch (66), Batch(400/809), loss: 3.765799, imid loss: 1.781869, cmid loss: 1.983931 \n","Epoch (66), Batch(450/809), loss: 3.493261, imid loss: 1.479199, cmid loss: 2.014062 \n","Epoch (66), Batch(500/809), loss: 3.553020, imid loss: 1.586763, cmid loss: 1.966256 \n","Epoch (66), Batch(550/809), loss: 3.577165, imid loss: 1.618573, cmid loss: 1.958593 \n","Epoch (66), Batch(600/809), loss: 3.906087, imid loss: 1.906247, cmid loss: 1.999839 \n","Epoch (66), Batch(650/809), loss: 3.564820, imid loss: 1.566767, cmid loss: 1.998053 \n","Epoch (66), Batch(700/809), loss: 3.585073, imid loss: 1.554946, cmid loss: 2.030127 \n","Epoch (66), Batch(750/809), loss: 3.172178, imid loss: 1.175591, cmid loss: 1.996587 \n","Epoch (66), Batch(800/809), loss: 3.729778, imid loss: 1.741342, cmid loss: 1.988436 \n","Ending epoch -> 66  (training)\n","Starting epoch  66  (validation_epoch_start)\n","Starting epoch  66  (validation_step)\n","Linear Accuracy : 0.8237439222042139\n","==> NEW RECORD on accuracy on epoch  66  --- Accuracy =  0.8237439222042139  ----> SAVING Best Model...\n","==> Saving for frequency...\n","Training 66, loss: 3.950114\n","Starting epoch -> 67  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (67), Batch(0/809), loss: 3.725599, imid loss: 1.763437, cmid loss: 1.962163 \n","Epoch (67), Batch(50/809), loss: 3.870303, imid loss: 1.890918, cmid loss: 1.979385 \n","Epoch (67), Batch(100/809), loss: 3.960735, imid loss: 1.922403, cmid loss: 2.038332 \n","Epoch (67), Batch(150/809), loss: 3.987091, imid loss: 2.020618, cmid loss: 1.966473 \n","Epoch (67), Batch(200/809), loss: 3.995455, imid loss: 2.013915, cmid loss: 1.981540 \n","Epoch (67), Batch(250/809), loss: 4.087653, imid loss: 2.112983, cmid loss: 1.974670 \n","Epoch (67), Batch(300/809), loss: 4.118993, imid loss: 2.147285, cmid loss: 1.971708 \n","Epoch (67), Batch(350/809), loss: 3.186750, imid loss: 1.207397, cmid loss: 1.979354 \n","Epoch (67), Batch(400/809), loss: 3.549690, imid loss: 1.530671, cmid loss: 2.019019 \n","Epoch (67), Batch(450/809), loss: 4.052235, imid loss: 2.060664, cmid loss: 1.991571 \n","Epoch (67), Batch(500/809), loss: 3.284286, imid loss: 1.321037, cmid loss: 1.963248 \n","Epoch (67), Batch(550/809), loss: 3.974800, imid loss: 2.017524, cmid loss: 1.957276 \n","Epoch (67), Batch(600/809), loss: 3.820547, imid loss: 1.855422, cmid loss: 1.965125 \n","Epoch (67), Batch(650/809), loss: 3.726238, imid loss: 1.720825, cmid loss: 2.005413 \n","Epoch (67), Batch(700/809), loss: 3.601756, imid loss: 1.624396, cmid loss: 1.977360 \n","Epoch (67), Batch(750/809), loss: 3.635952, imid loss: 1.657860, cmid loss: 1.978092 \n","Epoch (67), Batch(800/809), loss: 3.662487, imid loss: 1.687367, cmid loss: 1.975120 \n","Ending epoch -> 67  (training)\n","Starting epoch  67  (validation_epoch_start)\n","Starting epoch  67  (validation_step)\n","Linear Accuracy : 0.8294165316045381\n","==> NEW RECORD on accuracy on epoch  67  --- Accuracy =  0.8294165316045381  ----> SAVING Best Model...\n","Training 67, loss: 3.932436\n","Starting epoch -> 68  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (68), Batch(0/809), loss: 3.911476, imid loss: 1.909878, cmid loss: 2.001598 \n","Epoch (68), Batch(50/809), loss: 4.797115, imid loss: 2.742527, cmid loss: 2.054589 \n","Epoch (68), Batch(100/809), loss: 3.664612, imid loss: 1.637740, cmid loss: 2.026872 \n","Epoch (68), Batch(150/809), loss: 3.511919, imid loss: 1.527816, cmid loss: 1.984103 \n","Epoch (68), Batch(200/809), loss: 3.557823, imid loss: 1.546222, cmid loss: 2.011601 \n","Epoch (68), Batch(250/809), loss: 3.823061, imid loss: 1.851386, cmid loss: 1.971674 \n","Epoch (68), Batch(300/809), loss: 3.778724, imid loss: 1.807040, cmid loss: 1.971684 \n","Epoch (68), Batch(350/809), loss: 3.658073, imid loss: 1.687927, cmid loss: 1.970147 \n","Epoch (68), Batch(400/809), loss: 4.001544, imid loss: 2.003050, cmid loss: 1.998494 \n","Epoch (68), Batch(450/809), loss: 4.267565, imid loss: 2.244659, cmid loss: 2.022906 \n","Epoch (68), Batch(500/809), loss: 4.405572, imid loss: 2.447870, cmid loss: 1.957702 \n","Epoch (68), Batch(550/809), loss: 4.259329, imid loss: 2.196575, cmid loss: 2.062754 \n","Epoch (68), Batch(600/809), loss: 3.654124, imid loss: 1.690665, cmid loss: 1.963459 \n","Epoch (68), Batch(650/809), loss: 4.005822, imid loss: 2.041173, cmid loss: 1.964650 \n","Epoch (68), Batch(700/809), loss: 3.984466, imid loss: 1.937077, cmid loss: 2.047389 \n","Epoch (68), Batch(750/809), loss: 3.666486, imid loss: 1.713615, cmid loss: 1.952871 \n","Epoch (68), Batch(800/809), loss: 3.927258, imid loss: 1.950172, cmid loss: 1.977086 \n","Ending epoch -> 68  (training)\n","Starting epoch  68  (validation_epoch_start)\n","Starting epoch  68  (validation_step)\n","Linear Accuracy : 0.8184764991896273\n","==> Saving for frequency...\n","Training 68, loss: 3.931581\n","Starting epoch -> 69  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (69), Batch(0/809), loss: 4.063732, imid loss: 2.094697, cmid loss: 1.969035 \n","Epoch (69), Batch(50/809), loss: 3.888559, imid loss: 1.886112, cmid loss: 2.002446 \n","Epoch (69), Batch(100/809), loss: 4.952945, imid loss: 2.971468, cmid loss: 1.981477 \n","Epoch (69), Batch(150/809), loss: 3.769386, imid loss: 1.715109, cmid loss: 2.054278 \n","Epoch (69), Batch(200/809), loss: 3.591811, imid loss: 1.525174, cmid loss: 2.066638 \n","Epoch (69), Batch(250/809), loss: 3.631724, imid loss: 1.650410, cmid loss: 1.981314 \n","Epoch (69), Batch(300/809), loss: 4.252872, imid loss: 2.227513, cmid loss: 2.025359 \n","Epoch (69), Batch(350/809), loss: 3.429900, imid loss: 1.417314, cmid loss: 2.012585 \n","Epoch (69), Batch(400/809), loss: 4.146996, imid loss: 2.183108, cmid loss: 1.963888 \n","Epoch (69), Batch(450/809), loss: 4.858978, imid loss: 2.858841, cmid loss: 2.000137 \n","Epoch (69), Batch(500/809), loss: 3.295210, imid loss: 1.283336, cmid loss: 2.011874 \n","Epoch (69), Batch(550/809), loss: 3.537750, imid loss: 1.563067, cmid loss: 1.974683 \n","Epoch (69), Batch(600/809), loss: 3.725516, imid loss: 1.752866, cmid loss: 1.972650 \n","Epoch (69), Batch(650/809), loss: 3.661787, imid loss: 1.672597, cmid loss: 1.989190 \n","Epoch (69), Batch(700/809), loss: 3.779859, imid loss: 1.810158, cmid loss: 1.969701 \n","Epoch (69), Batch(750/809), loss: 3.852327, imid loss: 1.856303, cmid loss: 1.996024 \n","Epoch (69), Batch(800/809), loss: 4.068358, imid loss: 2.109349, cmid loss: 1.959010 \n","Ending epoch -> 69  (training)\n","Starting epoch  69  (validation_epoch_start)\n","Starting epoch  69  (validation_step)\n","Linear Accuracy : 0.8217179902755267\n","Training 69, loss: 3.915103\n","Starting epoch -> 70  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (70), Batch(0/809), loss: 3.614905, imid loss: 1.647063, cmid loss: 1.967842 \n","Epoch (70), Batch(50/809), loss: 3.715729, imid loss: 1.733951, cmid loss: 1.981777 \n","Epoch (70), Batch(100/809), loss: 4.181489, imid loss: 2.217278, cmid loss: 1.964211 \n","Epoch (70), Batch(150/809), loss: 4.815752, imid loss: 2.721931, cmid loss: 2.093821 \n","Epoch (70), Batch(200/809), loss: 3.984206, imid loss: 2.018449, cmid loss: 1.965757 \n","Epoch (70), Batch(250/809), loss: 4.450315, imid loss: 2.468562, cmid loss: 1.981754 \n","Epoch (70), Batch(300/809), loss: 4.319852, imid loss: 2.331516, cmid loss: 1.988336 \n","Epoch (70), Batch(350/809), loss: 3.683672, imid loss: 1.670126, cmid loss: 2.013547 \n","Epoch (70), Batch(400/809), loss: 3.759291, imid loss: 1.788795, cmid loss: 1.970496 \n","Epoch (70), Batch(450/809), loss: 4.234586, imid loss: 2.215573, cmid loss: 2.019013 \n","Epoch (70), Batch(500/809), loss: 3.968603, imid loss: 1.962252, cmid loss: 2.006351 \n","Epoch (70), Batch(550/809), loss: 3.842849, imid loss: 1.862939, cmid loss: 1.979910 \n","Epoch (70), Batch(600/809), loss: 4.695601, imid loss: 2.595711, cmid loss: 2.099890 \n","Epoch (70), Batch(650/809), loss: 4.272667, imid loss: 2.312680, cmid loss: 1.959987 \n","Epoch (70), Batch(700/809), loss: 4.102932, imid loss: 2.113412, cmid loss: 1.989520 \n","Epoch (70), Batch(750/809), loss: 3.587674, imid loss: 1.603287, cmid loss: 1.984386 \n","Epoch (70), Batch(800/809), loss: 4.253672, imid loss: 2.256961, cmid loss: 1.996710 \n","Ending epoch -> 70  (training)\n","Starting epoch  70  (validation_epoch_start)\n","Starting epoch  70  (validation_step)\n","Linear Accuracy : 0.8233387358184765\n","==> Saving for frequency...\n","Training 70, loss: 3.917951\n","Starting epoch -> 71  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (71), Batch(0/809), loss: 3.604883, imid loss: 1.615632, cmid loss: 1.989251 \n","Epoch (71), Batch(50/809), loss: 4.240567, imid loss: 2.278314, cmid loss: 1.962253 \n","Epoch (71), Batch(100/809), loss: 3.492656, imid loss: 1.461116, cmid loss: 2.031539 \n","Epoch (71), Batch(150/809), loss: 4.287362, imid loss: 2.323770, cmid loss: 1.963592 \n","Epoch (71), Batch(200/809), loss: 3.357627, imid loss: 1.380940, cmid loss: 1.976688 \n","Epoch (71), Batch(250/809), loss: 3.885352, imid loss: 1.920501, cmid loss: 1.964851 \n","Epoch (71), Batch(300/809), loss: 4.153904, imid loss: 2.194150, cmid loss: 1.959754 \n","Epoch (71), Batch(350/809), loss: 3.483398, imid loss: 1.510203, cmid loss: 1.973195 \n","Epoch (71), Batch(400/809), loss: 4.274966, imid loss: 2.263474, cmid loss: 2.011492 \n","Epoch (71), Batch(450/809), loss: 3.672686, imid loss: 1.698602, cmid loss: 1.974084 \n","Epoch (71), Batch(500/809), loss: 4.223926, imid loss: 2.266416, cmid loss: 1.957510 \n","Epoch (71), Batch(550/809), loss: 3.767190, imid loss: 1.665543, cmid loss: 2.101647 \n","Epoch (71), Batch(600/809), loss: 3.699934, imid loss: 1.725977, cmid loss: 1.973956 \n","Epoch (71), Batch(650/809), loss: 3.713187, imid loss: 1.727365, cmid loss: 1.985822 \n","Epoch (71), Batch(700/809), loss: 3.792314, imid loss: 1.824155, cmid loss: 1.968158 \n","Epoch (71), Batch(750/809), loss: 4.371352, imid loss: 2.394129, cmid loss: 1.977223 \n","Epoch (71), Batch(800/809), loss: 3.896744, imid loss: 1.919734, cmid loss: 1.977011 \n","Ending epoch -> 71  (training)\n","Starting epoch  71  (validation_epoch_start)\n","Starting epoch  71  (validation_step)\n","Linear Accuracy : 0.826580226904376\n","Training 71, loss: 3.891045\n","Starting epoch -> 72  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (72), Batch(0/809), loss: 5.002300, imid loss: 3.026615, cmid loss: 1.975686 \n","Epoch (72), Batch(50/809), loss: 3.726523, imid loss: 1.746565, cmid loss: 1.979958 \n","Epoch (72), Batch(100/809), loss: 3.727182, imid loss: 1.765216, cmid loss: 1.961966 \n","Epoch (72), Batch(150/809), loss: 3.501140, imid loss: 1.525681, cmid loss: 1.975459 \n","Epoch (72), Batch(200/809), loss: 3.925316, imid loss: 1.939703, cmid loss: 1.985613 \n","Epoch (72), Batch(250/809), loss: 4.099623, imid loss: 2.125816, cmid loss: 1.973807 \n","Epoch (72), Batch(300/809), loss: 4.796449, imid loss: 2.820697, cmid loss: 1.975752 \n","Epoch (72), Batch(350/809), loss: 3.450031, imid loss: 1.467001, cmid loss: 1.983030 \n","Epoch (72), Batch(400/809), loss: 3.893673, imid loss: 1.917842, cmid loss: 1.975832 \n","Epoch (72), Batch(450/809), loss: 3.734986, imid loss: 1.761069, cmid loss: 1.973917 \n","Epoch (72), Batch(500/809), loss: 4.561012, imid loss: 2.510432, cmid loss: 2.050580 \n","Epoch (72), Batch(550/809), loss: 3.527138, imid loss: 1.550095, cmid loss: 1.977043 \n","Epoch (72), Batch(600/809), loss: 4.034177, imid loss: 2.059194, cmid loss: 1.974983 \n","Epoch (72), Batch(650/809), loss: 4.412846, imid loss: 2.440580, cmid loss: 1.972266 \n","Epoch (72), Batch(700/809), loss: 4.214251, imid loss: 2.238230, cmid loss: 1.976021 \n","Epoch (72), Batch(750/809), loss: 4.001065, imid loss: 2.019462, cmid loss: 1.981603 \n","Epoch (72), Batch(800/809), loss: 3.664997, imid loss: 1.664857, cmid loss: 2.000140 \n","Ending epoch -> 72  (training)\n","Starting epoch  72  (validation_epoch_start)\n","Starting epoch  72  (validation_step)\n","Linear Accuracy : 0.8229335494327391\n","==> Saving for frequency...\n","Training 72, loss: 3.868854\n","Starting epoch -> 73  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (73), Batch(0/809), loss: 3.839763, imid loss: 1.863797, cmid loss: 1.975965 \n","Epoch (73), Batch(50/809), loss: 4.078686, imid loss: 2.110446, cmid loss: 1.968240 \n","Epoch (73), Batch(100/809), loss: 4.054420, imid loss: 1.997422, cmid loss: 2.056998 \n","Epoch (73), Batch(150/809), loss: 4.190508, imid loss: 2.215684, cmid loss: 1.974824 \n","Epoch (73), Batch(200/809), loss: 4.103678, imid loss: 2.122141, cmid loss: 1.981537 \n","Epoch (73), Batch(250/809), loss: 4.062046, imid loss: 2.101664, cmid loss: 1.960382 \n","Epoch (73), Batch(300/809), loss: 4.548871, imid loss: 2.584663, cmid loss: 1.964207 \n","Epoch (73), Batch(350/809), loss: 3.910705, imid loss: 1.925538, cmid loss: 1.985166 \n","Epoch (73), Batch(400/809), loss: 3.439225, imid loss: 1.468211, cmid loss: 1.971014 \n","Epoch (73), Batch(450/809), loss: 3.755436, imid loss: 1.742304, cmid loss: 2.013132 \n","Epoch (73), Batch(500/809), loss: 3.504599, imid loss: 1.539321, cmid loss: 1.965278 \n","Epoch (73), Batch(550/809), loss: 3.615072, imid loss: 1.620209, cmid loss: 1.994862 \n","Epoch (73), Batch(600/809), loss: 3.956861, imid loss: 1.996153, cmid loss: 1.960709 \n","Epoch (73), Batch(650/809), loss: 4.029691, imid loss: 2.019636, cmid loss: 2.010055 \n","Epoch (73), Batch(700/809), loss: 3.744037, imid loss: 1.758174, cmid loss: 1.985863 \n","Epoch (73), Batch(750/809), loss: 3.583797, imid loss: 1.620031, cmid loss: 1.963767 \n","Epoch (73), Batch(800/809), loss: 4.204407, imid loss: 2.238454, cmid loss: 1.965953 \n","Ending epoch -> 73  (training)\n","Starting epoch  73  (validation_epoch_start)\n","Starting epoch  73  (validation_step)\n","Linear Accuracy : 0.8176661264181524\n","Training 73, loss: 3.867244\n","Starting epoch -> 74  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (74), Batch(0/809), loss: 4.073915, imid loss: 2.098684, cmid loss: 1.975230 \n","Epoch (74), Batch(50/809), loss: 3.486826, imid loss: 1.502415, cmid loss: 1.984411 \n","Epoch (74), Batch(100/809), loss: 3.860026, imid loss: 1.876616, cmid loss: 1.983410 \n","Epoch (74), Batch(150/809), loss: 3.303207, imid loss: 1.326058, cmid loss: 1.977149 \n","Epoch (74), Batch(200/809), loss: 4.037708, imid loss: 2.058132, cmid loss: 1.979577 \n","Epoch (74), Batch(250/809), loss: 3.327839, imid loss: 1.347939, cmid loss: 1.979900 \n","Epoch (74), Batch(300/809), loss: 3.721291, imid loss: 1.736890, cmid loss: 1.984401 \n","Epoch (74), Batch(350/809), loss: 3.596344, imid loss: 1.564881, cmid loss: 2.031463 \n","Epoch (74), Batch(400/809), loss: 3.570944, imid loss: 1.581856, cmid loss: 1.989088 \n","Epoch (74), Batch(450/809), loss: 3.444342, imid loss: 1.452683, cmid loss: 1.991659 \n","Epoch (74), Batch(500/809), loss: 3.583414, imid loss: 1.575053, cmid loss: 2.008361 \n","Epoch (74), Batch(550/809), loss: 3.595130, imid loss: 1.582330, cmid loss: 2.012800 \n","Epoch (74), Batch(600/809), loss: 3.795982, imid loss: 1.835316, cmid loss: 1.960666 \n","Epoch (74), Batch(650/809), loss: 3.728891, imid loss: 1.741823, cmid loss: 1.987068 \n","Epoch (74), Batch(700/809), loss: 4.026210, imid loss: 2.056235, cmid loss: 1.969975 \n","Epoch (74), Batch(750/809), loss: 3.645026, imid loss: 1.655423, cmid loss: 1.989602 \n","Epoch (74), Batch(800/809), loss: 3.685601, imid loss: 1.684438, cmid loss: 2.001163 \n","Ending epoch -> 74  (training)\n","Starting epoch  74  (validation_epoch_start)\n","Starting epoch  74  (validation_step)\n","Linear Accuracy : 0.8225283630470016\n","==> Saving for frequency...\n","Training 74, loss: 3.852460\n","Starting epoch -> 75  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (75), Batch(0/809), loss: 3.402091, imid loss: 1.433233, cmid loss: 1.968858 \n","Epoch (75), Batch(50/809), loss: 3.460594, imid loss: 1.482864, cmid loss: 1.977730 \n","Epoch (75), Batch(100/809), loss: 3.668319, imid loss: 1.715994, cmid loss: 1.952325 \n","Epoch (75), Batch(150/809), loss: 3.978489, imid loss: 1.986573, cmid loss: 1.991916 \n","Epoch (75), Batch(200/809), loss: 3.827126, imid loss: 1.777111, cmid loss: 2.050015 \n","Epoch (75), Batch(250/809), loss: 3.595019, imid loss: 1.629471, cmid loss: 1.965548 \n","Epoch (75), Batch(300/809), loss: 3.705534, imid loss: 1.715584, cmid loss: 1.989949 \n","Epoch (75), Batch(350/809), loss: 4.068739, imid loss: 2.110033, cmid loss: 1.958707 \n","Epoch (75), Batch(400/809), loss: 4.022036, imid loss: 2.021177, cmid loss: 2.000859 \n","Epoch (75), Batch(450/809), loss: 3.647532, imid loss: 1.680925, cmid loss: 1.966607 \n","Epoch (75), Batch(500/809), loss: 3.739140, imid loss: 1.773274, cmid loss: 1.965866 \n","Epoch (75), Batch(550/809), loss: 3.666056, imid loss: 1.665649, cmid loss: 2.000407 \n","Epoch (75), Batch(600/809), loss: 3.885698, imid loss: 1.893759, cmid loss: 1.991939 \n","Epoch (75), Batch(650/809), loss: 3.292094, imid loss: 1.322372, cmid loss: 1.969722 \n","Epoch (75), Batch(700/809), loss: 3.506042, imid loss: 1.514834, cmid loss: 1.991207 \n","Epoch (75), Batch(750/809), loss: 3.756428, imid loss: 1.795185, cmid loss: 1.961243 \n","Epoch (75), Batch(800/809), loss: 4.044465, imid loss: 2.074488, cmid loss: 1.969976 \n","Ending epoch -> 75  (training)\n","Starting epoch  75  (validation_epoch_start)\n","Starting epoch  75  (validation_step)\n","Linear Accuracy : 0.8290113452188006\n","Training 75, loss: 3.830028\n","Starting epoch -> 76  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (76), Batch(0/809), loss: 3.579483, imid loss: 1.558516, cmid loss: 2.020967 \n","Epoch (76), Batch(50/809), loss: 3.554340, imid loss: 1.565624, cmid loss: 1.988716 \n","Epoch (76), Batch(100/809), loss: 3.461013, imid loss: 1.487017, cmid loss: 1.973996 \n","Epoch (76), Batch(150/809), loss: 3.298378, imid loss: 1.265165, cmid loss: 2.033213 \n","Epoch (76), Batch(200/809), loss: 3.502884, imid loss: 1.513286, cmid loss: 1.989598 \n","Epoch (76), Batch(250/809), loss: 3.590437, imid loss: 1.579657, cmid loss: 2.010780 \n","Epoch (76), Batch(300/809), loss: 3.859119, imid loss: 1.818375, cmid loss: 2.040744 \n","Epoch (76), Batch(350/809), loss: 3.555737, imid loss: 1.586567, cmid loss: 1.969170 \n","Epoch (76), Batch(400/809), loss: 4.112053, imid loss: 2.110648, cmid loss: 2.001404 \n","Epoch (76), Batch(450/809), loss: 3.536792, imid loss: 1.562239, cmid loss: 1.974553 \n","Epoch (76), Batch(500/809), loss: 3.578367, imid loss: 1.613570, cmid loss: 1.964797 \n","Epoch (76), Batch(550/809), loss: 3.629118, imid loss: 1.666025, cmid loss: 1.963094 \n","Epoch (76), Batch(600/809), loss: 3.953890, imid loss: 1.958933, cmid loss: 1.994957 \n","Epoch (76), Batch(650/809), loss: 3.557827, imid loss: 1.584640, cmid loss: 1.973187 \n","Epoch (76), Batch(700/809), loss: 3.452946, imid loss: 1.489560, cmid loss: 1.963386 \n","Epoch (76), Batch(750/809), loss: 3.786024, imid loss: 1.791341, cmid loss: 1.994683 \n","Epoch (76), Batch(800/809), loss: 3.526923, imid loss: 1.500834, cmid loss: 2.026089 \n","Ending epoch -> 76  (training)\n","Starting epoch  76  (validation_epoch_start)\n","Starting epoch  76  (validation_step)\n","Linear Accuracy : 0.8286061588330632\n","==> Saving for frequency...\n","Training 76, loss: 3.823392\n","Starting epoch -> 77  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (77), Batch(0/809), loss: 3.919032, imid loss: 1.942571, cmid loss: 1.976461 \n","Epoch (77), Batch(50/809), loss: 4.190420, imid loss: 2.201995, cmid loss: 1.988425 \n","Epoch (77), Batch(100/809), loss: 4.062435, imid loss: 2.090941, cmid loss: 1.971494 \n","Epoch (77), Batch(150/809), loss: 4.270464, imid loss: 2.158239, cmid loss: 2.112226 \n","Epoch (77), Batch(200/809), loss: 3.907035, imid loss: 1.948347, cmid loss: 1.958688 \n","Epoch (77), Batch(250/809), loss: 4.331374, imid loss: 2.345212, cmid loss: 1.986162 \n","Epoch (77), Batch(300/809), loss: 3.744372, imid loss: 1.677770, cmid loss: 2.066602 \n","Epoch (77), Batch(350/809), loss: 4.155357, imid loss: 2.170649, cmid loss: 1.984708 \n","Epoch (77), Batch(400/809), loss: 3.449842, imid loss: 1.475853, cmid loss: 1.973989 \n","Epoch (77), Batch(450/809), loss: 3.795924, imid loss: 1.840251, cmid loss: 1.955673 \n","Epoch (77), Batch(500/809), loss: 3.510768, imid loss: 1.543979, cmid loss: 1.966789 \n","Epoch (77), Batch(550/809), loss: 4.027943, imid loss: 2.056928, cmid loss: 1.971015 \n","Epoch (77), Batch(600/809), loss: 3.598641, imid loss: 1.612482, cmid loss: 1.986159 \n","Epoch (77), Batch(650/809), loss: 3.821604, imid loss: 1.840675, cmid loss: 1.980930 \n","Epoch (77), Batch(700/809), loss: 3.665738, imid loss: 1.696822, cmid loss: 1.968916 \n","Epoch (77), Batch(750/809), loss: 2.967812, imid loss: 0.965329, cmid loss: 2.002483 \n","Epoch (77), Batch(800/809), loss: 3.869288, imid loss: 1.875557, cmid loss: 1.993732 \n","Ending epoch -> 77  (training)\n","Starting epoch  77  (validation_epoch_start)\n","Starting epoch  77  (validation_step)\n","Linear Accuracy : 0.8269854132901134\n","Training 77, loss: 3.832919\n","Starting epoch -> 78  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (78), Batch(0/809), loss: 3.998926, imid loss: 2.029437, cmid loss: 1.969489 \n","Epoch (78), Batch(50/809), loss: 4.260645, imid loss: 2.250444, cmid loss: 2.010201 \n","Epoch (78), Batch(100/809), loss: 4.566562, imid loss: 2.553041, cmid loss: 2.013520 \n","Epoch (78), Batch(150/809), loss: 4.168026, imid loss: 2.182185, cmid loss: 1.985841 \n","Epoch (78), Batch(200/809), loss: 3.538986, imid loss: 1.544466, cmid loss: 1.994520 \n","Epoch (78), Batch(250/809), loss: 3.950401, imid loss: 1.988489, cmid loss: 1.961912 \n","Epoch (78), Batch(300/809), loss: 3.711165, imid loss: 1.712970, cmid loss: 1.998194 \n","Epoch (78), Batch(350/809), loss: 4.219570, imid loss: 2.216523, cmid loss: 2.003047 \n","Epoch (78), Batch(400/809), loss: 3.840992, imid loss: 1.776787, cmid loss: 2.064205 \n","Epoch (78), Batch(450/809), loss: 4.028836, imid loss: 2.062806, cmid loss: 1.966031 \n","Epoch (78), Batch(500/809), loss: 3.533355, imid loss: 1.541566, cmid loss: 1.991789 \n","Epoch (78), Batch(550/809), loss: 3.557759, imid loss: 1.581286, cmid loss: 1.976472 \n","Epoch (78), Batch(600/809), loss: 3.519122, imid loss: 1.471493, cmid loss: 2.047629 \n","Epoch (78), Batch(650/809), loss: 3.367898, imid loss: 1.391644, cmid loss: 1.976254 \n","Epoch (78), Batch(700/809), loss: 4.286776, imid loss: 2.310066, cmid loss: 1.976709 \n","Epoch (78), Batch(750/809), loss: 3.346208, imid loss: 1.349743, cmid loss: 1.996465 \n","Epoch (78), Batch(800/809), loss: 4.103300, imid loss: 2.081277, cmid loss: 2.022023 \n","Ending epoch -> 78  (training)\n","Starting epoch  78  (validation_epoch_start)\n","Starting epoch  78  (validation_step)\n","Linear Accuracy : 0.8192868719611021\n","==> Saving for frequency...\n","Training 78, loss: 3.822756\n","Starting epoch -> 79  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (79), Batch(0/809), loss: 4.973297, imid loss: 2.912579, cmid loss: 2.060718 \n","Epoch (79), Batch(50/809), loss: 3.529786, imid loss: 1.558808, cmid loss: 1.970978 \n","Epoch (79), Batch(100/809), loss: 4.210668, imid loss: 2.206122, cmid loss: 2.004546 \n","Epoch (79), Batch(150/809), loss: 4.627671, imid loss: 2.615808, cmid loss: 2.011863 \n","Epoch (79), Batch(200/809), loss: 3.679539, imid loss: 1.648541, cmid loss: 2.030998 \n","Epoch (79), Batch(250/809), loss: 4.048692, imid loss: 2.085124, cmid loss: 1.963568 \n","Epoch (79), Batch(300/809), loss: 4.134564, imid loss: 2.142130, cmid loss: 1.992434 \n","Epoch (79), Batch(350/809), loss: 3.393672, imid loss: 1.398407, cmid loss: 1.995264 \n","Epoch (79), Batch(400/809), loss: 3.933095, imid loss: 1.934270, cmid loss: 1.998825 \n","Epoch (79), Batch(450/809), loss: 3.658130, imid loss: 1.658096, cmid loss: 2.000034 \n","Epoch (79), Batch(500/809), loss: 4.423804, imid loss: 2.450789, cmid loss: 1.973015 \n","Epoch (79), Batch(550/809), loss: 3.796848, imid loss: 1.774338, cmid loss: 2.022510 \n","Epoch (79), Batch(600/809), loss: 3.719183, imid loss: 1.740089, cmid loss: 1.979094 \n","Epoch (79), Batch(650/809), loss: 3.787727, imid loss: 1.810591, cmid loss: 1.977136 \n","Epoch (79), Batch(700/809), loss: 3.444746, imid loss: 1.207132, cmid loss: 2.237614 \n","Epoch (79), Batch(750/809), loss: 3.101363, imid loss: 1.125789, cmid loss: 1.975574 \n","Epoch (79), Batch(800/809), loss: 3.889923, imid loss: 1.923064, cmid loss: 1.966859 \n","Ending epoch -> 79  (training)\n","Starting epoch  79  (validation_epoch_start)\n","Starting epoch  79  (validation_step)\n","Linear Accuracy : 0.8213128038897893\n","Training 79, loss: 3.818059\n","Starting epoch -> 80  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (80), Batch(0/809), loss: 3.733721, imid loss: 1.731833, cmid loss: 2.001887 \n","Epoch (80), Batch(50/809), loss: 3.836613, imid loss: 1.853497, cmid loss: 1.983116 \n","Epoch (80), Batch(100/809), loss: 3.532732, imid loss: 1.558129, cmid loss: 1.974602 \n","Epoch (80), Batch(150/809), loss: 3.820365, imid loss: 1.841119, cmid loss: 1.979246 \n","Epoch (80), Batch(200/809), loss: 3.445166, imid loss: 1.459550, cmid loss: 1.985616 \n","Epoch (80), Batch(250/809), loss: 3.669385, imid loss: 1.693849, cmid loss: 1.975536 \n","Epoch (80), Batch(300/809), loss: 3.601658, imid loss: 1.609550, cmid loss: 1.992108 \n","Epoch (80), Batch(350/809), loss: 3.244299, imid loss: 1.261654, cmid loss: 1.982645 \n","Epoch (80), Batch(400/809), loss: 4.173469, imid loss: 2.209525, cmid loss: 1.963944 \n","Epoch (80), Batch(450/809), loss: 4.159605, imid loss: 2.197644, cmid loss: 1.961961 \n","Epoch (80), Batch(500/809), loss: 3.583799, imid loss: 1.615556, cmid loss: 1.968243 \n","Epoch (80), Batch(550/809), loss: 3.881273, imid loss: 1.923217, cmid loss: 1.958055 \n","Epoch (80), Batch(600/809), loss: 3.632696, imid loss: 1.665712, cmid loss: 1.966984 \n","Epoch (80), Batch(650/809), loss: 3.923002, imid loss: 1.950625, cmid loss: 1.972377 \n","Epoch (80), Batch(700/809), loss: 3.685189, imid loss: 1.672724, cmid loss: 2.012466 \n","Epoch (80), Batch(750/809), loss: 3.717668, imid loss: 1.747590, cmid loss: 1.970078 \n","Epoch (80), Batch(800/809), loss: 3.842098, imid loss: 1.850025, cmid loss: 1.992072 \n","Ending epoch -> 80  (training)\n","Starting epoch  80  (validation_epoch_start)\n","Starting epoch  80  (validation_step)\n","Linear Accuracy : 0.8241491085899514\n","==> Saving for frequency...\n","Training 80, loss: 3.777086\n","Starting epoch -> 81  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (81), Batch(0/809), loss: 3.345740, imid loss: 1.363364, cmid loss: 1.982376 \n","Epoch (81), Batch(50/809), loss: 3.824368, imid loss: 1.854616, cmid loss: 1.969753 \n","Epoch (81), Batch(100/809), loss: 3.434854, imid loss: 1.449775, cmid loss: 1.985078 \n","Epoch (81), Batch(150/809), loss: 3.791080, imid loss: 1.823822, cmid loss: 1.967258 \n","Epoch (81), Batch(200/809), loss: 3.646653, imid loss: 1.648495, cmid loss: 1.998158 \n","Epoch (81), Batch(250/809), loss: 4.755922, imid loss: 2.569724, cmid loss: 2.186198 \n","Epoch (81), Batch(300/809), loss: 4.136547, imid loss: 2.127303, cmid loss: 2.009244 \n","Epoch (81), Batch(350/809), loss: 3.912540, imid loss: 1.905139, cmid loss: 2.007402 \n","Epoch (81), Batch(400/809), loss: 4.138026, imid loss: 2.180925, cmid loss: 1.957101 \n","Epoch (81), Batch(450/809), loss: 3.484449, imid loss: 1.506061, cmid loss: 1.978388 \n","Epoch (81), Batch(500/809), loss: 4.322136, imid loss: 2.359128, cmid loss: 1.963008 \n","Epoch (81), Batch(550/809), loss: 3.670538, imid loss: 1.683327, cmid loss: 1.987211 \n","Epoch (81), Batch(600/809), loss: 3.935282, imid loss: 1.961429, cmid loss: 1.973853 \n","Epoch (81), Batch(650/809), loss: 3.374832, imid loss: 1.362192, cmid loss: 2.012640 \n","Epoch (81), Batch(700/809), loss: 3.891717, imid loss: 1.884490, cmid loss: 2.007228 \n","Epoch (81), Batch(750/809), loss: 3.696095, imid loss: 1.507828, cmid loss: 2.188267 \n","Epoch (81), Batch(800/809), loss: 3.253187, imid loss: 1.277839, cmid loss: 1.975349 \n","Ending epoch -> 81  (training)\n","Starting epoch  81  (validation_epoch_start)\n","Starting epoch  81  (validation_step)\n","Linear Accuracy : 0.8237439222042139\n","Training 81, loss: 3.797113\n","Starting epoch -> 82  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (82), Batch(0/809), loss: 4.345477, imid loss: 2.383440, cmid loss: 1.962037 \n","Epoch (82), Batch(50/809), loss: 3.392520, imid loss: 1.412756, cmid loss: 1.979764 \n","Epoch (82), Batch(100/809), loss: 3.532418, imid loss: 1.543021, cmid loss: 1.989397 \n","Epoch (82), Batch(150/809), loss: 3.657293, imid loss: 1.662031, cmid loss: 1.995261 \n","Epoch (82), Batch(200/809), loss: 3.539848, imid loss: 1.390053, cmid loss: 2.149795 \n","Epoch (82), Batch(250/809), loss: 4.003458, imid loss: 1.967335, cmid loss: 2.036124 \n","Epoch (82), Batch(300/809), loss: 3.915436, imid loss: 1.911979, cmid loss: 2.003457 \n","Epoch (82), Batch(350/809), loss: 3.846355, imid loss: 1.878421, cmid loss: 1.967935 \n","Epoch (82), Batch(400/809), loss: 3.864441, imid loss: 1.875817, cmid loss: 1.988624 \n","Epoch (82), Batch(450/809), loss: 4.123925, imid loss: 2.143380, cmid loss: 1.980546 \n","Epoch (82), Batch(500/809), loss: 3.378087, imid loss: 1.386776, cmid loss: 1.991311 \n","Epoch (82), Batch(550/809), loss: 4.081084, imid loss: 2.123869, cmid loss: 1.957215 \n","Epoch (82), Batch(600/809), loss: 3.753976, imid loss: 1.770098, cmid loss: 1.983878 \n","Epoch (82), Batch(650/809), loss: 3.726104, imid loss: 1.761930, cmid loss: 1.964174 \n","Epoch (82), Batch(700/809), loss: 4.778726, imid loss: 2.799830, cmid loss: 1.978895 \n","Epoch (82), Batch(750/809), loss: 3.708600, imid loss: 1.713108, cmid loss: 1.995493 \n","Epoch (82), Batch(800/809), loss: 3.817600, imid loss: 1.766833, cmid loss: 2.050768 \n","Ending epoch -> 82  (training)\n","Starting epoch  82  (validation_epoch_start)\n","Starting epoch  82  (validation_step)\n","Linear Accuracy : 0.8245542949756888\n","==> Saving for frequency...\n","Training 82, loss: 3.783047\n","Starting epoch -> 83  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (83), Batch(0/809), loss: 3.411353, imid loss: 1.410431, cmid loss: 2.000921 \n","Epoch (83), Batch(50/809), loss: 3.090553, imid loss: 1.105957, cmid loss: 1.984596 \n","Epoch (83), Batch(100/809), loss: 3.461698, imid loss: 1.452592, cmid loss: 2.009106 \n","Epoch (83), Batch(150/809), loss: 4.211581, imid loss: 2.225981, cmid loss: 1.985600 \n","Epoch (83), Batch(200/809), loss: 3.198738, imid loss: 1.205419, cmid loss: 1.993318 \n","Epoch (83), Batch(250/809), loss: 3.584002, imid loss: 1.609274, cmid loss: 1.974728 \n","Epoch (83), Batch(300/809), loss: 3.368976, imid loss: 1.382791, cmid loss: 1.986184 \n","Epoch (83), Batch(350/809), loss: 3.999709, imid loss: 1.993269, cmid loss: 2.006440 \n","Epoch (83), Batch(400/809), loss: 3.698040, imid loss: 1.710222, cmid loss: 1.987818 \n","Epoch (83), Batch(450/809), loss: 3.474786, imid loss: 1.484230, cmid loss: 1.990556 \n","Epoch (83), Batch(500/809), loss: 3.396164, imid loss: 1.417788, cmid loss: 1.978376 \n","Epoch (83), Batch(550/809), loss: 3.188288, imid loss: 1.206111, cmid loss: 1.982177 \n","Epoch (83), Batch(600/809), loss: 3.647897, imid loss: 1.645004, cmid loss: 2.002892 \n","Epoch (83), Batch(650/809), loss: 3.093818, imid loss: 1.053361, cmid loss: 2.040456 \n","Epoch (83), Batch(700/809), loss: 3.844846, imid loss: 1.852207, cmid loss: 1.992640 \n","Epoch (83), Batch(750/809), loss: 3.796720, imid loss: 1.819356, cmid loss: 1.977364 \n","Epoch (83), Batch(800/809), loss: 3.853761, imid loss: 1.900567, cmid loss: 1.953194 \n","Ending epoch -> 83  (training)\n","Starting epoch  83  (validation_epoch_start)\n","Starting epoch  83  (validation_step)\n","Linear Accuracy : 0.8229335494327391\n","Training 83, loss: 3.777464\n","Starting epoch -> 84  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (84), Batch(0/809), loss: 3.773091, imid loss: 1.806144, cmid loss: 1.966948 \n","Epoch (84), Batch(50/809), loss: 3.823024, imid loss: 1.801249, cmid loss: 2.021775 \n","Epoch (84), Batch(100/809), loss: 3.533269, imid loss: 1.548290, cmid loss: 1.984979 \n","Epoch (84), Batch(150/809), loss: 4.038779, imid loss: 2.080813, cmid loss: 1.957965 \n","Epoch (84), Batch(200/809), loss: 3.582587, imid loss: 1.577009, cmid loss: 2.005578 \n","Epoch (84), Batch(250/809), loss: 3.773412, imid loss: 1.790077, cmid loss: 1.983335 \n","Epoch (84), Batch(300/809), loss: 3.397780, imid loss: 1.403893, cmid loss: 1.993888 \n","Epoch (84), Batch(350/809), loss: 3.440073, imid loss: 1.465944, cmid loss: 1.974129 \n","Epoch (84), Batch(400/809), loss: 4.067235, imid loss: 2.101986, cmid loss: 1.965248 \n","Epoch (84), Batch(450/809), loss: 3.230285, imid loss: 1.249110, cmid loss: 1.981175 \n","Epoch (84), Batch(500/809), loss: 3.764992, imid loss: 1.750086, cmid loss: 2.014906 \n","Epoch (84), Batch(550/809), loss: 3.444852, imid loss: 1.445070, cmid loss: 1.999782 \n","Epoch (84), Batch(600/809), loss: 3.271330, imid loss: 1.280162, cmid loss: 1.991167 \n","Epoch (84), Batch(650/809), loss: 3.259975, imid loss: 1.267705, cmid loss: 1.992270 \n","Epoch (84), Batch(700/809), loss: 3.338104, imid loss: 1.351063, cmid loss: 1.987041 \n","Epoch (84), Batch(750/809), loss: 3.626505, imid loss: 1.618261, cmid loss: 2.008244 \n","Epoch (84), Batch(800/809), loss: 4.585233, imid loss: 2.624712, cmid loss: 1.960521 \n","Ending epoch -> 84  (training)\n","Starting epoch  84  (validation_epoch_start)\n","Starting epoch  84  (validation_step)\n","Linear Accuracy : 0.8350891410048622\n","==> NEW RECORD on accuracy on epoch  84  --- Accuracy =  0.8350891410048622  ----> SAVING Best Model...\n","==> Saving for frequency...\n","Training 84, loss: 3.755952\n","Starting epoch -> 85  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (85), Batch(0/809), loss: 4.303056, imid loss: 2.284376, cmid loss: 2.018679 \n","Epoch (85), Batch(50/809), loss: 3.697577, imid loss: 1.674712, cmid loss: 2.022864 \n","Epoch (85), Batch(100/809), loss: 3.600657, imid loss: 1.606337, cmid loss: 1.994320 \n","Epoch (85), Batch(150/809), loss: 3.387304, imid loss: 1.403132, cmid loss: 1.984172 \n","Epoch (85), Batch(200/809), loss: 5.024811, imid loss: 3.037962, cmid loss: 1.986848 \n","Epoch (85), Batch(250/809), loss: 3.608405, imid loss: 1.623257, cmid loss: 1.985149 \n","Epoch (85), Batch(300/809), loss: 3.485856, imid loss: 1.490737, cmid loss: 1.995119 \n","Epoch (85), Batch(350/809), loss: 4.312038, imid loss: 2.300215, cmid loss: 2.011823 \n","Epoch (85), Batch(400/809), loss: 4.519287, imid loss: 2.524900, cmid loss: 1.994387 \n","Epoch (85), Batch(450/809), loss: 3.280061, imid loss: 1.308039, cmid loss: 1.972022 \n","Epoch (85), Batch(500/809), loss: 4.072720, imid loss: 2.110403, cmid loss: 1.962317 \n","Epoch (85), Batch(550/809), loss: 3.502946, imid loss: 1.475142, cmid loss: 2.027805 \n","Epoch (85), Batch(600/809), loss: 3.776511, imid loss: 1.791015, cmid loss: 1.985495 \n","Epoch (85), Batch(650/809), loss: 4.170014, imid loss: 2.181552, cmid loss: 1.988462 \n","Epoch (85), Batch(700/809), loss: 4.470115, imid loss: 2.429896, cmid loss: 2.040218 \n","Epoch (85), Batch(750/809), loss: 3.478509, imid loss: 1.512254, cmid loss: 1.966255 \n","Epoch (85), Batch(800/809), loss: 4.289918, imid loss: 2.311889, cmid loss: 1.978029 \n","Ending epoch -> 85  (training)\n","Starting epoch  85  (validation_epoch_start)\n","Starting epoch  85  (validation_step)\n","Linear Accuracy : 0.8334683954619124\n","Training 85, loss: 3.767262\n","Starting epoch -> 86  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (86), Batch(0/809), loss: 3.485322, imid loss: 1.505767, cmid loss: 1.979555 \n","Epoch (86), Batch(50/809), loss: 4.405835, imid loss: 2.424866, cmid loss: 1.980969 \n","Epoch (86), Batch(100/809), loss: 3.424940, imid loss: 1.429868, cmid loss: 1.995072 \n","Epoch (86), Batch(150/809), loss: 3.789090, imid loss: 1.821027, cmid loss: 1.968063 \n","Epoch (86), Batch(200/809), loss: 3.368593, imid loss: 1.325608, cmid loss: 2.042985 \n","Epoch (86), Batch(250/809), loss: 4.185730, imid loss: 2.218689, cmid loss: 1.967041 \n","Epoch (86), Batch(300/809), loss: 3.615585, imid loss: 1.612041, cmid loss: 2.003545 \n","Epoch (86), Batch(350/809), loss: 3.921609, imid loss: 1.930595, cmid loss: 1.991015 \n","Epoch (86), Batch(400/809), loss: 3.757949, imid loss: 1.794049, cmid loss: 1.963900 \n","Epoch (86), Batch(450/809), loss: 3.918158, imid loss: 1.904779, cmid loss: 2.013379 \n","Epoch (86), Batch(500/809), loss: 4.111760, imid loss: 2.154660, cmid loss: 1.957101 \n","Epoch (86), Batch(550/809), loss: 3.837322, imid loss: 1.866617, cmid loss: 1.970705 \n","Epoch (86), Batch(600/809), loss: 4.310508, imid loss: 2.343097, cmid loss: 1.967411 \n","Epoch (86), Batch(650/809), loss: 4.013543, imid loss: 2.014176, cmid loss: 1.999367 \n","Epoch (86), Batch(700/809), loss: 3.967679, imid loss: 2.012822, cmid loss: 1.954857 \n","Epoch (86), Batch(750/809), loss: 3.617161, imid loss: 1.648514, cmid loss: 1.968647 \n","Epoch (86), Batch(800/809), loss: 4.328376, imid loss: 2.352488, cmid loss: 1.975887 \n","Ending epoch -> 86  (training)\n","Starting epoch  86  (validation_epoch_start)\n","Starting epoch  86  (validation_step)\n","Linear Accuracy : 0.8221231766612642\n","==> Saving for frequency...\n","Training 86, loss: 3.754292\n","Starting epoch -> 87  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (87), Batch(0/809), loss: 4.075555, imid loss: 2.089316, cmid loss: 1.986239 \n","Epoch (87), Batch(50/809), loss: 4.675130, imid loss: 2.689536, cmid loss: 1.985594 \n","Epoch (87), Batch(100/809), loss: 3.279961, imid loss: 1.281250, cmid loss: 1.998710 \n","Epoch (87), Batch(150/809), loss: 3.834288, imid loss: 1.865555, cmid loss: 1.968733 \n","Epoch (87), Batch(200/809), loss: 3.299617, imid loss: 1.314147, cmid loss: 1.985469 \n","Epoch (87), Batch(250/809), loss: 3.789865, imid loss: 1.818995, cmid loss: 1.970871 \n","Epoch (87), Batch(300/809), loss: 3.631474, imid loss: 1.661703, cmid loss: 1.969771 \n","Epoch (87), Batch(350/809), loss: 3.744839, imid loss: 1.781839, cmid loss: 1.963000 \n","Epoch (87), Batch(400/809), loss: 3.189758, imid loss: 1.229130, cmid loss: 1.960628 \n","Epoch (87), Batch(450/809), loss: 3.478852, imid loss: 1.486917, cmid loss: 1.991935 \n","Epoch (87), Batch(500/809), loss: 3.952746, imid loss: 1.968636, cmid loss: 1.984110 \n","Epoch (87), Batch(550/809), loss: 3.476162, imid loss: 1.517111, cmid loss: 1.959051 \n","Epoch (87), Batch(600/809), loss: 4.150560, imid loss: 2.143390, cmid loss: 2.007170 \n","Epoch (87), Batch(650/809), loss: 3.488385, imid loss: 1.504099, cmid loss: 1.984286 \n","Epoch (87), Batch(700/809), loss: 3.004460, imid loss: 1.049009, cmid loss: 1.955451 \n","Epoch (87), Batch(750/809), loss: 4.022208, imid loss: 2.068337, cmid loss: 1.953871 \n","Epoch (87), Batch(800/809), loss: 3.272681, imid loss: 1.288662, cmid loss: 1.984019 \n","Ending epoch -> 87  (training)\n","Starting epoch  87  (validation_epoch_start)\n","Starting epoch  87  (validation_step)\n","Linear Accuracy : 0.8233387358184765\n","Training 87, loss: 3.748170\n","Starting epoch -> 88  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (88), Batch(0/809), loss: 3.135663, imid loss: 1.129844, cmid loss: 2.005818 \n","Epoch (88), Batch(50/809), loss: 3.573958, imid loss: 1.596335, cmid loss: 1.977623 \n","Epoch (88), Batch(100/809), loss: 3.141403, imid loss: 1.155591, cmid loss: 1.985812 \n","Epoch (88), Batch(150/809), loss: 3.339591, imid loss: 1.352409, cmid loss: 1.987181 \n","Epoch (88), Batch(200/809), loss: 3.553566, imid loss: 1.566795, cmid loss: 1.986771 \n","Epoch (88), Batch(250/809), loss: 4.087675, imid loss: 2.092250, cmid loss: 1.995424 \n","Epoch (88), Batch(300/809), loss: 3.931321, imid loss: 1.950792, cmid loss: 1.980529 \n","Epoch (88), Batch(350/809), loss: 3.729671, imid loss: 1.758218, cmid loss: 1.971453 \n","Epoch (88), Batch(400/809), loss: 3.869605, imid loss: 1.905862, cmid loss: 1.963743 \n","Epoch (88), Batch(450/809), loss: 6.278304, imid loss: 4.289764, cmid loss: 1.988540 \n","Epoch (88), Batch(500/809), loss: 4.177317, imid loss: 2.212675, cmid loss: 1.964641 \n","Epoch (88), Batch(550/809), loss: 3.603083, imid loss: 1.585095, cmid loss: 2.017988 \n","Epoch (88), Batch(600/809), loss: 3.194249, imid loss: 1.192142, cmid loss: 2.002107 \n","Epoch (88), Batch(650/809), loss: 4.314098, imid loss: 2.334346, cmid loss: 1.979752 \n","Epoch (88), Batch(700/809), loss: 4.545842, imid loss: 2.536121, cmid loss: 2.009721 \n","Epoch (88), Batch(750/809), loss: 4.496743, imid loss: 2.532523, cmid loss: 1.964220 \n","Epoch (88), Batch(800/809), loss: 3.810895, imid loss: 1.845542, cmid loss: 1.965353 \n","Ending epoch -> 88  (training)\n","Starting epoch  88  (validation_epoch_start)\n","Starting epoch  88  (validation_step)\n","Linear Accuracy : 0.8253646677471637\n","==> Saving for frequency...\n","Training 88, loss: 3.731848\n","Starting epoch -> 89  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (89), Batch(0/809), loss: 3.750522, imid loss: 1.792694, cmid loss: 1.957828 \n","Epoch (89), Batch(50/809), loss: 4.165898, imid loss: 2.181831, cmid loss: 1.984067 \n","Epoch (89), Batch(100/809), loss: 3.784194, imid loss: 1.801106, cmid loss: 1.983088 \n","Epoch (89), Batch(150/809), loss: 3.314908, imid loss: 1.331192, cmid loss: 1.983716 \n","Epoch (89), Batch(200/809), loss: 3.764838, imid loss: 1.749877, cmid loss: 2.014961 \n","Epoch (89), Batch(250/809), loss: 3.802198, imid loss: 1.720977, cmid loss: 2.081221 \n","Epoch (89), Batch(300/809), loss: 3.981510, imid loss: 1.953850, cmid loss: 2.027660 \n","Epoch (89), Batch(350/809), loss: 3.998597, imid loss: 2.024769, cmid loss: 1.973828 \n","Epoch (89), Batch(400/809), loss: 3.538114, imid loss: 1.566023, cmid loss: 1.972090 \n","Epoch (89), Batch(450/809), loss: 3.733737, imid loss: 1.769220, cmid loss: 1.964516 \n","Epoch (89), Batch(500/809), loss: 3.322524, imid loss: 1.332029, cmid loss: 1.990494 \n","Epoch (89), Batch(550/809), loss: 3.805361, imid loss: 1.824577, cmid loss: 1.980784 \n","Epoch (89), Batch(600/809), loss: 3.398714, imid loss: 1.420337, cmid loss: 1.978376 \n","Epoch (89), Batch(650/809), loss: 3.900411, imid loss: 1.862291, cmid loss: 2.038120 \n","Epoch (89), Batch(700/809), loss: 3.768989, imid loss: 1.726588, cmid loss: 2.042402 \n","Epoch (89), Batch(750/809), loss: 4.396967, imid loss: 2.294569, cmid loss: 2.102397 \n","Epoch (89), Batch(800/809), loss: 3.062918, imid loss: 1.062158, cmid loss: 2.000760 \n","Ending epoch -> 89  (training)\n","Starting epoch  89  (validation_epoch_start)\n","Starting epoch  89  (validation_step)\n","Linear Accuracy : 0.830226904376013\n","Training 89, loss: 3.754478\n","Starting epoch -> 90  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (90), Batch(0/809), loss: 3.207303, imid loss: 1.201884, cmid loss: 2.005419 \n","Epoch (90), Batch(50/809), loss: 3.759952, imid loss: 1.766981, cmid loss: 1.992971 \n","Epoch (90), Batch(100/809), loss: 4.573170, imid loss: 2.603254, cmid loss: 1.969916 \n","Epoch (90), Batch(150/809), loss: 3.619748, imid loss: 1.610850, cmid loss: 2.008898 \n","Epoch (90), Batch(200/809), loss: 4.094965, imid loss: 2.081900, cmid loss: 2.013065 \n","Epoch (90), Batch(250/809), loss: 3.171760, imid loss: 1.128084, cmid loss: 2.043676 \n","Epoch (90), Batch(300/809), loss: 3.598979, imid loss: 1.620586, cmid loss: 1.978393 \n","Epoch (90), Batch(350/809), loss: 3.600793, imid loss: 1.525425, cmid loss: 2.075368 \n","Epoch (90), Batch(400/809), loss: 3.078267, imid loss: 1.101790, cmid loss: 1.976476 \n","Epoch (90), Batch(450/809), loss: 3.706990, imid loss: 1.685011, cmid loss: 2.021979 \n","Epoch (90), Batch(500/809), loss: 4.768176, imid loss: 2.794886, cmid loss: 1.973290 \n","Epoch (90), Batch(550/809), loss: 3.838312, imid loss: 1.873741, cmid loss: 1.964571 \n","Epoch (90), Batch(600/809), loss: 3.863529, imid loss: 1.893461, cmid loss: 1.970068 \n","Epoch (90), Batch(650/809), loss: 3.179546, imid loss: 1.157739, cmid loss: 2.021807 \n","Epoch (90), Batch(700/809), loss: 3.383183, imid loss: 1.322955, cmid loss: 2.060227 \n","Epoch (90), Batch(750/809), loss: 3.359986, imid loss: 1.296654, cmid loss: 2.063332 \n","Epoch (90), Batch(800/809), loss: 3.626487, imid loss: 1.673239, cmid loss: 1.953247 \n","Ending epoch -> 90  (training)\n","Starting epoch  90  (validation_epoch_start)\n","Starting epoch  90  (validation_step)\n","Linear Accuracy : 0.8310372771474879\n","==> Saving for frequency...\n","Training 90, loss: 3.757748\n","Starting epoch -> 91  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (91), Batch(0/809), loss: 3.818285, imid loss: 1.811227, cmid loss: 2.007057 \n","Epoch (91), Batch(50/809), loss: 3.522601, imid loss: 1.545768, cmid loss: 1.976834 \n","Epoch (91), Batch(100/809), loss: 3.676579, imid loss: 1.714920, cmid loss: 1.961659 \n","Epoch (91), Batch(150/809), loss: 3.221030, imid loss: 1.204751, cmid loss: 2.016279 \n","Epoch (91), Batch(200/809), loss: 3.418539, imid loss: 1.443918, cmid loss: 1.974621 \n","Epoch (91), Batch(250/809), loss: 3.598031, imid loss: 1.621344, cmid loss: 1.976687 \n","Epoch (91), Batch(300/809), loss: 3.338046, imid loss: 1.330270, cmid loss: 2.007776 \n","Epoch (91), Batch(350/809), loss: 3.627352, imid loss: 1.618685, cmid loss: 2.008667 \n","Epoch (91), Batch(400/809), loss: 4.032544, imid loss: 2.011936, cmid loss: 2.020608 \n","Epoch (91), Batch(450/809), loss: 3.070428, imid loss: 1.088068, cmid loss: 1.982360 \n","Epoch (91), Batch(500/809), loss: 3.662378, imid loss: 1.680606, cmid loss: 1.981772 \n","Epoch (91), Batch(550/809), loss: 3.676097, imid loss: 1.665723, cmid loss: 2.010374 \n","Epoch (91), Batch(600/809), loss: 3.995965, imid loss: 2.027753, cmid loss: 1.968212 \n","Epoch (91), Batch(650/809), loss: 3.535390, imid loss: 1.551515, cmid loss: 1.983875 \n","Epoch (91), Batch(700/809), loss: 3.903389, imid loss: 1.938184, cmid loss: 1.965205 \n","Epoch (91), Batch(750/809), loss: 4.016702, imid loss: 2.055566, cmid loss: 1.961135 \n","Epoch (91), Batch(800/809), loss: 4.534419, imid loss: 2.534841, cmid loss: 1.999578 \n","Ending epoch -> 91  (training)\n","Starting epoch  91  (validation_epoch_start)\n","Starting epoch  91  (validation_step)\n","Linear Accuracy : 0.8237439222042139\n","Training 91, loss: 3.741692\n","Starting epoch -> 92  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (92), Batch(0/809), loss: 3.360652, imid loss: 1.375047, cmid loss: 1.985605 \n","Epoch (92), Batch(50/809), loss: 3.673609, imid loss: 1.701963, cmid loss: 1.971646 \n","Epoch (92), Batch(100/809), loss: 4.095733, imid loss: 2.067506, cmid loss: 2.028227 \n","Epoch (92), Batch(150/809), loss: 3.254940, imid loss: 1.288457, cmid loss: 1.966483 \n","Epoch (92), Batch(200/809), loss: 3.356010, imid loss: 1.375061, cmid loss: 1.980949 \n","Epoch (92), Batch(250/809), loss: 4.593086, imid loss: 2.618654, cmid loss: 1.974433 \n","Epoch (92), Batch(300/809), loss: 3.863662, imid loss: 1.836737, cmid loss: 2.026925 \n","Epoch (92), Batch(350/809), loss: 3.145477, imid loss: 1.068396, cmid loss: 2.077081 \n","Epoch (92), Batch(400/809), loss: 4.025001, imid loss: 2.013165, cmid loss: 2.011836 \n","Epoch (92), Batch(450/809), loss: 3.655317, imid loss: 1.552863, cmid loss: 2.102454 \n","Epoch (92), Batch(500/809), loss: 4.424511, imid loss: 2.469280, cmid loss: 1.955231 \n","Epoch (92), Batch(550/809), loss: 3.722673, imid loss: 1.682501, cmid loss: 2.040172 \n","Epoch (92), Batch(600/809), loss: 3.506111, imid loss: 1.545244, cmid loss: 1.960867 \n","Epoch (92), Batch(650/809), loss: 3.588025, imid loss: 1.608871, cmid loss: 1.979154 \n","Epoch (92), Batch(700/809), loss: 3.758534, imid loss: 1.789809, cmid loss: 1.968726 \n","Epoch (92), Batch(750/809), loss: 4.001416, imid loss: 2.009560, cmid loss: 1.991857 \n","Epoch (92), Batch(800/809), loss: 3.759107, imid loss: 1.775406, cmid loss: 1.983701 \n","Ending epoch -> 92  (training)\n","Starting epoch  92  (validation_epoch_start)\n","Starting epoch  92  (validation_step)\n","Linear Accuracy : 0.8233387358184765\n","==> Saving for frequency...\n","Training 92, loss: 3.748655\n","Starting epoch -> 93  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (93), Batch(0/809), loss: 3.888235, imid loss: 1.912464, cmid loss: 1.975771 \n","Epoch (93), Batch(50/809), loss: 3.202785, imid loss: 1.179975, cmid loss: 2.022810 \n","Epoch (93), Batch(100/809), loss: 5.276487, imid loss: 3.296038, cmid loss: 1.980449 \n","Epoch (93), Batch(150/809), loss: 3.385946, imid loss: 1.405307, cmid loss: 1.980639 \n","Epoch (93), Batch(200/809), loss: 3.738139, imid loss: 1.764935, cmid loss: 1.973204 \n","Epoch (93), Batch(250/809), loss: 3.358532, imid loss: 1.395569, cmid loss: 1.962963 \n","Epoch (93), Batch(300/809), loss: 3.797264, imid loss: 1.828645, cmid loss: 1.968619 \n","Epoch (93), Batch(350/809), loss: 3.239096, imid loss: 1.253318, cmid loss: 1.985778 \n","Epoch (93), Batch(400/809), loss: 3.497428, imid loss: 1.525857, cmid loss: 1.971571 \n","Epoch (93), Batch(450/809), loss: 4.746388, imid loss: 2.764211, cmid loss: 1.982177 \n","Epoch (93), Batch(500/809), loss: 3.797499, imid loss: 1.756695, cmid loss: 2.040803 \n","Epoch (93), Batch(550/809), loss: 3.621501, imid loss: 1.641107, cmid loss: 1.980394 \n","Epoch (93), Batch(600/809), loss: 4.156153, imid loss: 2.198413, cmid loss: 1.957740 \n","Epoch (93), Batch(650/809), loss: 4.035975, imid loss: 2.019998, cmid loss: 2.015978 \n","Epoch (93), Batch(700/809), loss: 3.517148, imid loss: 1.534801, cmid loss: 1.982347 \n","Epoch (93), Batch(750/809), loss: 3.685023, imid loss: 1.697770, cmid loss: 1.987253 \n","Epoch (93), Batch(800/809), loss: 4.267095, imid loss: 2.297493, cmid loss: 1.969602 \n","Ending epoch -> 93  (training)\n","Starting epoch  93  (validation_epoch_start)\n","Starting epoch  93  (validation_step)\n","Linear Accuracy : 0.8233387358184765\n","Training 93, loss: 3.713230\n","Starting epoch -> 94  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (94), Batch(0/809), loss: 3.999688, imid loss: 2.043251, cmid loss: 1.956438 \n","Epoch (94), Batch(50/809), loss: 3.648087, imid loss: 1.674414, cmid loss: 1.973674 \n","Epoch (94), Batch(100/809), loss: 4.164705, imid loss: 2.168999, cmid loss: 1.995706 \n","Epoch (94), Batch(150/809), loss: 4.270991, imid loss: 2.291003, cmid loss: 1.979988 \n","Epoch (94), Batch(200/809), loss: 3.630826, imid loss: 1.644717, cmid loss: 1.986109 \n","Epoch (94), Batch(250/809), loss: 3.865295, imid loss: 1.885591, cmid loss: 1.979704 \n","Epoch (94), Batch(300/809), loss: 3.707540, imid loss: 1.747836, cmid loss: 1.959704 \n","Epoch (94), Batch(350/809), loss: 4.630318, imid loss: 2.659368, cmid loss: 1.970950 \n","Epoch (94), Batch(400/809), loss: 3.274745, imid loss: 1.233918, cmid loss: 2.040827 \n","Epoch (94), Batch(450/809), loss: 3.864052, imid loss: 1.772420, cmid loss: 2.091632 \n","Epoch (94), Batch(500/809), loss: 4.187302, imid loss: 2.124603, cmid loss: 2.062699 \n","Epoch (94), Batch(550/809), loss: 4.493752, imid loss: 2.539181, cmid loss: 1.954571 \n","Epoch (94), Batch(600/809), loss: 3.797641, imid loss: 1.820070, cmid loss: 1.977571 \n","Epoch (94), Batch(650/809), loss: 3.326750, imid loss: 1.302862, cmid loss: 2.023888 \n","Epoch (94), Batch(700/809), loss: 3.978055, imid loss: 2.006551, cmid loss: 1.971504 \n","Epoch (94), Batch(750/809), loss: 3.983718, imid loss: 1.875908, cmid loss: 2.107810 \n","Epoch (94), Batch(800/809), loss: 3.543785, imid loss: 1.470064, cmid loss: 2.073720 \n","Ending epoch -> 94  (training)\n","Starting epoch  94  (validation_epoch_start)\n","Starting epoch  94  (validation_step)\n","Linear Accuracy : 0.8273905996758509\n","==> Saving for frequency...\n","Training 94, loss: 3.736607\n","Starting epoch -> 95  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (95), Batch(0/809), loss: 3.759141, imid loss: 1.772345, cmid loss: 1.986796 \n","Epoch (95), Batch(50/809), loss: 3.846418, imid loss: 1.860222, cmid loss: 1.986197 \n","Epoch (95), Batch(100/809), loss: 3.254031, imid loss: 1.293863, cmid loss: 1.960168 \n","Epoch (95), Batch(150/809), loss: 3.507915, imid loss: 1.520441, cmid loss: 1.987474 \n","Epoch (95), Batch(200/809), loss: 3.908708, imid loss: 1.954493, cmid loss: 1.954214 \n","Epoch (95), Batch(250/809), loss: 3.325828, imid loss: 1.351488, cmid loss: 1.974340 \n","Epoch (95), Batch(300/809), loss: 4.234468, imid loss: 2.206110, cmid loss: 2.028357 \n","Epoch (95), Batch(350/809), loss: 3.301172, imid loss: 1.320567, cmid loss: 1.980605 \n","Epoch (95), Batch(400/809), loss: 3.278753, imid loss: 1.306774, cmid loss: 1.971979 \n","Epoch (95), Batch(450/809), loss: 3.926330, imid loss: 1.766346, cmid loss: 2.159984 \n","Epoch (95), Batch(500/809), loss: 3.934258, imid loss: 1.973041, cmid loss: 1.961217 \n","Epoch (95), Batch(550/809), loss: 4.666202, imid loss: 2.701773, cmid loss: 1.964429 \n","Epoch (95), Batch(600/809), loss: 3.995270, imid loss: 2.021277, cmid loss: 1.973993 \n","Epoch (95), Batch(650/809), loss: 4.579777, imid loss: 2.611557, cmid loss: 1.968220 \n","Epoch (95), Batch(700/809), loss: 4.152960, imid loss: 2.185294, cmid loss: 1.967666 \n","Epoch (95), Batch(750/809), loss: 3.740069, imid loss: 1.770455, cmid loss: 1.969614 \n","Epoch (95), Batch(800/809), loss: 4.254956, imid loss: 2.249787, cmid loss: 2.005169 \n","Ending epoch -> 95  (training)\n","Starting epoch  95  (validation_epoch_start)\n","Starting epoch  95  (validation_step)\n","Linear Accuracy : 0.8241491085899514\n","Training 95, loss: 3.735999\n","Starting epoch -> 96  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (96), Batch(0/809), loss: 4.361945, imid loss: 2.380172, cmid loss: 1.981774 \n","Epoch (96), Batch(50/809), loss: 3.504254, imid loss: 1.529423, cmid loss: 1.974831 \n","Epoch (96), Batch(100/809), loss: 4.163162, imid loss: 2.159276, cmid loss: 2.003886 \n","Epoch (96), Batch(150/809), loss: 3.675261, imid loss: 1.674543, cmid loss: 2.000718 \n","Epoch (96), Batch(200/809), loss: 3.538935, imid loss: 1.550374, cmid loss: 1.988561 \n","Epoch (96), Batch(250/809), loss: 3.621586, imid loss: 1.613386, cmid loss: 2.008200 \n","Epoch (96), Batch(300/809), loss: 4.906966, imid loss: 2.909354, cmid loss: 1.997612 \n","Epoch (96), Batch(350/809), loss: 3.459377, imid loss: 1.482024, cmid loss: 1.977353 \n","Epoch (96), Batch(400/809), loss: 3.973231, imid loss: 2.008164, cmid loss: 1.965067 \n","Epoch (96), Batch(450/809), loss: 3.602781, imid loss: 1.612266, cmid loss: 1.990515 \n","Epoch (96), Batch(500/809), loss: 3.240309, imid loss: 1.189186, cmid loss: 2.051123 \n","Epoch (96), Batch(550/809), loss: 3.929412, imid loss: 1.921794, cmid loss: 2.007618 \n","Epoch (96), Batch(600/809), loss: 3.194352, imid loss: 1.201789, cmid loss: 1.992563 \n","Epoch (96), Batch(650/809), loss: 4.271595, imid loss: 2.314884, cmid loss: 1.956711 \n","Epoch (96), Batch(700/809), loss: 3.477385, imid loss: 1.467971, cmid loss: 2.009413 \n","Epoch (96), Batch(750/809), loss: 4.451340, imid loss: 2.451275, cmid loss: 2.000065 \n","Epoch (96), Batch(800/809), loss: 3.582300, imid loss: 1.565643, cmid loss: 2.016657 \n","Ending epoch -> 96  (training)\n","Starting epoch  96  (validation_epoch_start)\n","Starting epoch  96  (validation_step)\n","Linear Accuracy : 0.8314424635332253\n","==> Saving for frequency...\n","Training 96, loss: 3.740143\n","Starting epoch -> 97  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (97), Batch(0/809), loss: 3.528622, imid loss: 1.549415, cmid loss: 1.979206 \n","Epoch (97), Batch(50/809), loss: 3.916934, imid loss: 1.929062, cmid loss: 1.987872 \n","Epoch (97), Batch(100/809), loss: 4.151344, imid loss: 2.137864, cmid loss: 2.013480 \n","Epoch (97), Batch(150/809), loss: 3.545625, imid loss: 1.553393, cmid loss: 1.992232 \n","Epoch (97), Batch(200/809), loss: 3.527679, imid loss: 1.546646, cmid loss: 1.981034 \n","Epoch (97), Batch(250/809), loss: 3.260821, imid loss: 1.246579, cmid loss: 2.014241 \n","Epoch (97), Batch(300/809), loss: 3.684051, imid loss: 1.703064, cmid loss: 1.980987 \n","Epoch (97), Batch(350/809), loss: 3.911567, imid loss: 1.910809, cmid loss: 2.000758 \n","Epoch (97), Batch(400/809), loss: 3.672569, imid loss: 1.668805, cmid loss: 2.003764 \n","Epoch (97), Batch(450/809), loss: 3.704894, imid loss: 1.742103, cmid loss: 1.962791 \n","Epoch (97), Batch(500/809), loss: 3.383226, imid loss: 1.402516, cmid loss: 1.980710 \n","Epoch (97), Batch(550/809), loss: 3.777475, imid loss: 1.720376, cmid loss: 2.057099 \n","Epoch (97), Batch(600/809), loss: 4.147765, imid loss: 2.188206, cmid loss: 1.959558 \n","Epoch (97), Batch(650/809), loss: 3.057799, imid loss: 1.058189, cmid loss: 1.999610 \n","Epoch (97), Batch(700/809), loss: 4.147531, imid loss: 1.901364, cmid loss: 2.246167 \n","Epoch (97), Batch(750/809), loss: 3.509640, imid loss: 1.522309, cmid loss: 1.987331 \n","Epoch (97), Batch(800/809), loss: 3.568692, imid loss: 1.588577, cmid loss: 1.980115 \n","Ending epoch -> 97  (training)\n","Starting epoch  97  (validation_epoch_start)\n","Starting epoch  97  (validation_step)\n","Linear Accuracy : 0.826580226904376\n","Training 97, loss: 3.700926\n","Starting epoch -> 98  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (98), Batch(0/809), loss: 3.507367, imid loss: 1.502808, cmid loss: 2.004559 \n","Epoch (98), Batch(50/809), loss: 3.971581, imid loss: 1.848995, cmid loss: 2.122586 \n","Epoch (98), Batch(100/809), loss: 3.833859, imid loss: 1.761558, cmid loss: 2.072300 \n","Epoch (98), Batch(150/809), loss: 3.868470, imid loss: 1.891715, cmid loss: 1.976755 \n","Epoch (98), Batch(200/809), loss: 4.251555, imid loss: 2.282412, cmid loss: 1.969143 \n","Epoch (98), Batch(250/809), loss: 3.423265, imid loss: 1.442322, cmid loss: 1.980943 \n","Epoch (98), Batch(300/809), loss: 3.292347, imid loss: 1.258242, cmid loss: 2.034105 \n","Epoch (98), Batch(350/809), loss: 3.531145, imid loss: 1.566891, cmid loss: 1.964254 \n","Epoch (98), Batch(400/809), loss: 3.917294, imid loss: 1.962068, cmid loss: 1.955227 \n","Epoch (98), Batch(450/809), loss: 3.661491, imid loss: 1.694487, cmid loss: 1.967004 \n","Epoch (98), Batch(500/809), loss: 4.041264, imid loss: 2.067240, cmid loss: 1.974024 \n","Epoch (98), Batch(550/809), loss: 4.486339, imid loss: 2.483449, cmid loss: 2.002890 \n","Epoch (98), Batch(600/809), loss: 3.244932, imid loss: 1.276221, cmid loss: 1.968712 \n","Epoch (98), Batch(650/809), loss: 3.729909, imid loss: 1.767820, cmid loss: 1.962090 \n","Epoch (98), Batch(700/809), loss: 3.511465, imid loss: 1.516846, cmid loss: 1.994619 \n","Epoch (98), Batch(750/809), loss: 3.625627, imid loss: 1.579642, cmid loss: 2.045985 \n","Epoch (98), Batch(800/809), loss: 3.071002, imid loss: 0.984017, cmid loss: 2.086985 \n","Ending epoch -> 98  (training)\n","Starting epoch  98  (validation_epoch_start)\n","Starting epoch  98  (validation_step)\n","Linear Accuracy : 0.8253646677471637\n","==> Saving for frequency...\n","Training 98, loss: 3.730415\n","Starting epoch -> 99  (training)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch (99), Batch(0/809), loss: 3.755253, imid loss: 1.747810, cmid loss: 2.007443 \n","Epoch (99), Batch(50/809), loss: 4.353641, imid loss: 2.281699, cmid loss: 2.071941 \n","Epoch (99), Batch(100/809), loss: 3.521624, imid loss: 1.538737, cmid loss: 1.982887 \n","Epoch (99), Batch(150/809), loss: 3.179818, imid loss: 1.211648, cmid loss: 1.968170 \n","Epoch (99), Batch(200/809), loss: 3.760816, imid loss: 1.784870, cmid loss: 1.975946 \n","Epoch (99), Batch(250/809), loss: 4.188596, imid loss: 2.147746, cmid loss: 2.040850 \n","Epoch (99), Batch(300/809), loss: 3.594396, imid loss: 1.622003, cmid loss: 1.972393 \n","Epoch (99), Batch(350/809), loss: 4.067648, imid loss: 2.108467, cmid loss: 1.959181 \n","Epoch (99), Batch(400/809), loss: 3.764773, imid loss: 1.775525, cmid loss: 1.989249 \n","Epoch (99), Batch(450/809), loss: 3.372734, imid loss: 1.400077, cmid loss: 1.972657 \n","Epoch (99), Batch(500/809), loss: 4.001813, imid loss: 2.011745, cmid loss: 1.990068 \n","Epoch (99), Batch(550/809), loss: 4.024331, imid loss: 2.036134, cmid loss: 1.988197 \n","Epoch (99), Batch(600/809), loss: 3.493909, imid loss: 1.500654, cmid loss: 1.993255 \n","Epoch (99), Batch(650/809), loss: 3.426117, imid loss: 1.445568, cmid loss: 1.980549 \n","Epoch (99), Batch(700/809), loss: 3.839744, imid loss: 1.868832, cmid loss: 1.970912 \n","Epoch (99), Batch(750/809), loss: 3.973163, imid loss: 1.918992, cmid loss: 2.054171 \n","Epoch (99), Batch(800/809), loss: 3.114746, imid loss: 1.096882, cmid loss: 2.017864 \n","Ending epoch -> 99  (training)\n","Starting epoch  99  (validation_epoch_start)\n","Starting epoch  99  (validation_step)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n"]},{"name":"stdout","output_type":"stream","text":["Linear Accuracy : 0.8350891410048622\n","Training 99, loss: 3.718217\n"]}],"source":["check_checkpoint_folders()\n","torch.set_float32_matmul_precision('medium')\n","io = IOStream('/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/checkpoints/' + args['exp_name'] + '/run.log')\n","io.cprint(str(args))\n","args['cuda'] = not args['no_cuda'] and torch.cuda.is_available()\n","torch.manual_seed(args['seed'])\n","if args['cuda']:\n","    io.cprint(\n","        'Using GPU : ' + str(torch.cuda.current_device()) + ' from ' + str(torch.cuda.device_count()) + ' devices')\n","    torch.cuda.manual_seed(args['seed'])\n","else:\n","    io.cprint('Using CPU')\n","\n","if args['model_point'] == 'pointbert':\n","  sys.path.append('content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT/models')\n","  from drive.MyDrive.CrossPoint_Sapienza_NN_2023.models.Point_BERT.models import Point_BERT\n","\n","sys.path.append('/content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/datasets')\n","from drive.MyDrive.CrossPoint_Sapienza_NN_2023.datasets.data import ShapeNetRender, ModelNet40SVM\n","#sys.path.append('content/drive/MyDrive/CrossPoint_Sapienza_NN_2023/models/Point_BERT') # forse è /models/Point_BERT/models\n","\n","\n","# ------------\n","# training or testing\n","# ------------ \n","if not args['evalu']:\n","    train(args, io)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsVh-BuiRkQ_"},"outputs":[],"source":["if torch.cuda.is_available(): print('Flying on gpu')\n","else: print('Morendo su cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4G7yaIYSSGQK"},"outputs":[],"source":["mamt_frec_e_puzz = Pct(torch.load(args['spct_model_path']))\n","print(mamt_frec_e_puzz)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP1OQJV1f6A50mTTLhfOD9h","collapsed_sections":["7N2WmitQqRPx","O5-hFUnOyQmO","g71fP8BIp0Jj","VI2q7To7pu-S","jN5esaF3p5cS","Bc0lqOkTqIQ7","nb6iWR5aH55d","Z_yVOvUsEmbd"],"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6 (main, Aug 30 2022, 04:58:14) [Clang 13.1.6 (clang-1316.0.21.2.5)]"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"05eb21e578d449b6bc21c0fecfbb93c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c0a889bc775441b97c0fd9547e1f985":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f0af6de4aa7405ea79f2058f15dc62d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1645d670966546409357466519f81a9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35df70bedbb8479db5736c86c0f5b481":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d5f76bf51e54f29b3e21792ccd9c0f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"444e3ea07fac49d7b200be511a83e6a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c0a889bc775441b97c0fd9547e1f985","placeholder":"​","style":"IPY_MODEL_05eb21e578d449b6bc21c0fecfbb93c6","value":"Epoch 99: 100%"}},"4c8115b14564473689b0010fd0a78214":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4cf574578d4249e796faa249bbe91df2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6057521411c944fc8bfe40db1b61f9bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74630514a4ef432e89286059fc550c1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e88433848394b11b02bc536a0d049f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85473093b6e44a1d97d5b034ba23ad25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9499781c1e244cffae40f46c5b054a1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74630514a4ef432e89286059fc550c1d","placeholder":"​","style":"IPY_MODEL_7e88433848394b11b02bc536a0d049f5","value":"0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\r"}},"9d61e858c872444fb136f2e252304b7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_9499781c1e244cffae40f46c5b054a1e","IPY_MODEL_fc2e5618be574c92bf9080bf128ac0c6"],"layout":"IPY_MODEL_6057521411c944fc8bfe40db1b61f9bb"}},"c591daf894834208894cc662f7427692":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_444e3ea07fac49d7b200be511a83e6a5","IPY_MODEL_e5cbe3c7cc5349ca8ac71d2fe46f1458","IPY_MODEL_f0c77a7856184aaf86af04bd98681bbd"],"layout":"IPY_MODEL_3d5f76bf51e54f29b3e21792ccd9c0f6"}},"e5cbe3c7cc5349ca8ac71d2fe46f1458":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cf574578d4249e796faa249bbe91df2","max":809,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c8115b14564473689b0010fd0a78214","value":809}},"f0c77a7856184aaf86af04bd98681bbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1645d670966546409357466519f81a9d","placeholder":"​","style":"IPY_MODEL_85473093b6e44a1d97d5b034ba23ad25","value":" 809/809 [05:26&lt;00:00,  2.48it/s, loss=3.7, v_num=0]"}},"fc2e5618be574c92bf9080bf128ac0c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_35df70bedbb8479db5736c86c0f5b481","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f0af6de4aa7405ea79f2058f15dc62d","value":0.0745409429280397}}}}},"nbformat":4,"nbformat_minor":0}
